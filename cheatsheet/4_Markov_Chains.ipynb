{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86a17acc",
   "metadata": {},
   "source": [
    "# 4) Markov Chain & Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab41051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33765e93",
   "metadata": {},
   "source": [
    "### Validate Transition Matrix\n",
    "\n",
    "**What is this?**\n",
    "Checks if a matrix is a valid Markov chain transition matrix.\n",
    "\n",
    "**Requirements for validity:**\n",
    "1. **Non-negative entries**: All probabilities $P_{ij} \\geq 0$\n",
    "2. **Row stochastic**: Each row sums to 1 (sum of transition probabilities from any state = 1)\n",
    "\n",
    "**Mathematical Notation:**\n",
    "- $P$ = Transition probability matrix\n",
    "- $P_{ij}$ = Probability of transitioning from state $i$ to state $j$\n",
    "- $i$ = Current state (row index)\n",
    "- $j$ = Next state (column index)\n",
    "\n",
    "**Interpretation:**\n",
    "- $P_{ij}$ = Probability of transitioning from state $i$ to state $j$\n",
    "- Each row represents a probability distribution over next states\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "P = [[0.7, 0.3],\n",
    "     [0.4, 0.6]]  # Valid: rows sum to 1, all non-negative\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6cc0c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_transition_matrix(P, tol=1e-10):\n",
    "    \"\"\"\n",
    "    Check if a matrix is a valid transition matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like, shape (n_states, n_states)\n",
    "        Matrix to check for transition matrix properties\n",
    "    tol : float, default=1e-10\n",
    "        Tolerance for numerical checks (negative values and row sums)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    bool : True if P is a valid transition matrix, False otherwise\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    if (P < -tol).any():\n",
    "        return False\n",
    "    return np.allclose(P.sum(axis=1), 1.0, atol=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdbe1d6",
   "metadata": {},
   "source": [
    "### Estimate Transition Matrix from Path\n",
    "\n",
    "**What is this?**\n",
    "Learn the transition probabilities of a Markov chain from observed state sequences.\n",
    "\n",
    "**Algorithm:**\n",
    "1. Count transitions: How many times did we go from state $i$ to state $j$?\n",
    "2. Normalize each row: $\\hat{P}_{ij} = \\frac{\\text{count}(i \\to j)}{\\sum_k \\text{count}(i \\to k)}$\n",
    "\n",
    "**Variables:**\n",
    "- $\\hat{P}_{ij}$ = Estimated probability of transitioning from state $i$ to state $j$\n",
    "- $i$ = Current state (source state)\n",
    "- $j$ = Next state (destination state)\n",
    "- $k$ = Index for summing over all possible destination states\n",
    "- count$(i \\to j)$ = Number of observed transitions from state $i$ to state $j$\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Path: [0, 1, 1, 0, 1]\n",
    "Transitions: 0→1 (2 times), 1→1 (1 time), 1→0 (1 time)\n",
    "Matrix: P[0,1] = 2/2 = 1.0\n",
    "        P[1,0] = 1/2 = 0.5\n",
    "        P[1,1] = 1/2 = 0.5\n",
    "```\n",
    "\n",
    "**Use case:** Learning transition probabilities from real data (e.g., customer behavior, weather patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40fd442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_transition_matrix(states, n_states=None):\n",
    "    \"\"\"\n",
    "    Estimate transition matrix from observed state sequence.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    states : array-like, shape (n_observations,)\n",
    "        Sequence of observed states (integer state indices)\n",
    "    n_states : int, optional\n",
    "        Number of states in the chain. If None, inferred as max(states) + 1\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    P_hat : array, shape (n_states, n_states)\n",
    "        Estimated transition probability matrix where P_hat[i,j] is the \n",
    "        estimated probability of transitioning from state i to state j\n",
    "    \"\"\"\n",
    "    s = np.asarray(states, dtype=int)\n",
    "    if n_states is None:\n",
    "        n_states = int(s.max()) + 1\n",
    "\n",
    "    counts = np.zeros((n_states, n_states), dtype=float)\n",
    "    for a, b in zip(s[:-1], s[1:]):\n",
    "        counts[a, b] += 1\n",
    "\n",
    "    row_sums = counts.sum(axis=1, keepdims=True)\n",
    "    P_hat = np.divide(counts, row_sums, out=np.zeros_like(counts), where=row_sums > 0)\n",
    "    return P_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95777db0",
   "metadata": {},
   "source": [
    "### Simulate Chain\n",
    "\n",
    "**What is this?**\n",
    "Generate a random path/trajectory through a Markov chain.\n",
    "\n",
    "**Algorithm:**\n",
    "1. Start at initial state $x_0$\n",
    "2. At each step, randomly choose next state according to $P[x_t, \\cdot]$\n",
    "3. Repeat for $T$ steps\n",
    "\n",
    "**Variables:**\n",
    "- $x_0$ = Initial state (starting state)\n",
    "- $x_t$ = State at time $t$\n",
    "- $T$ = Number of transitions to simulate\n",
    "- $P[x_t, \\cdot]$ = Row of transition matrix representing probabilities from state $x_t$ to all other states\n",
    "\n",
    "**Parameters:**\n",
    "- `P`: Transition matrix\n",
    "- `x0`: Starting state\n",
    "- `T`: Number of transitions to simulate\n",
    "\n",
    "**Output:** Sequence of states $[x_0, x_1, x_2, \\ldots, x_T]$\n",
    "\n",
    "**Use cases:**\n",
    "- Simulating random processes (stock prices, weather)\n",
    "- Monte Carlo estimation of chain properties\n",
    "- Testing chain convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f7a4f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_chain(P, x0, T, rng=None):\n",
    "    \"\"\"\n",
    "    Simulate a random path through a Markov chain.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like, shape (n_states, n_states)\n",
    "        Transition probability matrix\n",
    "    x0 : int\n",
    "        Initial state (starting state index)\n",
    "    T : int\n",
    "        Number of transitions to simulate\n",
    "    rng : numpy.random.Generator, optional\n",
    "        Random number generator. If None, creates a new default generator\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    path : array, shape (T+1,)\n",
    "        Sequence of states [x_0, x_1, x_2, ..., x_T] visited during simulation\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    P = np.asarray(P, float)\n",
    "    x = int(x0)\n",
    "    path = [x]\n",
    "    for _ in range(T):\n",
    "        x = rng.choice(P.shape[0], p=P[x])\n",
    "        path.append(int(x))\n",
    "    return np.array(path, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ac8b59",
   "metadata": {},
   "source": [
    "### N-Step Transition Probability\n",
    "\n",
    "**What is this?**\n",
    "Computes the probability of being in state $j$ after exactly $n$ steps, starting from state $i$.\n",
    "\n",
    "**Formula:**\n",
    "$$P^{(n)}_{ij} = (P^n)_{ij}$$\n",
    "\n",
    "where $P^n$ is the transition matrix raised to the $n$-th power.\n",
    "\n",
    "**Variables:**\n",
    "- $P^{(n)}_{ij}$ = Probability of transitioning from state $i$ to state $j$ in exactly $n$ steps\n",
    "- $P$ = One-step transition matrix\n",
    "- $P^n$ = n-step transition matrix (P multiplied by itself n times)\n",
    "- $i$ = Starting state\n",
    "- $j$ = Ending state\n",
    "- $n$ = Number of steps\n",
    "\n",
    "**Why it works:**\n",
    "- $P^1 = P$: 1-step transition probabilities\n",
    "- $P^2 = P \\times P$: 2-step transition probabilities  \n",
    "- $P^n$: n-step transition probabilities (Chapman-Kolmogorov equation)\n",
    "\n",
    "**Example:**\n",
    "If you're in state 0, what's the probability of being in state 1 after 5 steps?\n",
    "```python\n",
    "prob = n_step_probability(P, start_state=0, end_state=1, n=5)\n",
    "```\n",
    "\n",
    "**Use cases:**\n",
    "- Long-term predictions without computing full stationary distribution\n",
    "- Finite-horizon forecasting (e.g., \"What's my customer state in 6 months?\")\n",
    "- Understanding transient behavior before convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbb8295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_step_probability(P, start_state, end_state, n):\n",
    "    \"\"\"\n",
    "    Calculate probability of being in end_state after n steps from start_state.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like, shape (n_states, n_states)\n",
    "        Transition probability matrix\n",
    "    start_state : int\n",
    "        Starting state index\n",
    "    end_state : int\n",
    "        Target state index\n",
    "    n : int\n",
    "        Number of steps\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float : Probability of transition from start_state to end_state in n steps\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    P_n = np.linalg.matrix_power(P, n)\n",
    "    return P_n[start_state, end_state]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7eef13",
   "metadata": {},
   "source": [
    "### First Passage Time Probability\n",
    "\n",
    "**What is this?**\n",
    "Computes the probability of reaching state $j$ **for the first time** after exactly $n$ steps, starting from state $i$.\n",
    "\n",
    "**Difference from n-step probability:**\n",
    "- **N-step probability**: Probability of being in state $j$ after $n$ steps (may have visited before)\n",
    "- **First passage time**: Probability of reaching state $j$ for the **first time** at step $n$\n",
    "\n",
    "**Formula:**\n",
    "$$f^{(n)}_{ij} = P^{(n)}_{ij} - \\sum_{k=1}^{n-1} f^{(k)}_{ij} \\cdot P^{(n-k)}_{jj}$$\n",
    "\n",
    "where:\n",
    "- $f^{(1)}_{ij} = P_{ij}$ (1-step is always first time if $i \\neq j$)\n",
    "- For $i = j$: first return time to the same state\n",
    "\n",
    "**Variables:**\n",
    "- $f^{(n)}_{ij}$ = Probability of first passage from state $i$ to state $j$ at exactly step $n$\n",
    "- $P^{(n)}_{ij}$ = n-step transition probability from $i$ to $j$ (may include multiple visits)\n",
    "- $k$ = Intermediate step at which first passage could occur\n",
    "- $P^{(n-k)}_{jj}$ = Probability of being in state $j$ after $n-k$ additional steps from $j$\n",
    "- $i$ = Starting state\n",
    "- $j$ = Target state\n",
    "- $n$ = Exact step at which first passage occurs\n",
    "\n",
    "**Example:**\n",
    "If you start in state 0, what's the probability you reach state 2 for the first time at exactly step 5?\n",
    "```python\n",
    "prob = first_passage_probability(P, start_state=0, target_state=2, n=5)\n",
    "```\n",
    "\n",
    "**Use cases:**\n",
    "- Time-to-event analysis (e.g., \"When will customer first churn?\")\n",
    "- Expected hitting times\n",
    "- Analyzing recurrence properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35c0931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_passage_probability(P, start_state, target_state, n):\n",
    "    \"\"\"\n",
    "    Calculate probability of reaching target_state for the FIRST time \n",
    "    at exactly step n, starting from start_state.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like, shape (n_states, n_states)\n",
    "        Transition probability matrix\n",
    "    start_state : int\n",
    "        Starting state index\n",
    "    target_state : int\n",
    "        Target state index to reach for first time\n",
    "    n : int\n",
    "        Number of steps (must reach at exactly this step)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float : First passage probability\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    \n",
    "    if n == 1:\n",
    "        # First step: just direct transition probability\n",
    "        return P[start_state, target_state]\n",
    "    \n",
    "    # Compute first passage probabilities recursively\n",
    "    f = {}  # f[(k, i, j)] = first passage prob from i to j at step k\n",
    "    \n",
    "    # Base case: 1-step first passage\n",
    "    for i in range(P.shape[0]):\n",
    "        for j in range(P.shape[0]):\n",
    "            f[(1, i, j)] = P[i, j]\n",
    "    \n",
    "    # Recursive computation for steps 2 to n\n",
    "    for k in range(2, n + 1):\n",
    "        for i in range(P.shape[0]):\n",
    "            for j in range(P.shape[0]):\n",
    "                # P^(k)_{ij} - sum of (first reach j at step m) * (stay around j until step k)\n",
    "                P_k_ij = n_step_probability(P, i, j, k)\n",
    "                correction = sum(f[(m, i, j)] * n_step_probability(P, j, j, k - m) \n",
    "                               for m in range(1, k))\n",
    "                f[(k, i, j)] = P_k_ij - correction\n",
    "    \n",
    "    return f[(n, start_state, target_state)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80e6010",
   "metadata": {},
   "source": [
    "### K-th Passage Time Probability\n",
    "\n",
    "**What is this?**\n",
    "Computes the probability of reaching state $j$ **for the k-th time** after exactly $n$ steps, starting from state $i$.\n",
    "\n",
    "**Generalizes first passage time:**\n",
    "- $k=1$: First time reaching the state\n",
    "- $k=2$: Second time reaching the state\n",
    "- $k=3$: Third time reaching the state, etc.\n",
    "\n",
    "**Formula (recursive):**\n",
    "$$f^{(n)}_k(i \\to j) = \\sum_{m=1}^{n-1} f^{(m)}_{k-1}(i \\to j) \\cdot f^{(n-m)}_1(j \\to j)$$\n",
    "\n",
    "where:\n",
    "- $f^{(n)}_1(i \\to j)$ is the first passage probability\n",
    "- $f^{(n)}_k(i \\to j)$ builds on previous visits\n",
    "\n",
    "**Variables:**\n",
    "- $f^{(n)}_k(i \\to j)$ = Probability of k-th passage from state $i$ to state $j$ at exactly step $n$\n",
    "- $k$ = Which visit/passage (1st, 2nd, 3rd, etc.)\n",
    "- $m$ = Step at which (k-1)-th passage occurred\n",
    "- $n-m$ = Remaining steps after (k-1)-th passage\n",
    "- $f^{(m)}_{k-1}(i \\to j)$ = Probability of (k-1)-th passage at step $m$\n",
    "- $f^{(n-m)}_1(j \\to j)$ = Probability of first return to $j$ in remaining $n-m$ steps\n",
    "- $i$ = Starting state\n",
    "- $j$ = Target state\n",
    "- $n$ = Exact step at which k-th passage occurs\n",
    "\n",
    "**Intuition:**\n",
    "To reach $j$ for the k-th time at step $n$:\n",
    "1. Reach $j$ for the (k-1)-th time at some earlier step $m$\n",
    "2. Then reach $j$ again (first return) in the remaining $n-m$ steps\n",
    "\n",
    "**Example:**\n",
    "What's the probability of visiting state 1 for the **second time** at exactly step 10?\n",
    "```python\n",
    "prob = kth_passage_probability(P, start_state=0, target_state=1, k=2, n=10)\n",
    "```\n",
    "\n",
    "**Use cases:**\n",
    "- Repeated event analysis (e.g., \"When will customer churn for the 2nd time?\")\n",
    "- Multi-visit patterns\n",
    "- Understanding state recurrence frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3761249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kth_passage_probability(P, start_state, target_state, k, n):\n",
    "    \"\"\"\n",
    "    Calculate probability of reaching target_state for the K-TH time \n",
    "    at exactly step n, starting from start_state.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like, shape (n_states, n_states)\n",
    "        Transition probability matrix\n",
    "    start_state : int\n",
    "        Starting state index\n",
    "    target_state : int\n",
    "        Target state index\n",
    "    k : int\n",
    "        Which visit (1=first time, 2=second time, etc.)\n",
    "    n : int\n",
    "        Number of steps (must reach for k-th time at exactly this step)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float : K-th passage probability\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    \n",
    "    if k < 1 or n < k:\n",
    "        return 0.0  # Impossible to have k visits in less than k steps\n",
    "    \n",
    "    # Memoization: f_cache[(visit, step, i, j)] = prob of visit-th passage from i to j at step\n",
    "    f_cache = {}\n",
    "    \n",
    "    def f_passage(visit, step, i, j):\n",
    "        \"\"\"Compute visit-th passage probability from i to j at exactly step.\"\"\"\n",
    "        if (visit, step, i, j) in f_cache:\n",
    "            return f_cache[(visit, step, i, j)]\n",
    "        \n",
    "        if visit == 1:\n",
    "            # First passage: use the previous function logic\n",
    "            result = first_passage_probability(P, i, j, step)\n",
    "        else:\n",
    "            # K-th passage: sum over all ways to reach (k-1)-th visit, then first return\n",
    "            result = 0.0\n",
    "            for m in range(visit - 1, step):  # Need at least (visit-1) steps for (k-1) visits\n",
    "                # Reach j for (visit-1)-th time at step m\n",
    "                prob_prev = f_passage(visit - 1, m, i, j)\n",
    "                # Then first return from j to j in (step - m) steps\n",
    "                if step - m > 0:\n",
    "                    prob_return = first_passage_probability(P, j, j, step - m)\n",
    "                    result += prob_prev * prob_return\n",
    "        \n",
    "        f_cache[(visit, step, i, j)] = result\n",
    "        return result\n",
    "    \n",
    "    return f_passage(k, n, start_state, target_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e54546",
   "metadata": {},
   "source": [
    "### Irreducibility Check\n",
    "\n",
    "**What is this?**\n",
    "A Markov chain is **irreducible** if you can reach any state from any other state (eventually).\n",
    "\n",
    "**Why it matters:**\n",
    "- Irreducible chains have a unique stationary distribution\n",
    "- Non-irreducible chains can get \"stuck\" in subsets of states\n",
    "\n",
    "**Algorithm:**\n",
    "Uses graph reachability: For each state, check if all other states are reachable following the transition graph.\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Irreducible: [0→1→2→0] (circular)\n",
    "Not irreducible: [0⇄1] [2⇄3] (two separate groups)\n",
    "```\n",
    "\n",
    "**Testing:** The function performs BFS/DFS from each state to verify full connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d92a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_irreducible(P):\n",
    "    \"\"\"\n",
    "    Check if a Markov chain is irreducible.\n",
    "    \n",
    "    A chain is irreducible if every state is reachable from every other state.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like, shape (n_states, n_states)\n",
    "        Transition probability matrix\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    bool : True if chain is irreducible, False otherwise\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    n = P.shape[0]\n",
    "    adj = (P > 0)\n",
    "\n",
    "    def reachable(start):\n",
    "        seen = set([start])\n",
    "        stack = [start]\n",
    "        while stack:\n",
    "            u = stack.pop()\n",
    "            for v in np.where(adj[u])[0]:\n",
    "                if v not in seen:\n",
    "                    seen.add(int(v))\n",
    "                    stack.append(int(v))\n",
    "        return seen\n",
    "\n",
    "    for s in range(n):\n",
    "        if len(reachable(s)) != n:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d5e3f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mat_A = np.array([[0.8,0.2,0,0],\n",
    "                  [0.6,0.2,0.2,0],\n",
    "                  [0,0.4,0,0.6],\n",
    "                  [0,0,0.8,0.2]])\n",
    "\n",
    "is_irreducible(Mat_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eddf41b",
   "metadata": {},
   "source": [
    "### Communicating Classes\n",
    "\n",
    "**What is this?**\n",
    "States $i$ and $j$ **communicate** if you can go from $i$ to $j$ and from $j$ to $i$ (not necessarily in one step).\n",
    "\n",
    "**Communicating Class:**\n",
    "A maximal set of states that all communicate with each other.\n",
    "\n",
    "**Properties:**\n",
    "- Communication is an equivalence relation (reflexive, symmetric, transitive)\n",
    "- Every state belongs to exactly one communicating class\n",
    "- Irreducible chain = Single communicating class (all states communicate)\n",
    "\n",
    "**Why it matters:**\n",
    "- Identifies independent parts of the chain\n",
    "- States in different classes don't interact\n",
    "- Each class can have its own stationary distribution\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "States: {0, 1, 2, 3}\n",
    "Transitions: 0⇄1, 2⇄3 (but no path between {0,1} and {2,3})\n",
    "Classes: {0, 1} and {2, 3}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c310cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_communicating_classes(P):\n",
    "    \"\"\"\n",
    "    Find all communicating classes in a Markov chain.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like\n",
    "        Transition matrix\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    classes : list of sets\n",
    "        List of communicating classes (each class is a set of state indices)\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    n = P.shape[0]\n",
    "    adj = (P > 0)\n",
    "    \n",
    "    def reachable_from(start):\n",
    "        \"\"\"Find all states reachable from start.\"\"\"\n",
    "        seen = set([start])\n",
    "        stack = [start]\n",
    "        while stack:\n",
    "            u = stack.pop()\n",
    "            for v in np.where(adj[u])[0]:\n",
    "                if v not in seen:\n",
    "                    seen.add(int(v))\n",
    "                    stack.append(int(v))\n",
    "        return seen\n",
    "    \n",
    "    # Find communicating classes using Union-Find approach\n",
    "    classes = []\n",
    "    visited = set()\n",
    "    \n",
    "    for i in range(n):\n",
    "        if i in visited:\n",
    "            continue\n",
    "        \n",
    "        # Find all states reachable from i\n",
    "        reachable_i = reachable_from(i)\n",
    "        \n",
    "        # Find states that can reach i (i.e., i is reachable from them)\n",
    "        can_reach_i = set()\n",
    "        for j in range(n):\n",
    "            if i in reachable_from(j):\n",
    "                can_reach_i.add(j)\n",
    "        \n",
    "        # Communicating class = intersection\n",
    "        comm_class = reachable_i & can_reach_i\n",
    "        \n",
    "        classes.append(comm_class)\n",
    "        visited.update(comm_class)\n",
    "    \n",
    "    return classes\n",
    "\n",
    "def classify_chain_structure(P):\n",
    "    \"\"\"\n",
    "    Classify the structure of a Markov chain.\n",
    "    \n",
    "    Returns information about communicating classes and irreducibility.\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    classes = find_communicating_classes(P)\n",
    "    \n",
    "    is_irreducible_chain = (len(classes) == 1)\n",
    "    \n",
    "    return {\n",
    "        \"num_classes\": len(classes),\n",
    "        \"classes\": classes,\n",
    "        \"is_irreducible\": is_irreducible_chain,\n",
    "        \"class_sizes\": [len(c) for c in classes]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f570fcda",
   "metadata": {},
   "source": [
    "### Transient and Recurrent States\n",
    "\n",
    "**What is this?**\n",
    "Classification of states based on whether the chain will definitely return to them.\n",
    "\n",
    "**Definitions:**\n",
    "- **Recurrent state**: Starting from state $i$, the chain returns to $i$ with probability 1\n",
    "  - Guaranteed to revisit infinitely often\n",
    "- **Transient state**: Starting from state $i$, there's a chance of never returning\n",
    "  - Visited only finitely many times (eventually leaves forever)\n",
    "\n",
    "**Mathematical Test:**\n",
    "State $i$ is recurrent if and only if:\n",
    "$$\\sum_{n=1}^{\\infty} P^n_{ii} = \\infty$$\n",
    "\n",
    "**Key Properties:**\n",
    "- In a finite irreducible chain, all states are recurrent\n",
    "- Transient states lead to recurrent states\n",
    "- If state $i$ is recurrent and communicates with $j$, then $j$ is also recurrent\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Random walk on integers: All states are recurrent (1D)\n",
    "Random walk on 2D grid: All states are recurrent\n",
    "Random walk on 3D grid: All states are transient!\n",
    "```\n",
    "\n",
    "**Practical importance:**\n",
    "- Recurrent states form the \"core\" of the chain\n",
    "- Transient states are temporary (system eventually settles in recurrent states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d44f041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_states_transient_recurrent(P, max_steps=1000, tol=1e-10):\n",
    "    \"\"\"\n",
    "    Classify states as transient or recurrent using finite approximation.\n",
    "    \n",
    "    For finite chains: A state is recurrent if starting from it, you can return to it.\n",
    "    More precisely, we check if the sum of return probabilities diverges.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like\n",
    "        Transition matrix\n",
    "    max_steps : int, default=1000\n",
    "        Maximum number of steps to check\n",
    "    tol : float, default=1e-10\n",
    "        Tolerance for numerical comparisons\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    classification : dict\n",
    "        Dictionary with 'recurrent' and 'transient' state sets\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    n = P.shape[0]\n",
    "    \n",
    "    recurrent = set()\n",
    "    transient = set()\n",
    "    \n",
    "    # For each state, compute sum of P^n[i,i]\n",
    "    P_power = P.copy()\n",
    "    cumulative_return_prob = np.diag(P).copy()\n",
    "    \n",
    "    for step in range(2, max_steps + 1):\n",
    "        P_power = P_power @ P\n",
    "        cumulative_return_prob += np.diag(P_power)\n",
    "    \n",
    "    # In finite chains, we use a heuristic:\n",
    "    # If sum is very large, state is recurrent\n",
    "    # More precisely: check if state can reach itself\n",
    "    for i in range(n):\n",
    "        # Check if i can return to itself\n",
    "        can_return = cumulative_return_prob[i] > tol\n",
    "        \n",
    "        # For finite chains: state is recurrent if it's in a closed communicating class\n",
    "        # Simple heuristic: if cumulative return probability is high, it's recurrent\n",
    "        if cumulative_return_prob[i] > max_steps * 0.01:  # Heuristic threshold\n",
    "            recurrent.add(i)\n",
    "        else:\n",
    "            transient.add(i)\n",
    "    \n",
    "    return {\n",
    "        \"recurrent\": recurrent,\n",
    "        \"transient\": transient,\n",
    "        \"cumulative_return_probs\": cumulative_return_prob\n",
    "    }\n",
    "\n",
    "def find_absorbing_states(P, tol=1e-10):\n",
    "    \"\"\"\n",
    "    Find absorbing states in a Markov chain.\n",
    "    \n",
    "    An absorbing state is a state that, once entered, cannot be left (P[i,i] = 1).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like\n",
    "        Transition matrix\n",
    "    tol : float, default=1e-10\n",
    "        Tolerance for checking P[i,i] = 1\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    absorbing_states : set\n",
    "        Set of absorbing state indices\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    n = P.shape[0]\n",
    "    \n",
    "    absorbing = set()\n",
    "    for i in range(n):\n",
    "        if abs(P[i, i] - 1.0) < tol:\n",
    "            absorbing.add(i)\n",
    "    \n",
    "    return absorbing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de623e7",
   "metadata": {},
   "source": [
    "### Absorbing States and Absorbing Chains\n",
    "\n",
    "**What is this?**\n",
    "An **absorbing state** is a state you can never leave once you enter it.\n",
    "\n",
    "**Mathematical definition:** State $i$ is absorbing if $P_{ii} = 1$ (and $P_{ij} = 0$ for $j \\neq i$)\n",
    "\n",
    "**Variables:**\n",
    "- $P_{ii}$ = Probability of staying in state $i$ (equals 1 for absorbing state)\n",
    "- $P_{ij}$ = Probability of transitioning from state $i$ to state $j$ (equals 0 for absorbing state when $j \\neq i$)\n",
    "- $i$ = State being checked for absorption property\n",
    "- $j$ = Any other state\n",
    "\n",
    "**Absorbing Chain:**\n",
    "A chain with:\n",
    "1. At least one absorbing state\n",
    "2. From every state, you can reach some absorbing state\n",
    "\n",
    "**Standard Form:**\n",
    "Absorbing chains can be written as:\n",
    "$$P = \\begin{pmatrix} Q & R \\\\ 0 & I \\end{pmatrix}$$\n",
    "\n",
    "**Standard Form Variables:**\n",
    "- $Q$ = Transitions between transient states (top-left block)\n",
    "- $R$ = Transitions from transient to absorbing states (top-right block)\n",
    "- $0$ = Zero matrix (absorbing states can't transition back to transient)\n",
    "- $I$ = Identity matrix (absorbing states stay put)\n",
    "\n",
    "**Fundamental Matrix:** $N = (I - Q)^{-1}$\n",
    "- $N_{ij}$ = Expected number of times in transient state $j$ starting from transient state $i$\n",
    "- $I$ = Identity matrix of size (n_transient × n_transient)\n",
    "\n",
    "**Absorption Probabilities:** $B = NR$\n",
    "- $B_{ij}$ = Probability of absorbing into absorbing state $j$ starting from transient state $i$\n",
    "\n",
    "**Examples:**\n",
    "- Gambler's ruin: Broke ($0) and Rich (target) are absorbing\n",
    "- Random walk with barriers\n",
    "- Customer churn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606dc6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_absorbing_chain(P, absorbing_states=None, tol=1e-10):\n",
    "    \"\"\"\n",
    "    Analyze an absorbing Markov chain.\n",
    "    \n",
    "    Computes fundamental matrix and absorption probabilities.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like\n",
    "        Transition matrix\n",
    "    absorbing_states : set or list, optional\n",
    "        Indices of absorbing states. If None, automatically detected.\n",
    "    tol : float, default=1e-10\n",
    "        Tolerance for numerical operations\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    result : dict\n",
    "        Dictionary containing:\n",
    "        - 'absorbing_states': Set of absorbing state indices\n",
    "        - 'transient_states': List of transient state indices\n",
    "        - 'N': Fundamental matrix (expected time in each transient state)\n",
    "        - 'B': Absorption probability matrix\n",
    "        - 'expected_steps': Expected steps to absorption from each transient state\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    n = P.shape[0]\n",
    "    \n",
    "    # Find absorbing states if not provided\n",
    "    if absorbing_states is None:\n",
    "        absorbing_states = find_absorbing_states(P, tol)\n",
    "    \n",
    "    absorbing_states = set(absorbing_states)\n",
    "    transient_states = [i for i in range(n) if i not in absorbing_states]\n",
    "    \n",
    "    if len(absorbing_states) == 0:\n",
    "        return {\n",
    "            \"absorbing_states\": set(),\n",
    "            \"transient_states\": list(range(n)),\n",
    "            \"N\": None,\n",
    "            \"B\": None,\n",
    "            \"expected_steps\": None,\n",
    "            \"message\": \"No absorbing states found\"\n",
    "        }\n",
    "    \n",
    "    if len(transient_states) == 0:\n",
    "        return {\n",
    "            \"absorbing_states\": absorbing_states,\n",
    "            \"transient_states\": [],\n",
    "            \"N\": None,\n",
    "            \"B\": None,\n",
    "            \"expected_steps\": None,\n",
    "            \"message\": \"All states are absorbing\"\n",
    "        }\n",
    "    \n",
    "    # Reorder states: transient first, then absorbing\n",
    "    absorbing_list = sorted(absorbing_states)\n",
    "    state_order = transient_states + absorbing_list\n",
    "    \n",
    "    # Reorder transition matrix\n",
    "    P_reordered = P[np.ix_(state_order, state_order)]\n",
    "    \n",
    "    # Extract Q (transient to transient) and R (transient to absorbing)\n",
    "    n_transient = len(transient_states)\n",
    "    Q = P_reordered[:n_transient, :n_transient]\n",
    "    R = P_reordered[:n_transient, n_transient:]\n",
    "    \n",
    "    # Compute fundamental matrix N = (I - Q)^(-1)\n",
    "    I = np.eye(n_transient)\n",
    "    try:\n",
    "        N = np.linalg.inv(I - Q)\n",
    "    except np.linalg.LinAlgError:\n",
    "        return {\n",
    "            \"absorbing_states\": absorbing_states,\n",
    "            \"transient_states\": transient_states,\n",
    "            \"N\": None,\n",
    "            \"B\": None,\n",
    "            \"expected_steps\": None,\n",
    "            \"message\": \"Cannot compute fundamental matrix (I-Q is singular)\"\n",
    "        }\n",
    "    \n",
    "    # Compute absorption probabilities B = NR\n",
    "    B = N @ R\n",
    "    \n",
    "    # Expected number of steps to absorption\n",
    "    expected_steps = N @ np.ones(n_transient)\n",
    "    \n",
    "    return {\n",
    "        \"absorbing_states\": absorbing_states,\n",
    "        \"transient_states\": transient_states,\n",
    "        \"N\": N,  # Fundamental matrix\n",
    "        \"B\": B,  # Absorption probabilities\n",
    "        \"expected_steps\": expected_steps,\n",
    "        \"Q\": Q,\n",
    "        \"R\": R\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeaf3c7",
   "metadata": {},
   "source": [
    "### Periodicity Check\n",
    "\n",
    "**What is this?**\n",
    "A chain is **aperiodic** if states don't have cyclical return patterns. Periodicity matters for convergence.\n",
    "\n",
    "**Period of a state:** $d = \\gcd\\{n : P^n_{ii} > 0\\}$\n",
    "\n",
    "**Variables:**\n",
    "- $d$ = Period of a state (the greatest common divisor)\n",
    "- $n$ = Number of steps\n",
    "- $P^n_{ii}$ = Probability of returning to state $i$ after exactly $n$ steps\n",
    "- $\\{n : P^n_{ii} > 0\\}$ = Set of all step counts where return is possible\n",
    "- $\\gcd$ = Greatest common divisor function\n",
    "- $i$ = State being analyzed for periodicity\n",
    "\n",
    "- Period 1 = Aperiodic (can return at any time)\n",
    "- Period > 1 = Periodic (returns only at multiples of d)\n",
    "\n",
    "**Why it matters:**\n",
    "- Aperiodic + Irreducible → Convergence to unique stationary distribution\n",
    "- Periodic chains oscillate (don't converge to stationary distribution)\n",
    "\n",
    "**Making chain aperiodic:**\n",
    "Add self-loops (e.g., set $P_{ii} > 0$ for some state)\n",
    "\n",
    "**Example:**\n",
    "- [0→1→0]: Period 2 (alternates)\n",
    "- [0→0, 0→1, 1→0]: Period 1 (aperiodic, has self-loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25a2683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def gcd_list(numbers):\n",
    "    \"\"\"\n",
    "    Compute GCD of a list of numbers.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    numbers : list of int\n",
    "        List of integers to compute GCD for\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    int : Greatest common divisor of all numbers in the list\n",
    "    \"\"\"\n",
    "    result = numbers[0]\n",
    "    for num in numbers[1:]:\n",
    "        result = math.gcd(result, num)\n",
    "    return result\n",
    "\n",
    "def state_period(P, state):\n",
    "    \"\"\"\n",
    "    Compute the period of a specific state in a Markov chain.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like, shape (n_states, n_states)\n",
    "        Transition probability matrix\n",
    "    state : int\n",
    "        State index to check period for\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    period : int or float\n",
    "        Period of the state (1 = aperiodic, >1 = periodic, inf = never returns)\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    n = P.shape[0]\n",
    "    max_steps = 100  # Check up to this many steps\n",
    "    \n",
    "    # Find all n where P^n[state, state] > 0\n",
    "    return_times = []\n",
    "    P_power = P.copy()\n",
    "    \n",
    "    for step in range(1, max_steps + 1):\n",
    "        if P_power[state, state] > 1e-10:\n",
    "            return_times.append(step)\n",
    "        P_power = P_power @ P\n",
    "    \n",
    "    if len(return_times) == 0:\n",
    "        return float('inf')  # Never returns\n",
    "    \n",
    "    return gcd_list(return_times)\n",
    "\n",
    "def is_aperiodic(P):\n",
    "    \"\"\"\n",
    "    Check if chain is aperiodic (all states have period 1).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like, shape (n_states, n_states)\n",
    "        Transition probability matrix\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    bool : True if all states are aperiodic, False otherwise\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    n = P.shape[0]\n",
    "    \n",
    "    for state in range(n):\n",
    "        if state_period(P, state) > 1:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def all_state_periods(P):\n",
    "    \"\"\"\n",
    "    Compute the period for each state in a Markov chain.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like, shape (n_states, n_states)\n",
    "        Transition probability matrix\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    periods : array, shape (n_states,)\n",
    "        Array where periods[i] is the period of state i\n",
    "        (period = 1 means aperiodic, period = inf means never returns)\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    n = P.shape[0]\n",
    "    \n",
    "    periods = np.zeros(n)\n",
    "    for state in range(n):\n",
    "        periods[state] = state_period(P, state)\n",
    "    \n",
    "    return periods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4489dd71",
   "metadata": {},
   "source": [
    "### Stationary Distribution\n",
    "\n",
    "**What is this?**\n",
    "The stationary (or invariant) distribution is a probability distribution over states that remains unchanged as the Markov chain evolves. Once the chain reaches this distribution, it stays in it forever. This represents the equilibrium behavior of the system.\n",
    "\n",
    "**Mathematical Definition:** \n",
    "\n",
    "A probability distribution $\\pi = [\\pi_1, \\pi_2, \\ldots, \\pi_n]$ is stationary if:\n",
    "\n",
    "$$\\pi^T P = \\pi^T$$\n",
    "\n",
    "or equivalently:\n",
    "\n",
    "$$\\sum_{j=1}^{n} \\pi_j P_{ji} = \\pi_i \\quad \\text{for all } i$$\n",
    "\n",
    "where:\n",
    "- $\\pi$ is a row vector of probabilities\n",
    "- $P$ is the transition matrix\n",
    "- $\\pi_i \\geq 0$ for all $i$ and $\\sum_{i=1}^{n} \\pi_i = 1$\n",
    "\n",
    "**Key Properties:**\n",
    "\n",
    "1. **Eigenvector Interpretation:** $\\pi$ is a left eigenvector of $P$ with eigenvalue 1\n",
    "   - Equivalently, $\\pi$ is a right eigenvector of $P^T$ with eigenvalue 1\n",
    "   \n",
    "2. **Uniqueness:** For irreducible, aperiodic chains, the stationary distribution is unique\n",
    "\n",
    "3. **Convergence:** $\\lim_{n \\to \\infty} P^n = \\begin{bmatrix} \\pi^T \\\\ \\pi^T \\\\ \\vdots \\\\ \\pi^T \\end{bmatrix}$ (each row converges to $\\pi^T$)\n",
    "\n",
    "**How to Find It:**\n",
    "\n",
    "**Method 1: Eigenvalue Approach**\n",
    "1. Find eigenvector $v$ of $P^T$ corresponding to eigenvalue $\\lambda = 1$\n",
    "2. Normalize: $\\pi = \\frac{v}{\\sum_i v_i}$ so that $\\sum_i \\pi_i = 1$\n",
    "\n",
    "**Method 2: System of Linear Equations**\n",
    "1. Solve $\\pi^T P = \\pi^T$ which gives $(n-1)$ independent equations\n",
    "2. Add constraint $\\sum_{i=1}^{n} \\pi_i = 1$\n",
    "3. Solve the resulting system\n",
    "\n",
    "**Method 3: Power Method**\n",
    "- Compute $P^n$ for large $n$; any row gives $\\pi^T$\n",
    "\n",
    "**Interpretation:**\n",
    "- $\\pi_i$ = Long-run proportion of time the chain spends in state $i$\n",
    "- $\\pi_i$ = Limiting probability of being in state $i$ after many steps\n",
    "- After running the chain long enough, state probabilities converge to $\\pi$ regardless of initial state\n",
    "- For irreducible, aperiodic chains, this convergence is guaranteed\n",
    "\n",
    "**Detailed Example:** \n",
    "\n",
    "Weather Model with states $\\{$Sunny, Rainy$\\}$ and transition matrix:\n",
    "\n",
    "$$P = \\begin{bmatrix} 0.8 & 0.2 \\\\ 0.4 & 0.6 \\end{bmatrix}$$\n",
    "\n",
    "To find $\\pi = [\\pi_S, \\pi_R]$, solve:\n",
    "- $0.8\\pi_S + 0.4\\pi_R = \\pi_S$ → $0.2\\pi_S = 0.4\\pi_R$ → $\\pi_S = 2\\pi_R$\n",
    "- $\\pi_S + \\pi_R = 1$\n",
    "\n",
    "Solution: $\\pi = [0.667, 0.333]$ or $[\\frac{2}{3}, \\frac{1}{3}]$\n",
    "\n",
    "**Interpretation:** In the long run, expect 66.7% sunny days and 33.3% rainy days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a7a5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import eig\n",
    "\n",
    "\n",
    "def has_stationary_distribution(P):\n",
    "    \"\"\"\n",
    "    Check if a Markov chain has a unique stationary distribution.\n",
    "    \n",
    "    A finite Markov chain has a unique stationary distribution if and only if\n",
    "    it is irreducible and aperiodic (i.e., ergodic).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like, shape (n_states, n_states)\n",
    "        Transition probability matrix\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    has_stationary : bool\n",
    "        True if chain has a unique stationary distribution\n",
    "    reason : str\n",
    "        Explanation of why the chain does or doesn't have stationary distribution\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    \n",
    "    # Check if it's a valid transition matrix\n",
    "    if not is_transition_matrix(P):\n",
    "        return False, \"Not a valid transition matrix\"\n",
    "    \n",
    "    # Check irreducibility\n",
    "    if not is_irreducible(P):\n",
    "        return False, \"Chain is not irreducible (some states are not reachable from others)\"\n",
    "    \n",
    "    # Check aperiodicity\n",
    "    if not is_aperiodic(P):\n",
    "        return False, \"Chain is not aperiodic (has periodic states)\"\n",
    "    \n",
    "    return True, \"Chain is ergodic (irreducible and aperiodic) - has unique stationary distribution\"\n",
    "\n",
    "def stationary_distribution(P):\n",
    "    \"\"\"\n",
    "    Compute the stationary distribution of a Markov chain.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like, shape (n_states, n_states)\n",
    "        Transition probability matrix\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pi : array, shape (n_states,)\n",
    "        Stationary distribution where pi[i] is the long-run probability \n",
    "        of being in state i. Satisfies: pi^T P = pi^T and sum(pi) = 1\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, dtype=float)\n",
    "    w, v = eig(P.T)\n",
    "    k = np.argmin(np.abs(w - 1))\n",
    "    pi = np.real(v[:, k])\n",
    "    pi = np.abs(pi)  # Take absolute value instead of maximum with 0\n",
    "    pi = pi / pi.sum()\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2650db",
   "metadata": {},
   "source": [
    "### Reversibility and Detailed Balance\n",
    "\n",
    "**What is this?**\n",
    "A Markov chain is **reversible** if the forward and backward processes are statistically identical. This is formalized through the **detailed balance condition**.\n",
    "\n",
    "**Detailed Balance Condition:**\n",
    "A chain with transition matrix $P$ and stationary distribution $\\pi$ satisfies detailed balance if:\n",
    "$$\\pi_i P_{ij} = \\pi_j P_{ji} \\quad \\text{for all states } i, j$$\n",
    "\n",
    "**Variables:**\n",
    "- $\\pi_i$ = Stationary probability of state $i$\n",
    "- $\\pi_j$ = Stationary probability of state $j$\n",
    "- $P_{ij}$ = Transition probability from state $i$ to state $j$\n",
    "- $P_{ji}$ = Transition probability from state $j$ to state $i$ (reverse direction)\n",
    "- $i, j$ = State indices\n",
    "\n",
    "**Interpretation:**\n",
    "- $\\pi_i P_{ij}$ = Long-run rate of transitions from $i$ to $j$\n",
    "- $\\pi_j P_{ji}$ = Long-run rate of transitions from $j$ to $i$\n",
    "- Detailed balance means these rates are equal (equilibrium at individual transition level)\n",
    "\n",
    "**Why it matters:**\n",
    "- **Checking stationary distribution**: If detailed balance holds, $\\pi$ is stationary\n",
    "- **MCMC algorithms**: Many samplers (Metropolis-Hastings) rely on reversibility\n",
    "- **Symmetric chains**: If $P = P^T$ (symmetric), the chain is reversible with $\\pi = \\text{uniform}$\n",
    "\n",
    "**Variables in Context:**\n",
    "- $P^T$ = Transpose of transition matrix $P$\n",
    "- uniform = Uniform distribution where all states have equal probability\n",
    "\n",
    "**Key Properties:**\n",
    "- Reversible + Irreducible → Unique stationary distribution\n",
    "- Not all chains are reversible (e.g., deterministic cycles)\n",
    "- Reversibility is sufficient but not necessary for stationarity\n",
    "\n",
    "**Example:**\n",
    "Random walk on undirected graph is reversible; directed cycle is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c7b9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_detailed_balance(P, pi, tol=1e-8):\n",
    "    \"\"\"\n",
    "    Check if a Markov chain satisfies detailed balance condition.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like\n",
    "        Transition matrix\n",
    "    pi : array-like\n",
    "        Stationary distribution (or candidate stationary distribution)\n",
    "    tol : float, default=1e-8\n",
    "        Numerical tolerance for equality check\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    is_reversible : bool\n",
    "        True if detailed balance holds\n",
    "    max_violation : float\n",
    "        Maximum absolute difference |pi_i * P_ij - pi_j * P_ji|\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    pi = np.asarray(pi, float)\n",
    "    n = P.shape[0]\n",
    "    \n",
    "    # Check detailed balance: pi[i] * P[i,j] = pi[j] * P[j,i] for all i,j\n",
    "    max_violation = 0.0\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            forward_rate = pi[i] * P[i, j]\n",
    "            backward_rate = pi[j] * P[j, i]\n",
    "            violation = abs(forward_rate - backward_rate)\n",
    "            max_violation = max(max_violation, violation)\n",
    "    \n",
    "    is_reversible = (max_violation < tol)\n",
    "    \n",
    "    return is_reversible, float(max_violation)\n",
    "\n",
    "def is_reversible_chain(P, pi=None, tol=1e-8):\n",
    "    \"\"\"\n",
    "    Check if a Markov chain is reversible.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like\n",
    "        Transition matrix\n",
    "    pi : array-like, optional\n",
    "        Stationary distribution. If None, computes it automatically\n",
    "    tol : float, default=1e-8\n",
    "        Numerical tolerance\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    reversible : bool\n",
    "        True if chain is reversible\n",
    "    message : str\n",
    "        Explanation\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    \n",
    "    # Check if it's a valid transition matrix\n",
    "    if not is_transition_matrix(P):\n",
    "        return False, \"Not a valid transition matrix\"\n",
    "    \n",
    "    # Get stationary distribution if not provided\n",
    "    if pi is None:\n",
    "        # Check if chain has unique stationary distribution\n",
    "        has_stat, reason = has_stationary_distribution(P)\n",
    "        if not has_stat:\n",
    "            return False, f\"Cannot check reversibility: {reason}\"\n",
    "        pi = stationary_distribution(P)\n",
    "    \n",
    "    # Check detailed balance\n",
    "    is_rev, max_viol = check_detailed_balance(P, pi, tol)\n",
    "    \n",
    "    if is_rev:\n",
    "        return True, f\"Chain is reversible (max violation: {max_viol:.2e})\"\n",
    "    else:\n",
    "        return False, f\"Chain is not reversible (max violation: {max_viol:.2e})\"\n",
    "\n",
    "def check_symmetry(P, tol=1e-8):\n",
    "    \"\"\"\n",
    "    Check if transition matrix is symmetric (P = P^T).\n",
    "    Symmetric chains are always reversible with uniform stationary distribution.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like\n",
    "        Transition matrix\n",
    "    tol : float, default=1e-8\n",
    "        Numerical tolerance\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    is_symmetric : bool\n",
    "        True if P = P^T\n",
    "    max_diff : float\n",
    "        Maximum absolute difference |P_ij - P_ji|\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    diff = P - P.T\n",
    "    max_diff = float(np.max(np.abs(diff)))\n",
    "    is_symmetric = (max_diff < tol)\n",
    "    \n",
    "    return is_symmetric, max_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22df21e4",
   "metadata": {},
   "source": [
    "### Mean Return Time\n",
    "\n",
    "**What is this?**\n",
    "The expected number of steps to return to a state, starting from that state.\n",
    "\n",
    "**Mathematical definition:** \n",
    "For state $i$: $m_i = E[\\text{time to return to } i | X_0 = i]$\n",
    "\n",
    "**Variables:**\n",
    "- $m_i$ = Mean return time for state $i$ (expected number of steps)\n",
    "- $E[\\cdot]$ = Expected value (average)\n",
    "- $X_0$ = Initial state at time 0\n",
    "- $i$ = The state we're returning to\n",
    "\n",
    "**Relationship to Stationary Distribution:**\n",
    "For an irreducible, aperiodic chain:\n",
    "$$\\pi_i = \\frac{1}{m_i}$$\n",
    "\n",
    "**Variables in Relationship:**\n",
    "- $\\pi_i$ = Stationary probability of state $i$ (long-run proportion of time in state $i$)\n",
    "- $m_i$ = Mean return time to state $i$\n",
    "\n",
    "**Interpretation:**\n",
    "- $m_i = 10$ means on average, the chain returns to state $i$ every 10 steps\n",
    "- $\\pi_i = 0.1$ means state $i$ is visited 10% of the time\n",
    "- States with higher stationary probability have shorter return times\n",
    "\n",
    "**Why it matters:**\n",
    "- Understanding how \"frequently\" states are visited\n",
    "- Quality control: How often does the system return to a desired state?\n",
    "- Queueing: Average time between customer arrivals\n",
    "\n",
    "**Example:**\n",
    "Weather with $\\pi_{\\text{sunny}} = 0.7$:\n",
    "- Mean return time to sunny = $1/0.7 \\approx 1.43$ days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_return_times(P, pi=None):\n",
    "    \"\"\"\n",
    "    Compute mean return time for each state.\n",
    "    \n",
    "    For an ergodic chain, mean return time m_i = 1 / pi_i.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like\n",
    "        Transition matrix\n",
    "    pi : array-like, optional\n",
    "        Stationary distribution. If None, computes it automatically.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    return_times : array\n",
    "        Mean return time for each state\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    \n",
    "    # Get stationary distribution\n",
    "    if pi is None:\n",
    "        has_stat, reason = has_stationary_distribution(P)\n",
    "        if not has_stat:\n",
    "            raise ValueError(f\"Cannot compute return times: {reason}\")\n",
    "        pi = stationary_distribution(P)\n",
    "    \n",
    "    pi = np.asarray(pi, float)\n",
    "    \n",
    "    # Mean return time = 1 / pi_i (for ergodic chains)\n",
    "    return_times = np.zeros(len(pi))\n",
    "    for i in range(len(pi)):\n",
    "        if pi[i] > 1e-10:\n",
    "            return_times[i] = 1.0 / pi[i]\n",
    "        else:\n",
    "            return_times[i] = np.inf  # State not visited in stationary distribution\n",
    "    \n",
    "    return return_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c46eb97",
   "metadata": {},
   "source": [
    "### Reducing and Reversing Markov Chains\n",
    "\n",
    "**What is this?**\n",
    "Techniques for simplifying Markov chains or constructing the time-reversed process.\n",
    "\n",
    "**1. Canonical Form (Reducing to Standard Form)**\n",
    "\n",
    "For chains with both transient and recurrent states, reorder the transition matrix into canonical form:\n",
    "$$P = \\begin{pmatrix} Q & R \\\\ 0 & S \\end{pmatrix}$$\n",
    "\n",
    "Where:\n",
    "- $Q$: Transitions among transient states\n",
    "- $R$: Transitions from transient to recurrent\n",
    "- $S$: Transitions among recurrent states\n",
    "- $0$: Recurrent states can't return to transient\n",
    "\n",
    "**2. Lumping States (State Aggregation)**\n",
    "\n",
    "Combine states into groups if they behave similarly:\n",
    "- **Lumpable**: If for all states in a group, transition probabilities to other groups are identical\n",
    "- Reduces state space complexity\n",
    "- Preserves Markov property if done correctly\n",
    "\n",
    "**3. Time-Reversed Chain**\n",
    "\n",
    "The **reversed chain** has transition matrix $\\tilde{P}$ where:\n",
    "$$\\tilde{P}_{ij} = \\frac{\\pi_j P_{ji}}{\\pi_i}$$\n",
    "\n",
    "**Properties:**\n",
    "- If original chain has stationary distribution $\\pi$, reversed chain has the same $\\pi$\n",
    "- Chain is reversible ⟺ Original and reversed chains are identical\n",
    "- Used in MCMC diagnostics and theoretical analysis\n",
    "\n",
    "**When to use:**\n",
    "- **Canonical form**: Analyzing chains with absorbing states\n",
    "- **Lumping**: Simplifying large state spaces\n",
    "- **Reversing**: Testing reversibility, understanding detailed balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ca3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canonical_form(P, transient_states=None):\n",
    "    \"\"\"\n",
    "    Convert transition matrix to canonical form.\n",
    "    \n",
    "    Reorders states so transient states come first, then recurrent states.\n",
    "    Results in block matrix: [[Q, R], [0, S]]\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like\n",
    "        Transition matrix\n",
    "    transient_states : list, optional\n",
    "        List of transient state indices. If None, automatically detected.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    P_canonical : array\n",
    "        Reordered transition matrix in canonical form\n",
    "    state_order : array\n",
    "        New ordering of states\n",
    "    partition : dict\n",
    "        Dictionary with 'transient' and 'recurrent' state indices in new order\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    n = P.shape[0]\n",
    "    \n",
    "    # Detect transient and recurrent states if not provided\n",
    "    if transient_states is None:\n",
    "        classification = classify_states_transient_recurrent(P)\n",
    "        transient_states = list(classification['transient'])\n",
    "    \n",
    "    transient_states = list(transient_states)\n",
    "    recurrent_states = [i for i in range(n) if i not in transient_states]\n",
    "    \n",
    "    # Create new state ordering: transient first, then recurrent\n",
    "    state_order = transient_states + recurrent_states\n",
    "    \n",
    "    # Reorder transition matrix\n",
    "    P_canonical = P[np.ix_(state_order, state_order)]\n",
    "    \n",
    "    n_transient = len(transient_states)\n",
    "    \n",
    "    return P_canonical, np.array(state_order), {\n",
    "        'transient': list(range(n_transient)),\n",
    "        'recurrent': list(range(n_transient, n)),\n",
    "        'n_transient': n_transient,\n",
    "        'n_recurrent': len(recurrent_states)\n",
    "    }\n",
    "\n",
    "def reverse_chain(P, pi=None):\n",
    "    \"\"\"\n",
    "    Compute the time-reversed Markov chain.\n",
    "    \n",
    "    The reversed chain has transition matrix P_tilde where:\n",
    "    P_tilde[i,j] = (pi[j] * P[j,i]) / pi[i]\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like\n",
    "        Transition matrix\n",
    "    pi : array-like, optional\n",
    "        Stationary distribution. If None, computes it automatically.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    P_reversed : array\n",
    "        Transition matrix of reversed chain\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    n = P.shape[0]\n",
    "    \n",
    "    # Get stationary distribution\n",
    "    if pi is None:\n",
    "        has_stat, reason = has_stationary_distribution(P)\n",
    "        if not has_stat:\n",
    "            raise ValueError(f\"Cannot compute reversed chain: {reason}\")\n",
    "        pi = stationary_distribution(P)\n",
    "    \n",
    "    pi = np.asarray(pi, float)\n",
    "    \n",
    "    # Compute reversed transition matrix\n",
    "    P_reversed = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if pi[i] > 1e-10:\n",
    "                P_reversed[i, j] = (pi[j] * P[j, i]) / pi[i]\n",
    "            else:\n",
    "                P_reversed[i, j] = 0.0\n",
    "    \n",
    "    return P_reversed\n",
    "\n",
    "def test_lumpability(P, partition, tol=1e-8):\n",
    "    \"\"\"\n",
    "    Test if a partition of states is lumpable.\n",
    "    \n",
    "    A partition is lumpable if for each group A in the partition,\n",
    "    all states in A have the same transition probability to each other group B.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like\n",
    "        Transition matrix\n",
    "    partition : list of lists\n",
    "        Each element is a list of states that form a group\n",
    "    tol : float, default=1e-8\n",
    "        Numerical tolerance\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    is_lumpable : bool\n",
    "        True if partition is lumpable\n",
    "    lumped_P : array or None\n",
    "        Transition matrix on lumped state space (if lumpable)\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    k = len(partition)  # Number of groups\n",
    "    \n",
    "    # Check lumpability condition\n",
    "    lumped_P = np.zeros((k, k))\n",
    "    \n",
    "    for a, group_a in enumerate(partition):\n",
    "        for b, group_b in enumerate(partition):\n",
    "            # Compute transition probability from group_a to group_b\n",
    "            # Should be same for all states in group_a\n",
    "            probs = []\n",
    "            for i in group_a:\n",
    "                prob_i_to_b = sum(P[i, j] for j in group_b)\n",
    "                probs.append(prob_i_to_b)\n",
    "            \n",
    "            # Check if all states in group_a have same transition prob to group_b\n",
    "            if len(probs) > 0:\n",
    "                avg_prob = np.mean(probs)\n",
    "                if not all(abs(p - avg_prob) < tol for p in probs):\n",
    "                    return False, None\n",
    "                lumped_P[a, b] = avg_prob\n",
    "    \n",
    "    return True, lumped_P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f556dcf1",
   "metadata": {},
   "source": [
    "### Expected Time to Hit a Target Set\n",
    "\n",
    "**What is this?**\n",
    "Calculates the expected number of steps to reach a target state (or set of states) from each starting state.\n",
    "\n",
    "**Mathematical formulation:**\n",
    "For state $i$ not in target: $h_i = 1 + \\sum_j P_{ij} h_j$\n",
    "For state $i$ in target: $h_i = 0$\n",
    "\n",
    "**Variables:**\n",
    "- $h_i$ = Expected hitting time starting from state $i$ (average number of steps to reach target)\n",
    "- $P_{ij}$ = Transition probability from state $i$ to state $j$\n",
    "- $j$ = Index for summing over all possible next states\n",
    "- $i$ = Current/starting state\n",
    "- 1 = One step taken before transitioning to next state\n",
    "- Target = Set of goal states to reach\n",
    "\n",
    "**How it works:**\n",
    "Solves a system of linear equations to find expected hitting times.\n",
    "\n",
    "**Interpretation:**\n",
    "- $h_i$ = Average number of steps to reach target starting from state $i$\n",
    "- If target is never reachable from $i$, the value will be infinite\n",
    "\n",
    "**Example use case:**\n",
    "- Customer journey: Expected time until purchase\n",
    "- Game: Expected moves until winning/losing\n",
    "- Network: Expected hops to reach destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a108c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_hitting_times(P, target_states):\n",
    "    \"\"\"\n",
    "    Calculate expected number of steps to reach a target set from each state.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like, shape (n_states, n_states)\n",
    "        Transition probability matrix\n",
    "    target_states : list or set of int\n",
    "        Indices of target states to reach\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    hitting_times : array, shape (n_states,)\n",
    "        Expected number of steps to reach target_states from each state.\n",
    "        For states in target_states, value is 0.\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    n = P.shape[0]\n",
    "    target = set(target_states)\n",
    "\n",
    "    A = np.zeros((n, n), float)\n",
    "    b = np.zeros(n, float)\n",
    "\n",
    "    for i in range(n):\n",
    "        if i in target:\n",
    "            A[i, i] = 1.0\n",
    "            b[i] = 0.0\n",
    "        else:\n",
    "            A[i, i] = 1.0\n",
    "            A[i, :] -= P[i, :]\n",
    "            b[i] = 1.0\n",
    "\n",
    "    return np.linalg.solve(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92fd4af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25., 20.,  0.,  0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_hitting_times(Mat_A, target_states=[2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fcefce",
   "metadata": {},
   "source": [
    "### Convergence By Powering Matrix (K Steps)\n",
    "\n",
    "**What is this?**\n",
    "Computes the k-step transition probabilities by raising the transition matrix to the k-th power.\n",
    "\n",
    "**Formula:** $P^{(k)} = P^k$\n",
    "\n",
    "**Variables:**\n",
    "- $P^{(k)}$ = k-step transition matrix\n",
    "- $P$ = One-step transition matrix\n",
    "- $k$ = Number of steps (exponent)\n",
    "\n",
    "**Interpretation:**\n",
    "- $P^k_{ij}$ = Probability of being in state $j$ after exactly $k$ steps starting from state $i$\n",
    "- As $k \\to \\infty$, rows converge to the stationary distribution (for irreducible, aperiodic chains)\n",
    "\n",
    "**Variables in Interpretation:**\n",
    "- $i$ = Starting state (row index)\n",
    "- $j$ = Ending state (column index)\n",
    "- $\\infty$ = Infinity (limit as k approaches infinity)\n",
    "\n",
    "**Use cases:**\n",
    "- Predict state distribution after k time steps\n",
    "- Check convergence to stationary distribution\n",
    "- Analyze mixing time\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "P2 = n_step_transition(P, 2)  # 2-step transitions\n",
    "P100 = n_step_transition(P, 100)  # Should be close to stationary\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce229ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_step_transition(P, k):\n",
    "    \"\"\"\n",
    "    Compute k-step transition probability matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like, shape (n_states, n_states)\n",
    "        Transition probability matrix\n",
    "    k : int\n",
    "        Number of steps\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    P_k : array, shape (n_states, n_states)\n",
    "        k-step transition matrix where P_k[i,j] is the probability \n",
    "        of being in state j after exactly k steps starting from state i\n",
    "    \"\"\"\n",
    "    return np.linalg.matrix_power(np.asarray(P, float), k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90099cbe",
   "metadata": {},
   "source": [
    "### Mixing Time\n",
    "\n",
    "**What is this?**\n",
    "The time it takes for a Markov chain to \"forget\" its initial state and get close to the stationary distribution.\n",
    "\n",
    "**Mathematical Definition:**\n",
    "The mixing time $\\tau(\\epsilon)$ is the smallest time $t$ such that:\n",
    "$$\\max_i \\|P^t(i, \\cdot) - \\pi\\|_{TV} \\leq \\epsilon$$\n",
    "\n",
    "Where $\\|\\cdot\\|_{TV}$ is the total variation distance.\n",
    "\n",
    "**Variables:**\n",
    "- $\\tau(\\epsilon)$ = Mixing time for tolerance $\\epsilon$\n",
    "- $\\epsilon$ = Tolerance level (how close to stationary distribution)\n",
    "- $t$ = Number of steps (time)\n",
    "- $i$ = Starting state\n",
    "- $P^t(i, \\cdot)$ = Distribution after $t$ steps starting from state $i$ (row $i$ of $P^t$)\n",
    "- $\\pi$ = Stationary distribution\n",
    "- $\\|\\cdot\\|_{TV}$ = Total variation distance metric\n",
    "- $\\max_i$ = Maximum over all starting states\n",
    "\n",
    "**Total Variation Distance:**\n",
    "$$\\|p - q\\|_{TV} = \\frac{1}{2}\\sum_j |p_j - q_j|$$\n",
    "\n",
    "**Variables in TV Distance:**\n",
    "- $p, q$ = Two probability distributions\n",
    "- $p_j, q_j$ = Probability of state $j$ in distributions $p$ and $q$\n",
    "- $j$ = Index for summing over all states\n",
    "- $|\\cdot|$ = Absolute value\n",
    "\n",
    "**Interpretation:**\n",
    "- After $\\tau(\\epsilon)$ steps, distribution is within $\\epsilon$ of stationary\n",
    "- Common choice: $\\epsilon = 0.25$ (within 25% of stationary)\n",
    "- Smaller mixing time = Faster convergence\n",
    "\n",
    "**Why it matters:**\n",
    "- **MCMC**: How many samples to discard as \"burn-in\"\n",
    "- **Randomized algorithms**: How long until output is \"random enough\"\n",
    "- **Performance**: Fast mixing = Efficient sampling\n",
    "\n",
    "**Factors affecting mixing time:**\n",
    "- Chain connectivity (better connected = faster mixing)\n",
    "- Second largest eigenvalue (closer to 1 = slower mixing)\n",
    "- Bottlenecks in state space\n",
    "\n",
    "**Example:**\n",
    "Well-connected graph: $\\tau \\approx \\log n$\n",
    "Line graph: $\\tau \\approx n^2$ (very slow!)\n",
    "\n",
    "**Variables in Examples:**\n",
    "- $n$ = Number of states\n",
    "- $\\log n$ = Natural logarithm of $n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_variation_distance(p, q):\n",
    "    \"\"\"\n",
    "    Compute total variation distance between two probability distributions.\n",
    "    \n",
    "    TV(p, q) = 0.5 * sum_i |p_i - q_i|\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    p, q : array-like\n",
    "        Probability distributions (should sum to 1)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tv_dist : float\n",
    "        Total variation distance (between 0 and 1)\n",
    "    \"\"\"\n",
    "    p = np.asarray(p, float)\n",
    "    q = np.asarray(q, float)\n",
    "    \n",
    "    return 0.5 * np.sum(np.abs(p - q))\n",
    "\n",
    "def estimate_mixing_time(P, epsilon=0.25, max_steps=10000, pi=None):\n",
    "    \"\"\"\n",
    "    Estimate the mixing time of a Markov chain.\n",
    "    \n",
    "    Mixing time is the smallest t such that ||P^t(i,·) - π||_TV ≤ ε for all i.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like\n",
    "        Transition matrix\n",
    "    epsilon : float, default=0.25\n",
    "        Tolerance for total variation distance\n",
    "    max_steps : int, default=10000\n",
    "        Maximum number of steps to check\n",
    "    pi : array-like, optional\n",
    "        Stationary distribution. If None, computes it automatically.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    mixing_time : int\n",
    "        Estimated mixing time (number of steps)\n",
    "    convergence_info : dict\n",
    "        Information about convergence from each starting state\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    n = P.shape[0]\n",
    "    \n",
    "    # Get stationary distribution\n",
    "    if pi is None:\n",
    "        has_stat, reason = has_stationary_distribution(P)\n",
    "        if not has_stat:\n",
    "            return None, {\"error\": f\"Cannot compute mixing time: {reason}\"}\n",
    "        pi = stationary_distribution(P)\n",
    "    \n",
    "    pi = np.asarray(pi, float)\n",
    "    \n",
    "    # For each starting state, find when it gets close to stationary\n",
    "    convergence_times = np.zeros(n, dtype=int)\n",
    "    \n",
    "    for start_state in range(n):\n",
    "        # Initial distribution (start from state i)\n",
    "        current_dist = np.zeros(n)\n",
    "        current_dist[start_state] = 1.0\n",
    "        \n",
    "        P_power = np.eye(n)\n",
    "        \n",
    "        for t in range(1, max_steps + 1):\n",
    "            P_power = P_power @ P\n",
    "            current_dist = P_power[start_state, :]\n",
    "            \n",
    "            tv_dist = total_variation_distance(current_dist, pi)\n",
    "            \n",
    "            if tv_dist <= epsilon:\n",
    "                convergence_times[start_state] = t\n",
    "                break\n",
    "        else:\n",
    "            # Didn't converge within max_steps\n",
    "            convergence_times[start_state] = max_steps\n",
    "    \n",
    "    mixing_time = int(np.max(convergence_times))\n",
    "    \n",
    "    return mixing_time, {\n",
    "        \"convergence_times\": convergence_times,\n",
    "        \"max_time\": mixing_time,\n",
    "        \"epsilon\": epsilon,\n",
    "        \"all_converged\": (mixing_time < max_steps)\n",
    "    }\n",
    "\n",
    "def spectral_gap_mixing_bound(P, pi=None):\n",
    "    \"\"\"\n",
    "    Estimate mixing time using spectral gap (second largest eigenvalue).\n",
    "    \n",
    "    The spectral gap λ = 1 - |λ_2| where λ_2 is the second largest eigenvalue.\n",
    "    Mixing time is roughly O(1/λ).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like\n",
    "        Transition matrix\n",
    "    pi : array-like, optional\n",
    "        Stationary distribution\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    spectral_gap : float\n",
    "        Gap between largest and second largest eigenvalue\n",
    "    mixing_estimate : float\n",
    "        Rough estimate of mixing time based on spectral gap\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    \n",
    "    # Compute eigenvalues\n",
    "    eigenvalues = np.linalg.eigvals(P)\n",
    "    eigenvalues_sorted = np.sort(np.abs(eigenvalues))[::-1]\n",
    "    \n",
    "    # Spectral gap = 1 - |second largest eigenvalue|\n",
    "    if len(eigenvalues_sorted) > 1:\n",
    "        second_largest = eigenvalues_sorted[1]\n",
    "        spectral_gap = 1.0 - second_largest\n",
    "    else:\n",
    "        spectral_gap = 1.0\n",
    "    \n",
    "    # Mixing time estimate: O(log(n) / spectral_gap)\n",
    "    n = P.shape[0]\n",
    "    if spectral_gap > 1e-10:\n",
    "        mixing_estimate = np.log(n) / spectral_gap\n",
    "    else:\n",
    "        mixing_estimate = np.inf\n",
    "    \n",
    "    return float(spectral_gap), float(mixing_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30657988",
   "metadata": {},
   "source": [
    "### Theoretical Foundations of Markov Chains\n",
    "\n",
    "This section covers the key mathematical theorems that underpin Markov chain theory.\n",
    "\n",
    "---\n",
    "\n",
    "#### Chapman-Kolmogorov Equation\n",
    "\n",
    "**What is this?**\n",
    "The fundamental equation describing how multi-step transition probabilities compose.\n",
    "\n",
    "**Statement:**\n",
    "$$P^{(n+m)}_{ij} = \\sum_{k} P^{(n)}_{ik} P^{(m)}_{kj}$$\n",
    "\n",
    "In matrix form: $P^{(n+m)} = P^{(n)} \\cdot P^{(m)}$\n",
    "\n",
    "**Variables:**\n",
    "- $P^{(n+m)}_{ij}$ = Probability of going from state $i$ to state $j$ in $n+m$ steps\n",
    "- $P^{(n)}_{ik}$ = Probability of going from state $i$ to state $k$ in $n$ steps\n",
    "- $P^{(m)}_{kj}$ = Probability of going from state $k$ to state $j$ in $m$ steps\n",
    "- $i$ = Starting state\n",
    "- $j$ = Ending state\n",
    "- $k$ = Intermediate state (summation index)\n",
    "- $n, m$ = Number of steps (positive integers)\n",
    "- $\\sum_{k}$ = Sum over all possible intermediate states\n",
    "\n",
    "**Interpretation:**\n",
    "- To go from $i$ to $j$ in $n+m$ steps, you must pass through some intermediate state $k$\n",
    "- Probability = sum over all possible intermediate states\n",
    "- This is essentially the Markov property in action\n",
    "\n",
    "**Consequence:**\n",
    "- $P^{(n)} = P^n$ (n-fold matrix multiplication)\n",
    "- Multi-step probabilities can be computed by matrix powers\n",
    "- Foundational for analyzing long-term behavior\n",
    "\n",
    "---\n",
    "\n",
    "#### Limiting Behavior Theorem\n",
    "\n",
    "**What is this?**\n",
    "Conditions under which a Markov chain converges to a stationary distribution.\n",
    "\n",
    "**Statement:**\n",
    "For a finite, irreducible, and aperiodic Markov chain:\n",
    "$$\\lim_{n \\to \\infty} P^n_{ij} = \\pi_j$$\n",
    "\n",
    "Where $\\pi$ is the unique stationary distribution.\n",
    "\n",
    "**Variables:**\n",
    "- $\\lim_{n \\to \\infty}$ = Limit as $n$ approaches infinity\n",
    "- $P^n_{ij}$ = Probability of being in state $j$ after $n$ steps starting from state $i$\n",
    "- $\\pi_j$ = Stationary probability of state $j$\n",
    "- $\\pi$ = Stationary distribution (vector)\n",
    "- $i$ = Starting state\n",
    "- $j$ = Ending state\n",
    "- $n$ = Number of steps\n",
    "\n",
    "**What this means:**\n",
    "- No matter where you start (state $i$), after many steps the probability of being in state $j$ approaches $\\pi_j$\n",
    "- The chain \"forgets\" its initial state\n",
    "- All rows of $P^n$ converge to the same vector $\\pi$\n",
    "\n",
    "**Requirements:**\n",
    "1. **Finite**: Finite number of states\n",
    "2. **Irreducible**: Can reach any state from any other state\n",
    "3. **Aperiodic**: No cyclical return patterns\n",
    "\n",
    "**Visual interpretation:**\n",
    "```\n",
    "P^1: Initial transitions\n",
    "P^2: 2-step transitions  \n",
    "...\n",
    "P^100: All rows ≈ [π₀, π₁, π₂, ...]\n",
    "P^∞: Exact stationary distribution\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Ergodic Theorem\n",
    "\n",
    "**What is this?**\n",
    "Connects **time averages** (how often you visit states in one long run) with **space averages** (stationary distribution).\n",
    "\n",
    "**Statement:**\n",
    "For an irreducible, aperiodic Markov chain with stationary distribution $\\pi$:\n",
    "$$\\lim_{n \\to \\infty} \\frac{1}{n} \\sum_{k=1}^{n} \\mathbb{1}_{X_k = j} = \\pi_j \\quad \\text{almost surely}$$\n",
    "\n",
    "**Variables:**\n",
    "- $\\lim_{n \\to \\infty}$ = Limit as $n$ approaches infinity\n",
    "- $n$ = Total number of steps (time horizon)\n",
    "- $\\frac{1}{n}$ = Normalizing factor (makes it an average)\n",
    "- $\\sum_{k=1}^{n}$ = Sum from time step 1 to $n$\n",
    "- $k$ = Time step index (summation variable)\n",
    "- $\\mathbb{1}_{X_k = j}$ = Indicator function: equals 1 if $X_k = j$, else 0\n",
    "- $X_k$ = State at time $k$ (random variable)\n",
    "- $j$ = Target state\n",
    "- $\\pi_j$ = Stationary probability of state $j$\n",
    "- \"almost surely\" = With probability 1 (probabilistic convergence)\n",
    "\n",
    "**Interpretation:**\n",
    "- Left side: Fraction of time spent in state $j$ over a long run\n",
    "- Right side: Stationary probability of state $j$\n",
    "- They're equal! (with probability 1)\n",
    "\n",
    "**Practical meaning:**\n",
    "- Simulate one long chain → frequency of visits estimates $\\pi$\n",
    "- Don't need multiple independent runs\n",
    "- Justifies using simulation to estimate stationary distribution\n",
    "\n",
    "**Example:**\n",
    "Weather chain with $\\pi_{\\text{sunny}} = 0.7$:\n",
    "- Run chain for 1000 days\n",
    "- Count sunny days ≈ 700\n",
    "- As days → ∞, proportion → 0.7 exactly\n",
    "\n",
    "**Why it matters:**\n",
    "- **Monte Carlo methods**: Single long run is enough\n",
    "- **MCMC sampling**: Frequencies give you the target distribution\n",
    "- **Real-world validation**: Can estimate $\\pi$ from observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aebf88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_chapman_kolmogorov(P, n, m, tol=1e-10):\n",
    "    \"\"\"\n",
    "    Verify Chapman-Kolmogorov equation: P^(n+m) = P^n * P^m\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like, shape (n_states, n_states)\n",
    "        Transition probability matrix\n",
    "    n : int\n",
    "        First step count\n",
    "    m : int\n",
    "        Second step count\n",
    "    tol : float, default=1e-10\n",
    "        Numerical tolerance for equality check\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    verified : bool\n",
    "        True if equation holds within tolerance\n",
    "    max_error : float\n",
    "        Maximum absolute difference between left and right sides\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    \n",
    "    # Compute P^(n+m) directly\n",
    "    P_n_plus_m = np.linalg.matrix_power(P, n + m)\n",
    "    \n",
    "    # Compute P^n * P^m\n",
    "    P_n = np.linalg.matrix_power(P, n)\n",
    "    P_m = np.linalg.matrix_power(P, m)\n",
    "    P_n_times_P_m = P_n @ P_m\n",
    "    \n",
    "    # Check if they're equal\n",
    "    diff = np.abs(P_n_plus_m - P_n_times_P_m)\n",
    "    max_error = float(np.max(diff))\n",
    "    verified = (max_error < tol)\n",
    "    \n",
    "    return verified, max_error\n",
    "\n",
    "def demonstrate_limiting_behavior(P, max_steps=100, start_state=0):\n",
    "    \"\"\"\n",
    "    Demonstrate convergence to stationary distribution.\n",
    "    \n",
    "    Shows how P^n rows converge to π as n increases.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like, shape (n_states, n_states)\n",
    "        Transition probability matrix\n",
    "    max_steps : int, default=100\n",
    "        Maximum number of steps to compute\n",
    "    start_state : int, default=0\n",
    "        Starting state for distribution evolution\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    convergence_data : dict\n",
    "        Dictionary containing:\n",
    "        - 'steps': Array of step numbers\n",
    "        - 'distributions': Distribution at each step starting from start_state\n",
    "        - 'stationary': Stationary distribution π\n",
    "        - 'distances': Total variation distance from π at each step\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    n_states = P.shape[0]\n",
    "    \n",
    "    # Get stationary distribution\n",
    "    try:\n",
    "        pi = stationary_distribution(P)\n",
    "    except:\n",
    "        pi = None\n",
    "    \n",
    "    # Track distribution starting from start_state\n",
    "    steps = []\n",
    "    distributions = []\n",
    "    distances = []\n",
    "    \n",
    "    # Initial distribution (deterministic start)\n",
    "    current_dist = np.zeros(n_states)\n",
    "    current_dist[start_state] = 1.0\n",
    "    \n",
    "    P_power = np.eye(n_states)\n",
    "    \n",
    "    for step in range(max_steps + 1):\n",
    "        steps.append(step)\n",
    "        current_dist = P_power[start_state, :]\n",
    "        distributions.append(current_dist.copy())\n",
    "        \n",
    "        if pi is not None:\n",
    "            tv_dist = total_variation_distance(current_dist, pi)\n",
    "            distances.append(tv_dist)\n",
    "        \n",
    "        if step < max_steps:\n",
    "            P_power = P_power @ P\n",
    "    \n",
    "    return {\n",
    "        'steps': np.array(steps),\n",
    "        'distributions': np.array(distributions),\n",
    "        'stationary': pi,\n",
    "        'distances': np.array(distances) if pi is not None else None\n",
    "    }\n",
    "\n",
    "def simulate_markov_chain(P, start_state, n_steps, rng=None):\n",
    "    \"\"\"\n",
    "    Simulate a Markov chain for n_steps.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like, shape (n_states, n_states)\n",
    "        Transition probability matrix\n",
    "    start_state : int\n",
    "        Initial state index\n",
    "    n_steps : int\n",
    "        Number of steps to simulate\n",
    "    rng : numpy.random.Generator, optional\n",
    "        Random number generator. If None, creates default generator\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    path : array, shape (n_steps+1,)\n",
    "        Sequence of visited states\n",
    "    \"\"\"\n",
    "    return simulate_chain(P, start_state, n_steps, rng)\n",
    "\n",
    "def demonstrate_ergodic_theorem(P, start_state=0, n_steps=10000, target_state=None):\n",
    "    \"\"\"\n",
    "    Demonstrate the Ergodic Theorem by simulation.\n",
    "    \n",
    "    Shows that time average (frequency of visits) converges to stationary probability.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like, shape (n_states, n_states)\n",
    "        Transition probability matrix\n",
    "    start_state : int, default=0\n",
    "        Starting state index\n",
    "    n_steps : int, default=10000\n",
    "        Number of simulation steps\n",
    "    target_state : int, optional\n",
    "        Specific state to track. If None, tracks all states.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    result : dict\n",
    "        Dictionary containing:\n",
    "        - 'path': Simulated path (array of states visited)\n",
    "        - 'time_averages': Frequency of each state over time (n_steps+1 x n_states)\n",
    "        - 'stationary': Stationary distribution π\n",
    "        - 'final_frequencies': Final empirical frequencies (should converge to π)\n",
    "        - 'steps': Array of step numbers\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    n_states = P.shape[0]\n",
    "    \n",
    "    # Simulate path\n",
    "    path = simulate_markov_chain(P, start_state, n_steps)\n",
    "    \n",
    "    # Compute cumulative frequencies\n",
    "    visit_counts = np.zeros((n_steps + 1, n_states))\n",
    "    \n",
    "    for step in range(n_steps + 1):\n",
    "        if step == 0:\n",
    "            visit_counts[0, path[0]] = 1\n",
    "        else:\n",
    "            visit_counts[step] = visit_counts[step - 1]\n",
    "            visit_counts[step, path[step]] += 1\n",
    "    \n",
    "    # Compute time averages (frequencies)\n",
    "    time_averages = np.zeros((n_steps + 1, n_states))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        time_averages[step] = visit_counts[step] / (step + 1)\n",
    "    \n",
    "    # Get stationary distribution\n",
    "    try:\n",
    "        pi = stationary_distribution(P)\n",
    "    except:\n",
    "        pi = None\n",
    "    \n",
    "    return {\n",
    "        'path': path,\n",
    "        'time_averages': time_averages,\n",
    "        'stationary': pi,\n",
    "        'final_frequencies': time_averages[-1],\n",
    "        'steps': np.arange(n_steps + 1)\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
