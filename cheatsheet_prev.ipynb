{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a347dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from numpy.linalg import eig\n",
    "from scipy import optimize\n",
    "from scipy.special import gammaln  # log(y!) safely\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c0ad766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_numpy(x):\n",
    "    \"\"\"Force numpy array (autograders often care).\"\"\"\n",
    "    return np.asarray(x)\n",
    "\n",
    "def clip01(a):\n",
    "    return np.clip(a, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e6f7a8",
   "metadata": {},
   "source": [
    "# 1) Markov Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209c84de",
   "metadata": {},
   "source": [
    "## 1.1 Estimate Transition Matrix from a Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9108e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_transition_matrix(states, n_states=None):\n",
    "    \"\"\"\n",
    "    states: 1D array/list like [x0,x1,...,xT]\n",
    "    returns P_hat shape (n_states,n_states)\n",
    "    \"\"\"\n",
    "    s = np.asarray(states, dtype=int)\n",
    "    if n_states is None:\n",
    "        n_states = int(s.max()) + 1\n",
    "\n",
    "    counts = np.zeros((n_states, n_states), dtype=float)\n",
    "    for a, b in zip(s[:-1], s[1:]):\n",
    "        counts[a, b] += 1\n",
    "\n",
    "    row_sums = counts.sum(axis=1, keepdims=True)\n",
    "    P_hat = np.divide(counts, row_sums, out=np.zeros_like(counts), where=row_sums > 0)\n",
    "    return P_hat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4834d18a",
   "metadata": {},
   "source": [
    "### Check Transition Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bdf592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_transition_matrix(P, tol=1e-10):\n",
    "    P = np.asarray(P, dtype=float)\n",
    "    if (P < -tol).any():\n",
    "        return False\n",
    "    rs = P.sum(axis=1)\n",
    "    return np.allclose(rs, 1.0, atol=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3908a119",
   "metadata": {},
   "source": [
    "## 1.2 Stationary distribution π"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f512f6",
   "metadata": {},
   "source": [
    "### Method A (robust): Eigenvector of $P^T$ at eigenvalue 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6200ddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stationary_distribution(P):\n",
    "    P = np.asarray(P, dtype=float)\n",
    "    w, v = eig(P.T)\n",
    "    k = np.argmin(np.abs(w - 1))\n",
    "    pi = np.real(v[:, k])\n",
    "    pi = pi / pi.sum()\n",
    "    pi = np.maximum(pi, 0)\n",
    "    pi = pi / pi.sum()\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedac92d",
   "metadata": {},
   "source": [
    "### Method B (Linear System): solve $(P^T-I)\\pi = 0 + constraint$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be8fce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stationary_distribution_lstsq(P):\n",
    "    P = np.asarray(P, dtype=float)\n",
    "    n = P.shape[0]\n",
    "    A = np.vstack([P.T - np.eye(n), np.ones(n)])\n",
    "    b = np.zeros(n+1)\n",
    "    b[-1] = 1\n",
    "    pi, *_ = np.linalg.lstsq(A, b, rcond=None)\n",
    "    pi = np.maximum(pi, 0)\n",
    "    return pi / pi.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1e4a15",
   "metadata": {},
   "source": [
    "## 1.3 n-step transition probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f51e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_step_prob(P, i, j, k):\n",
    "    Pk = np.linalg.matrix_power(np.asarray(P, float), k)\n",
    "    return float(Pk[i, j])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a235fb28",
   "metadata": {},
   "source": [
    "## 1.4 Simulate the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65edf50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_chain(P, x0, T, rng=None):\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    P = np.asarray(P, float)\n",
    "    x = int(x0)\n",
    "    path = [x]\n",
    "    for _ in range(T):\n",
    "        x = rng.choice(P.shape[0], p=P[x])\n",
    "        path.append(int(x))\n",
    "    return np.array(path, dtype=int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eff5cb",
   "metadata": {},
   "source": [
    "## 1.5 Irreducible? (graph reachability)\n",
    "\n",
    "A chain is irreducible if every state can reach every other state with positive probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "112a853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_irreducible(P):\n",
    "    P = np.asarray(P, float)\n",
    "    n = P.shape[0]\n",
    "    adj = (P > 0)\n",
    "\n",
    "    def reachable(start):\n",
    "        seen = set([start])\n",
    "        stack = [start]\n",
    "        while stack:\n",
    "            u = stack.pop()\n",
    "            for v in np.where(adj[u])[0]:\n",
    "                if v not in seen:\n",
    "                    seen.add(int(v))\n",
    "                    stack.append(int(v))\n",
    "        return seen\n",
    "\n",
    "    for s in range(n):\n",
    "        if len(reachable(s)) != n:\n",
    "            return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8cf2d9",
   "metadata": {},
   "source": [
    "## 1.6 Period / aperiodic\n",
    "\n",
    "Period of state i is gcd of return times $\\{n : (P^n)_ii > 0\\}$. If gcd=1 ⇒ aperiodic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd726fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def period_of_state(P, i, max_power=200):\n",
    "    P = np.asarray(P, float)\n",
    "    n = P.shape[0]\n",
    "    g = 0\n",
    "    Pk = np.eye(n)\n",
    "    for k in range(1, max_power+1):\n",
    "        Pk = Pk @ P\n",
    "        if Pk[i, i] > 1e-12:\n",
    "            g = k if g == 0 else math.gcd(g, k)\n",
    "    return g if g != 0 else None  # None means never returns within max_power\n",
    "\n",
    "def is_aperiodic(P, max_power=200):\n",
    "    P = np.asarray(P, float)\n",
    "    for i in range(P.shape[0]):\n",
    "        d = period_of_state(P, i, max_power=max_power)\n",
    "        if d is not None and d != 1:\n",
    "            return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359c62ab",
   "metadata": {},
   "source": [
    "## 1.7 Expected hitting time to target state/set (the “linear equations” part)\n",
    "\n",
    "Let target set be A. For $i \\in A: m_i = 0$. Else:\n",
    "\n",
    "\\begin{equation*}\n",
    "m_i = 1 + \\sum_{j} P_{ij} m_j\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7ba79ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_hitting_times(P, target_states):\n",
    "    P = np.asarray(P, float)\n",
    "    n = P.shape[0]\n",
    "    target = set(target_states)\n",
    "\n",
    "    A = np.zeros((n, n), float)\n",
    "    b = np.zeros(n, float)\n",
    "\n",
    "    for i in range(n):\n",
    "        if i in target:\n",
    "            A[i, i] = 1.0\n",
    "            b[i] = 0.0\n",
    "        else:\n",
    "            A[i, i] = 1.0\n",
    "            A[i, :] -= P[i, :]\n",
    "            b[i] = 1.0\n",
    "\n",
    "    m = np.linalg.solve(A, b)\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bb5a3a",
   "metadata": {},
   "source": [
    "### Simulation Estimate (Backup Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f19e61b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def hitting_time_sim(P, start, target, n_sims=2000, max_steps=10000, rng=None):\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    P = np.asarray(P, float)\n",
    "    target = set(target if hasattr(target, \"__iter__\") else [target])\n",
    "\n",
    "    times = []\n",
    "    for _ in range(n_sims):\n",
    "        x = int(start)\n",
    "        t = 0\n",
    "        while t < max_steps and x not in target:\n",
    "            x = rng.choice(P.shape[0], p=P[x])\n",
    "            t += 1\n",
    "        times.append(t if x in target else np.inf)\n",
    "    return np.array(times, float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d935c590",
   "metadata": {},
   "source": [
    "## 1.8 “First time hit D at time t” (exact distribution)\n",
    "\n",
    "If target is state d. Let Q be transitions among non-target states, and r be probs into d. Then:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbb{P}(T = t) = e_s^T Q^{t-1}r\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbb{P}(T = \\inf) = 1- \\sum_{t \\ge 1} \\mathbb{P}(T = t)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60123d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_hit_probabilities(P, start, target_state, t_list):\n",
    "    P = np.asarray(P, float)\n",
    "    n = P.shape[0]\n",
    "    d = int(target_state)\n",
    "\n",
    "    non = [i for i in range(n) if i != d]\n",
    "    idx = {s:i for i,s in enumerate(non)}\n",
    "\n",
    "    Q = P[np.ix_(non, non)]\n",
    "    r = P[non, d]\n",
    "\n",
    "    s = int(start)\n",
    "    if s == d:\n",
    "        return {t: (1.0 if t == 0 else 0.0) for t in t_list} | {\"inf\": 0.0}\n",
    "\n",
    "    e = np.zeros(len(non))\n",
    "    e[idx[s]] = 1.0\n",
    "\n",
    "    out = {}\n",
    "    for t in t_list:\n",
    "        if t <= 0:\n",
    "            out[t] = 0.0\n",
    "        else:\n",
    "            Qtm1 = np.linalg.matrix_power(Q, t-1)\n",
    "            out[t] = float(e @ Qtm1 @ r)\n",
    "\n",
    "    # probability of ever hitting (sum_{t>=1} e Q^{t-1} r = e (I-Q)^(-1) r)\n",
    "    I = np.eye(len(non))\n",
    "    hit_ever = float(e @ np.linalg.solve(I - Q, r))\n",
    "    out[\"inf\"] = 1.0 - hit_ever\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1ae34e",
   "metadata": {},
   "source": [
    "# 2) Random Variables & Sampling \n",
    "\n",
    "### Inversion, Rejection, and LCG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ce0782",
   "metadata": {},
   "source": [
    "## 2.1 Inversion sampling (when CDF is invertible)\n",
    "\n",
    "Example Problem: \n",
    "\n",
    "\\begin{equation*}\n",
    "F(x) = \\frac{e^{x^2} - 1}{e-1}, 0 \\lt x \\lt 1\n",
    "\\end{equation*}\n",
    "\n",
    "Solve $u = {(e^{x^2} - 1)}/{(e-1)}$:\n",
    "\n",
    "\\begin{equation*}\n",
    "x = \\sqrt{ln(1 + u(e-1))}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eed7a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_inversion_e_x2(n, rng=None):\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    u = rng.uniform(0, 1, size=n)\n",
    "    x = np.sqrt(np.log(1 + u*(math.e - 1)))\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42982517",
   "metadata": {},
   "source": [
    "## 2.2 Rejection sampling (general recipe)\n",
    "\n",
    "1. Identify target density $f(x)$ on support\n",
    "2. Choose Proposal $g(x)$ that's easy to sample\n",
    "3. Find $M \\ge sup_x f(x)/g(x)$\n",
    "4. Accept with Probability $f(x)/(M g(x))$\n",
    "\n",
    "### For the same distribution, using Uniform(0,1) proposal\n",
    "\n",
    "Density:\n",
    "\n",
    "\\begin{equation*}\n",
    "f(x) = \\frac{2xe^{x^2}}{e-1}, 0 \\lt x \\lt 1\n",
    "\\end{equation*}\n",
    "\n",
    "Maximum at $x = 1  \\Longrightarrow M = f(1) = 2e/(e-1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d05811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_rejection_e_x2(n, rng=None):\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    M = 2*math.e/(math.e - 1)\n",
    "\n",
    "    out = []\n",
    "    while len(out) < n:\n",
    "        x = rng.uniform(0, 1)\n",
    "        u = rng.uniform(0, 1)\n",
    "        fx = (2*x*math.exp(x*x))/(math.e - 1)\n",
    "        if u <= fx / M:\n",
    "            out.append(x)\n",
    "    return np.array(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45f367f",
   "metadata": {},
   "source": [
    "## 2.3 Monte Carlo integration (+ Hoeffding CI)\n",
    "\n",
    "If you sample $X \\sim f$, then:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\int h(x) f(x) d(x) = \\mathbb{E}[h(X)] \\approx \\frac{1}{n} \\sum h(X_i)\n",
    "\\end{equation*}\n",
    "\n",
    "#### Hoeffding 95% CI for bounded $h(X) \\in [a,b]\n",
    "\n",
    "\\begin{equation*}\n",
    "\\epsilon = (b-a) \\sqrt{\\frac{ln(2/\\delta)}{2n}}, \\delta = 0.05\n",
    "\\end{equation*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdbbfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hoeffding_ci(samples_of_h, a, b, delta=0.05):\n",
    "    z = np.asarray(samples_of_h, float)\n",
    "    n = len(z)\n",
    "    mean = float(z.mean())\n",
    "    eps = (b - a) * math.sqrt(math.log(2/delta) / (2*n))\n",
    "    return (mean - eps, mean + eps), mean, eps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbdd9ff",
   "metadata": {},
   "source": [
    "Example: $int_0^1 sin(x) f(x) dx$\n",
    "\n",
    "Since $sin(x) \\in [0,sin(1)] \\subset [0,1]$, safe bound is [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61259518",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sample_inversion_e_x2(100000)\n",
    "h = np.sin(x)\n",
    "ci, est, eps = hoeffding_ci(h, a=0.0, b=1.0, delta=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd1cb37",
   "metadata": {},
   "source": [
    "## 2.4 LCG → Uniform(0,1) → Accept/Reject target density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da824f8",
   "metadata": {},
   "source": [
    "### LCG Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5ed7db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcg(size, seed=1, a=1103515245, c=12345, m=2**31):\n",
    "    u = seed\n",
    "    out = []\n",
    "    for _ in range(size):\n",
    "        u = (a*u + c) % m\n",
    "        out.append(u / m)\n",
    "    return np.array(out, float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ccdb22",
   "metadata": {},
   "source": [
    "### Accept-reject for target $f(x) = \\frac{\\pi}{2}|sin(2 \\pi x)|$ on $[0,1]$\n",
    "\n",
    "Max is $\\pi/2$, proposal uniform $\\Rightarrow$ acceptance prob $= |sin(2 \\pi x)|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a97fffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sin_target(n, seed=1):\n",
    "    out = []\n",
    "    k = 0\n",
    "    while len(out) < n:\n",
    "        x = lcg(1, seed=seed+k)[0]\n",
    "        u = lcg(1, seed=seed+k+999)[0]\n",
    "        if u <= abs(math.sin(2*math.pi*x)):\n",
    "            out.append(x)\n",
    "        k += 1\n",
    "    return np.array(out, float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af963be",
   "metadata": {},
   "source": [
    "## 2.5 The “tricky CDF” hack\n",
    "\n",
    "CDF on $0 < x < 1/20$:\n",
    "\n",
    "\\begin{equation*}\n",
    "F(x) = 20xe^{20- \\frac{1}{x}}\n",
    "\\end{equation*}\n",
    "\n",
    "Let $Z = 1/X$ (so $Z \\ge 20$). Then propose:\n",
    "- Sample Z from shifted exponential: $Z = 20 + E, E \\sim Exp(1)$\n",
    "- Accept with a near-constant $M \\approx 1.05$ (very fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba329257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_tricky_cdf_fast(n, rng=None):\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    out = []\n",
    "    M = 1.05  # safe bound\n",
    "\n",
    "    while len(out) < n:\n",
    "        z = 20 + rng.exponential(1.0)   # proposal h(z) = e^{-(z-20)}\n",
    "        u = rng.uniform(0, 1)\n",
    "\n",
    "        # target/proposal ratio simplifies to 20*(1/z + 1/z^2)\n",
    "        ratio = 20.0*(1.0/z + 1.0/(z*z))\n",
    "        if u <= ratio / M:\n",
    "            out.append(1.0/z)\n",
    "\n",
    "    return np.array(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3159ab",
   "metadata": {},
   "source": [
    "# 3) Classification Metrics + Confidence Interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3647f48",
   "metadata": {},
   "source": [
    "## 3.1 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "178620b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, int)\n",
    "    y_pred = np.asarray(y_pred, int)\n",
    "\n",
    "    TP = int(np.sum((y_true==1) & (y_pred==1)))\n",
    "    TN = int(np.sum((y_true==0) & (y_pred==0)))\n",
    "    FP = int(np.sum((y_true==0) & (y_pred==1)))\n",
    "    FN = int(np.sum((y_true==1) & (y_pred==0)))\n",
    "    return {\"TP\":TP, \"TN\":TN, \"FP\":FP, \"FN\":FN}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec7736a",
   "metadata": {},
   "source": [
    "## 3.2 Precision / recall / accuracy\n",
    "\n",
    "![title](img/confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d401fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_accuracy(counts):\n",
    "    TP, TN, FP, FN = counts[\"TP\"], counts[\"TN\"], counts[\"FP\"], counts[\"FN\"]\n",
    "    precision = TP / (TP + FP) if (TP+FP)>0 else 0.0\n",
    "    recall    = TP / (TP + FN) if (TP+FN)>0 else 0.0\n",
    "    accuracy  = (TP + TN) / (TP + TN + FP + FN) if (TP+TN+FP+FN)>0 else 0.0\n",
    "    return precision, recall, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a12226d",
   "metadata": {},
   "source": [
    "## 3.3 Hoeffding CI for a proportion\n",
    "Works for accuracy, recall, precision if defined as mean of Bernoulli\n",
    "\n",
    "If metric is average of values in [0,1], Hoeffding gives:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{p} \\pm \\sqrt{\\frac{ln(2/\\delta)}{2n}} \n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac9f95d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hoeffding_ci_01(mean_hat, n, delta=0.05):\n",
    "    eps = math.sqrt(math.log(2/delta)/(2*n))\n",
    "    return (mean_hat - eps, mean_hat + eps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed932eb",
   "metadata": {},
   "source": [
    "#### How to apply to precision/recall properly\n",
    "\n",
    "- Recall is mean of indicators over the true positives set (all y=1):\n",
    "    - data size $= n_1 = \\# \\{i:y_i = 1\\}$\n",
    "- Precision is mean of indicators over the predicted positives set:\n",
    "    - data size $= n_{\\hat{1}} = \\# \\{i: \\hat{y_i} = 1\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "528f48d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_ci(y_true, y_pred, delta=0.05):\n",
    "    y_true = np.asarray(y_true, int); y_pred = np.asarray(y_pred, int)\n",
    "    idx = (y_true==1)\n",
    "    n = int(idx.sum())\n",
    "    if n == 0: \n",
    "        return (0.0, 1.0)\n",
    "    rec = float(np.mean(y_pred[idx]==1))\n",
    "    return hoeffding_ci_01(rec, n, delta=delta)\n",
    "\n",
    "def precision_ci(y_true, y_pred, delta=0.05):\n",
    "    y_true = np.asarray(y_true, int); y_pred = np.asarray(y_pred, int)\n",
    "    idx = (y_pred==1)\n",
    "    n = int(idx.sum())\n",
    "    if n == 0:\n",
    "        return (0.0, 1.0)\n",
    "    prec = float(np.mean(y_true[idx]==1))\n",
    "    return hoeffding_ci_01(prec, n, delta=delta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3f8b6c",
   "metadata": {},
   "source": [
    "# 4) Cost-Sensitive Classification (Fraud-style)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d35e59a",
   "metadata": {},
   "source": [
    "### Total Cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0455764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_cost(counts, c_fp=100, c_fn=500, c_tp=0, c_tn=0):\n",
    "    return (counts[\"FP\"]*c_fp +\n",
    "            counts[\"FN\"]*c_fn +\n",
    "            counts[\"TP\"]*c_tp +\n",
    "            counts[\"TN\"]*c_tn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfa522f",
   "metadata": {},
   "source": [
    "### Sweep thresholds over a score (SVM decision function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61485d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_thresholds(y_true, scores, thresholds, c_fp=100, c_fn=500):\n",
    "    y_true = np.asarray(y_true, int)\n",
    "    scores = np.asarray(scores, float)\n",
    "\n",
    "    rows = []\n",
    "    for t in thresholds:\n",
    "        y_pred = (scores >= t).astype(int)\n",
    "        counts = confusion_matrix(y_true, y_pred)\n",
    "        rows.append({\n",
    "            \"threshold\": float(t),\n",
    "            **counts,\n",
    "            \"total_cost\": float(total_cost(counts, c_fp=c_fp, c_fn=c_fn))\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values(\"total_cost\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed35d04",
   "metadata": {},
   "source": [
    "Typical usage with LinearSVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b749f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bn/w4ms4n5n7l3czmht6p6ntpjm0000gn/T/ipykernel_3219/124898202.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# X_train, X_test, y_train, y_test = ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf = LinearSVC(C=1.0, max_iter=10000, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "scores = clf.decision_function(X_test)\n",
    "thresholds = np.linspace(scores.min(), scores.max(), 200)\n",
    "df = sweep_thresholds(y_test, scores, thresholds)\n",
    "best = df.iloc[0]\n",
    "best_threshold = best[\"threshold\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a71f9d",
   "metadata": {},
   "source": [
    "### Hoeffding CI for average cost per observation\n",
    "Cost per obs is bounded in $[0,500]$\n",
    "\n",
    "Same Hoeffding formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "490e24cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_observation_cost(y_true, y_pred, c_fp=100, c_fn=500, c_tp=0, c_tn=0):\n",
    "    y_true = np.asarray(y_true, int)\n",
    "    y_pred = np.asarray(y_pred, int)\n",
    "    cost = np.zeros_like(y_true, dtype=float)\n",
    "\n",
    "    cost[(y_true==0) & (y_pred==1)] = c_fp\n",
    "    cost[(y_true==1) & (y_pred==0)] = c_fn\n",
    "    cost[(y_true==1) & (y_pred==1)] = c_tp\n",
    "    cost[(y_true==0) & (y_pred==0)] = c_tn\n",
    "    return cost\n",
    "\n",
    "def hoeffding_cost_ci(costs, a=0.0, b=500.0, delta=0.05):\n",
    "    costs = np.asarray(costs, float)\n",
    "    n = len(costs)\n",
    "    mean = float(costs.mean())\n",
    "    eps = (b-a)*math.sqrt(math.log(2/delta)/(2*n))\n",
    "    return (mean-eps, mean+eps), mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802923be",
   "metadata": {},
   "source": [
    "# 5) “Spam words” conditional probability (quick counting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3e4ac7",
   "metadata": {},
   "source": [
    "Estimate:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbb{P}(Y=1 | \\text{word present}) = \\frac{\\#(\\text{spam and word present})}{\\#(\\text{word present})}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fa3716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_word(text, words):\n",
    "    t = text.lower()\n",
    "    return any(w in t for w in words)\n",
    "\n",
    "def estimate_spam_given_words(data, words=(\"free\",\"prize\")):\n",
    "    # data: list of [text, label] where label 0/1\n",
    "    present = []\n",
    "    spam = []\n",
    "    for text, y in data:\n",
    "        if contains_word(text, words):\n",
    "            present.append(1)\n",
    "            spam.append(int(y))\n",
    "    present_n = len(present)\n",
    "    if present_n == 0:\n",
    "        return 0.0, 0\n",
    "    return sum(spam)/present_n, present_n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fdac4b",
   "metadata": {},
   "source": [
    "CI with Hoeffding (mean of Bernoulli):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb63cf74",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spam_no_spam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bn/w4ms4n5n7l3czmht6p6ntpjm0000gn/T/ipykernel_3219/3837538414.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimate_spam_given_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspam_no_spam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"free\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"prize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mci\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhoeffding_ci_01\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.10\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# for 90% interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spam_no_spam' is not defined"
     ]
    }
   ],
   "source": [
    "p_hat, n = estimate_spam_given_words(spam_no_spam, (\"free\",\"prize\"))\n",
    "ci = hoeffding_ci_01(p_hat, n, delta=0.10)  # for 90% interval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a0c9bc",
   "metadata": {},
   "source": [
    "“free appears twice” ⇒ count occurrences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efbc85ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word(text, word):\n",
    "    return text.lower().split().count(word)\n",
    "\n",
    "def estimate_spam_free_twice(data):\n",
    "    vals = []\n",
    "    for text, y in data:\n",
    "        if text.lower().count(\"free\") >= 2:\n",
    "            vals.append(int(y))\n",
    "    n = len(vals)\n",
    "    p_hat = sum(vals)/n if n>0 else 0.0\n",
    "    return p_hat, n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bb2a46",
   "metadata": {},
   "source": [
    "# 6) Logistic model + calibration (ProportionalSpam-style)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04f1457",
   "metadata": {},
   "source": [
    "## 6.1 Logistic loss (negative log-likelihood)\n",
    "\n",
    "For $p_i = \\sigma ({\\beta}_0 + {x_i}^T \\beta)$:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbb{L} = - \\sum{(y_i \\ log \\ p_i + (i-y_i) \\ log(1 - p_i))}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdd8accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_loss(X, y, coeffs):\n",
    "    X = np.asarray(X, float)\n",
    "    y = np.asarray(y, float)\n",
    "    b0 = coeffs[0]\n",
    "    b  = coeffs[1:]\n",
    "    z = b0 + X @ b\n",
    "    # stable sigmoid\n",
    "    p = 1.0/(1.0 + np.exp(-z))\n",
    "    eps = 1e-12\n",
    "    p = np.clip(p, eps, 1-eps)\n",
    "    return -np.sum(y*np.log(p) + (1-y)*np.log(1-p))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758ee25c",
   "metadata": {},
   "source": [
    "Fit with scipy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6895319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logistic(X, y):\n",
    "    X = np.asarray(X, float)\n",
    "    y = np.asarray(y, float)\n",
    "    init = np.zeros(X.shape[1] + 1)\n",
    "    res = optimize.minimize(lambda c: logistic_loss(X,y,c), init, method=\"CG\")\n",
    "    return res.x, res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8321bdae",
   "metadata": {},
   "source": [
    "Predict probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5a23d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_predict_proba(X, coeffs):\n",
    "    X = np.asarray(X, float)\n",
    "    z = coeffs[0] + X @ coeffs[1:]\n",
    "    return 1.0/(1.0 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1fe15d",
   "metadata": {},
   "source": [
    "## 6.2 Calibration with isotonic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a120fd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "def calibrate_isotonic(probs_calib, y_calib):\n",
    "    iso = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "    iso.fit(probs_calib, y_calib)\n",
    "    return iso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2c42a8",
   "metadata": {},
   "source": [
    "Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007ecaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit base model on train\n",
    "coeffs, _ = fit_logistic(X_train, y_train)\n",
    "\n",
    "# Calibrate on calib set\n",
    "p_cal = logistic_predict_proba(X_calib, coeffs)\n",
    "iso = calibrate_isotonic(p_cal, y_calib)\n",
    "\n",
    "# Final calibrated probs on test\n",
    "p_test = logistic_predict_proba(X_test, coeffs)\n",
    "p_final = iso.predict(p_test)\n",
    "\n",
    "# 0-1 loss using Bayes classifier threshold 0.5\n",
    "y_pred = (p_final >= 0.5).astype(int)\n",
    "loss01 = np.mean(y_pred != y_test)\n",
    "\n",
    "# Hoeffding CI for 0-1 loss (bounded [0,1])\n",
    "ci01 = hoeffding_ci_01(loss01, n=len(y_test), delta=0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea002b0",
   "metadata": {},
   "source": [
    "# 7) Regression questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5643aaf6",
   "metadata": {},
   "source": [
    "## 7.1 Train/test split + model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f9112ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def build_regression_pipeline(cat_cols, num_cols):\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "            (\"num\", \"passthrough\", num_cols),\n",
    "        ]\n",
    "    )\n",
    "    model = RandomForestRegressor(random_state=0)\n",
    "    return Pipeline([(\"pre\", pre), (\"model\", model)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad225ae5",
   "metadata": {},
   "source": [
    "## 7.2 Metrics: MAE + Absolute Relative Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f88a779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, float)\n",
    "    y_pred = np.asarray(y_pred, float)\n",
    "    return float(np.mean(np.abs(y_true - y_pred)))\n",
    "\n",
    "def abs_relative_error(y_true, y_pred, eps=1e-12):\n",
    "    y_true = np.asarray(y_true, float)\n",
    "    y_pred = np.asarray(y_pred, float)\n",
    "    return float(np.mean(np.abs((y_true - y_pred) / (y_true + eps))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f399e2",
   "metadata": {},
   "source": [
    "## 7.3 EDF of residuals + 95% confidence bands (DKW inequality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aac1405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def edf_with_dkw(residuals, alpha=0.05):\n",
    "    r = np.sort(np.asarray(residuals, float))\n",
    "    n = len(r)\n",
    "    Fn = np.arange(1, n+1)/n\n",
    "    eps = math.sqrt(math.log(2/alpha)/(2*n))\n",
    "    lower = clip01(Fn - eps)\n",
    "    upper = clip01(Fn + eps)\n",
    "    return r, Fn, lower, upper, eps\n",
    "\n",
    "def plot_edf_with_bands(residuals, alpha=0.05):\n",
    "    x, Fn, lo, hi, eps = edf_with_dkw(residuals, alpha=alpha)\n",
    "    plt.figure()\n",
    "    plt.step(x, Fn, where=\"post\")\n",
    "    plt.step(x, lo, where=\"post\")\n",
    "    plt.step(x, hi, where=\"post\")\n",
    "    plt.xlabel(\"residual\")\n",
    "    plt.ylabel(\"EDF\")\n",
    "    plt.title(f\"EDF with DKW {int((1-alpha)*100)}% bands (eps={eps:.4f})\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff3bfd1",
   "metadata": {},
   "source": [
    "## 7.4 Scatter plot predicted vs true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "574f674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred_vs_true(y_true, y_pred):\n",
    "    plt.figure()\n",
    "    plt.scatter(y_pred, y_true)\n",
    "    plt.xlabel(\"predicted\")\n",
    "    plt.ylabel(\"true\")\n",
    "    plt.title(\"Predicted vs True\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdd828b",
   "metadata": {},
   "source": [
    "# 8) Poisson Regression (counts visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34b8a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_loss(coeffs, X, y, include_factorial=False):\n",
    "    X = np.asarray(X, float)\n",
    "    y = np.asarray(y, float)\n",
    "    alpha = coeffs[:-1]\n",
    "    beta  = coeffs[-1]\n",
    "    eta = X @ alpha + beta\n",
    "    lam = np.exp(eta)\n",
    "\n",
    "    loss = np.sum(lam - y*eta)\n",
    "    if include_factorial:\n",
    "        loss += np.sum(gammaln(y + 1))  # constant w.r.t coeffs, but safe\n",
    "    return loss\n",
    "\n",
    "def fit_poisson(X, y):\n",
    "    X = np.asarray(X, float)\n",
    "    y = np.asarray(y, float)\n",
    "    init = np.zeros(X.shape[1] + 1)\n",
    "    res = optimize.minimize(lambda c: poisson_loss(c, X, y), init, method=\"CG\")\n",
    "    return res.x, res\n",
    "\n",
    "def poisson_predict(X, coeffs):\n",
    "    X = np.asarray(X, float)\n",
    "    alpha = coeffs[:-1]\n",
    "    beta  = coeffs[-1]\n",
    "    return np.exp(X @ alpha + beta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fe9d9c",
   "metadata": {},
   "source": [
    "Naive baseline (always predict mean of train):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca1f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_mean_predict(y_train, n_test):\n",
    "    return np.full(n_test, float(np.mean(y_train)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1e7c2f",
   "metadata": {},
   "source": [
    "# 9) SVD / PCA anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32198993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_explained_variance(X):\n",
    "    X = np.asarray(X, float)\n",
    "    U, s, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "    var = s**2\n",
    "    evr = var / var.sum()\n",
    "    cev = np.cumsum(evr)\n",
    "    return U, s, Vt, evr, cev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc97677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_k_for_variance(cum_evr, target=0.90):\n",
    "    return int(np.searchsorted(cum_evr, target) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f771ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_reconstruct(U, s, Vt, k):\n",
    "    Uk = U[:, :k]\n",
    "    sk = s[:k]\n",
    "    Vtk = Vt[:k, :]\n",
    "    return Uk @ (sk[:, None] * Vtk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768b4a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_reconstruction_error(X, Xhat):\n",
    "    X = np.asarray(X, float)\n",
    "    Xhat = np.asarray(Xhat, float)\n",
    "    return np.linalg.norm(X - Xhat, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992d77cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_anomalies(errors, k=10):\n",
    "    idx = np.argsort(errors)[::-1][:k]\n",
    "    return idx, errors[idx]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
