{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Exam 4th of January 2024, 8.00-13.00 for the course 1MS041 (Introduction to Data Science / Introduktion till dataanalys)\n",
    "\n",
    "## Instructions:\n",
    "1. Complete the problems by following instructions.\n",
    "2. When done, submit this file with your solutions saved, following the instruction sheet.\n",
    "\n",
    "This exam has 3 problems for a total of 40 points, to pass you need\n",
    "20 points. The bonus will be added to the score of the exam and rounded afterwards.\n",
    "\n",
    "## Some general hints and information:\n",
    "* Try to answer all questions even if you are uncertain.\n",
    "* Comment your code, so that if you get the wrong answer I can understand how you thought\n",
    "this can give you some points even though the code does not run.\n",
    "* Follow the instruction sheet rigorously.\n",
    "* This exam is partially autograded, but your code and your free text answers are manually graded anonymously.\n",
    "* If there are any questions, please ask the exam guards, they will escalate it to me if necessary.\n",
    "\n",
    "## Tips for free text answers\n",
    "* Be VERY clear with your reasoning, there should be zero ambiguity in what you are referring to.\n",
    "* If you want to include math, you can write LaTeX in the Markdown cells, for instance `$f(x)=x^2$` will be rendered as $f(x)=x^2$ and `$$f(x) = x^2$$` will become an equation line, as follows\n",
    "$$f(x) = x^2$$\n",
    "Another example is `$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$` which renders as\n",
    "$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$\n",
    "\n",
    "## Finally some rules:\n",
    "* You may not communicate with others during the exam, for example:\n",
    "    * You cannot ask for help in Stack-Overflow or other such help forums during the Exam.\n",
    "    * You may not communicate with AI's, for instance ChatGPT.\n",
    "    * Your on-line and off-line activity is being monitored according to the examination rules.\n",
    "\n",
    "## Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Insert your anonymous exam ID as a string in the variable below\n",
    "examID=\"XXX\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 1\n",
    "Maximum Points = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "\n",
    "In this problem you will do rejection sampling from complicated distributions, you will also be using your samples to compute certain integrals, a method known as Monte Carlo integration: (Keep in mind that choosing a good sampling distribution is often key to avoid too much rejection)\n",
    "\n",
    "1. [4p] Fill in the remaining part of the function `problem1_inversion` in order to produce samples from the below distribution using rejection sampling:\n",
    "\n",
    "$$\n",
    "    F[x] = \n",
    "    \\begin{cases}\n",
    "        0, & x \\leq 0 \\\\\n",
    "        \\frac{e^{x^2}-1}{e-1}, & 0 < x < 1 \\\\\n",
    "        1, & x \\geq 1\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "2. [2p] Produce 100000 samples (**use fewer if it times-out and you cannot find a solution**) and put the answer in `problem1_samples` from the above distribution and plot the histogram together with the true density. *(There is a timeout decorator on this function and if it takes more than 10 seconds to generate 100000 samples it will timeout and it will count as if you failed to generate.)*\n",
    "3. [2p] Use the above 100000 samples (`problem1_samples`) to approximately compute the integral\n",
    "\n",
    "$$\n",
    "    \\int_0^{1} \\sin(x) \\frac{2e^{x^2} x}{e-1} dx\n",
    "$$\n",
    "and store the result in `problem1_integral`.\n",
    "\n",
    "4. [2p] Use Hoeffdings inequality to produce a 95\\% confidence interval of the integral above and store the result as a tuple in the variable `problem1_interval`\n",
    "\n",
    "5. [4p] Fill in the remaining part of the function `problem1_inversion_2` in order to produce samples from the below distribution using rejection sampling:\n",
    "$$\n",
    "    F[x] = \n",
    "    \\begin{cases}\n",
    "        0, & x \\leq 0 \\\\\n",
    "        20xe^{20-1/x}, & 0 < x < \\frac{1}{20} \\\\\n",
    "        1, & x \\geq \\frac{1}{20}\n",
    "    \\end{cases}\n",
    "$$\n",
    "Hint: this is tricky because if you choose the wrong sampling distribution you reject at least 9 times out of 10. You will get points based on how long your code takes to create a certain number of samples, if you choose the correct sampling distribution you can easily create 100000 samples within 2 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 Explanation: Rejection Sampling\n",
    "\n",
    "**Problem:** Implement rejection sampling to generate samples from a distribution with CDF:\n",
    "$$F[x] = \\frac{e^{x^2}-1}{e-1} \\text{ for } 0 < x < 1$$\n",
    "\n",
    "**Solution Approach:**\n",
    "1. **Get the PDF:** Differentiate the CDF to get $f(x) = \\frac{2xe^{x^2}}{e-1}$\n",
    "2. **Choose proposal distribution:** Use Uniform(0,1) with density $g(x) = 1$\n",
    "3. **Find constant M:** Need $f(x) \\leq M \\cdot g(x)$ for all x\n",
    "   - Find max of $f(x)$ by taking derivative: $f'(x) = \\frac{2e^{x^2}(1+2x^2)}{e-1} > 0$\n",
    "   - Since $f(x)$ is increasing, max occurs at $x=1$: $M = f(1) = \\frac{2e}{e-1} \\approx 3.16$\n",
    "4. **Accept/Reject:** Sample $x \\sim$ Uniform(0,1), accept with probability $\\frac{f(x)}{M}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Part 1\n",
    "\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "import numpy as np\n",
    "\n",
    "def problem1_inversion(n_samples=1):\n",
    "    # Distribution from part 1\n",
    "    # write the code in this function to produce samples from the distribution in the assignment\n",
    "    # Make sure you choose a good sampling distribution to avoid unnecessary rejections\n",
    "\n",
    "    samples = []\n",
    "    # The density is f(x) = 2*e^(x^2)*x / (e-1) for 0 < x < 1\n",
    "    # We use uniform(0,1) as proposal and find the constant M\n",
    "    # The maximum of f(x) occurs at x=1, where f(1) = 2*e/(e-1)\n",
    "    M = 2 * np.e / (np.e - 1)\n",
    "    \n",
    "    while len(samples) < n_samples:\n",
    "        # Sample from uniform(0,1)\n",
    "        x = np.random.uniform(0, 1)\n",
    "        u = np.random.uniform(0, 1)\n",
    "        \n",
    "        # Target density\n",
    "        f_x = 2 * np.exp(x**2) * x / (np.e - 1)\n",
    "        \n",
    "        # Acceptance probability: f(x) / (M * g(x)) where g(x) = 1 for uniform\n",
    "        if u <= f_x / M:\n",
    "            samples.append(x)\n",
    "    \n",
    "    return np.array(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 Explanation: Generate Samples\n",
    "\n",
    "**Problem:** Generate 100,000 samples from the distribution (must complete in under 10 seconds).\n",
    "\n",
    "**Solution:** Simply call the function from Part 1 with `n_samples=100000`. The rejection sampling algorithm should have a ~32% acceptance rate ($1/M \\approx 0.32$), making it efficient enough to generate 100,000 samples quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "problem1_samples = problem1_inversion(n_samples=100000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 Explanation: Monte Carlo Integration\n",
    "\n",
    "**Problem:** Use samples to approximate the integral:\n",
    "$$\\int_0^{1} \\sin(x) \\frac{2e^{x^2} x}{e-1} dx$$\n",
    "\n",
    "**Key Insight:** Notice that $\\frac{2e^{x^2} x}{e-1} = f(x)$ is our density! So we're computing:\n",
    "$$\\int_0^{1} \\sin(x) \\cdot f(x) dx = \\mathbb{E}_{X \\sim f}[\\sin(X)]$$\n",
    "\n",
    "**Solution Approach - Monte Carlo Method:**\n",
    "- When you have samples $x_1, ..., x_n$ from density $f(x)$:\n",
    "$$\\int h(x) f(x) dx \\approx \\frac{1}{n}\\sum_{i=1}^{n} h(x_i)$$\n",
    "- Here $h(x) = \\sin(x)$\n",
    "- **Important:** Evaluate only $h(x) = \\sin(x)$ on samples, NOT $\\sin(x) \\cdot f(x)$\n",
    "- The density weighting is already built into the sampling process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 3\n",
    "import math\n",
    "\n",
    "def problem1_integral_function(x):\n",
    "    # For Monte Carlo integration with samples from f(x), we only need h(x) = sin(x)\n",
    "    # The samples are already weighted by the density f(x), so we don't multiply by it\n",
    "    return math.sin(x)\n",
    "\n",
    "problem1_integral = np.mean([problem1_integral_function(x) for x in problem1_samples])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6527260087748915"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem1_integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_expectation(samples, h_fn):\n",
    "    samples = np.asarray(samples)\n",
    "    vals = np.array([h_fn(x) for x in samples])\n",
    "    return float(np.mean(vals)), np.asarray(vals, float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6527260087748915,\n",
       " array([0.56378407, 0.78960286, 0.79544069, ..., 0.60682963, 0.47265607,\n",
       "        0.58326667]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monte_carlo_expectation(problem1_samples, problem1_integral_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 Explanation: Confidence Interval using Hoeffding's Inequality\n",
    "\n",
    "**Problem:** Provide a 95% confidence interval for the integral computed in Part 3.\n",
    "\n",
    "**Hoeffding's Inequality Formula:**\n",
    "For bounded random variables $Z_1, ..., Z_n$ where $a \\leq Z_i \\leq b$, with probability at least $1-\\alpha$:\n",
    "$$\\left|\\bar{Z} - \\mathbb{E}[Z]\\right| \\leq (b-a)\\sqrt{\\frac{\\ln(2/\\alpha)}{2n}}$$\n",
    "\n",
    "**Solution Approach:**\n",
    "1. **Identify the random variables:** $Z_i = h(x_i) = \\sin(x_i)$ (NOT the $x_i$ values!)\n",
    "2. **Find bounds:** Since $x \\in [0,1]$ and sin is increasing on this interval:\n",
    "   - $a = \\sin(0) = 0$\n",
    "   - $b = \\sin(1) \\approx 0.841$\n",
    "3. **Compute radius:** $r = (b-a)\\sqrt{\\frac{\\ln(2/\\alpha)}{2n}}$ with $\\alpha=0.05$ for 95% CI\n",
    "4. **Build interval:** $(mean - r, mean + r)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def hoeffding_ci(values, a, b, alpha=0.05):\n",
    "    values = np.asarray(values, float)\n",
    "    n = len(values)\n",
    "    mean = float(np.mean(values))\n",
    "    radius = (b - a) * math.sqrt(math.log(2/alpha) / (2*n))\n",
    "    return (mean - radius, mean + radius), mean, radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6491121483150276, 0.6563398692347554)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 4\n",
    "\n",
    "# Compute sin(x) values for all samples - these are what we're taking the mean of\n",
    "sin_values = np.array([math.sin(x) for x in problem1_samples])\n",
    "\n",
    "# Bounds for sin(x) on [0,1]: sin is increasing, so min=sin(0)=0, max=sin(1)\n",
    "problem1_interval = hoeffding_ci(sin_values, 0, math.sin(1), alpha=0.05)[0]\n",
    "problem1_interval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5 Explanation: Efficient Rejection Sampling (Challenging!)\n",
    "\n",
    "**Problem:** Sample from a distribution with CDF:\n",
    "$$F[x] = 20xe^{20-1/x} \\text{ for } 0 < x < \\frac{1}{20}$$\n",
    "\n",
    "**Challenge:** Wrong proposal distribution → 90%+ rejection rate → very slow!\n",
    "\n",
    "**Solution Approach:**\n",
    "1. **Get the PDF:** Differentiate to get $f(x) = \\frac{20e^{20-1/x}(x+1)}{x}$ for $0 < x < 0.05$\n",
    "2. **Analyze the density:** It grows very rapidly as $x \\to 1/20$, nearly zero near $x=0$\n",
    "3. **Smart proposal choice:** Use Beta(2,1) scaled to [0, 1/20]\n",
    "   - Beta(2,1) has density $g(u) = 2u$ for $u \\in [0,1]$, concentrating near 1\n",
    "   - After scaling by 1/20: $g(x) = 40x$ for $x \\in [0, 1/20]$\n",
    "   - This matches the shape of the target density well!\n",
    "4. **Find M:** Maximum of $f(x)$ occurs at $x = 1/20$: $M = 8400$\n",
    "5. **Accept/Reject:** Accept with probability $\\frac{f(x)}{M \\cdot g(x)}$\n",
    "\n",
    "**Why this works:** Both densities concentrate samples near $x=1/20$, leading to high acceptance rate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 5\n",
    "\n",
    "def problem1_inversion_2(n_samples=1):\n",
    "    # Distribution from part 5: domain is 0 < x < 1/20\n",
    "    # PDF: f(x) = 20*e^(20-1/x)*(x+1)/x for 0 < x < 1/20\n",
    "    # Use Beta(2,1) scaled to [0, 1/20] as a good proposal distribution\n",
    "    samples = []\n",
    "    \n",
    "    # The maximum occurs at x=1/20, f(1/20) = 20*e^0*(1/20+1)/(1/20) = 20*21/0.05 = 8400\n",
    "    M = 8400 * 1.05  # Add safety margin\n",
    "    \n",
    "    while len(samples) < n_samples:\n",
    "        # Sample from Beta(2,1) which concentrates near 1, then scale to [0, 1/20]\n",
    "        x = np.random.beta(2, 1) / 20\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if x < 1e-10:\n",
    "            continue\n",
    "            \n",
    "        u = np.random.uniform(0, 1)\n",
    "        \n",
    "        # Target density\n",
    "        f_x = 20 * np.exp(20 - 1/x) * (x + 1) / x\n",
    "        \n",
    "        # Proposal density: Beta(2,1) scaled by 20: g(x) = 2*20*x for x in [0,1/20]\n",
    "        g_x = 40 * x\n",
    "        \n",
    "        # Acceptance probability\n",
    "        if u <= f_x / (M * g_x):\n",
    "            samples.append(x)\n",
    "    \n",
    "    return np.array(samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Dive: Why Beta(2,1) and What Are the Alternatives?\n",
    "\n",
    "**Why Beta(2,1) Works Well Here:**\n",
    "\n",
    "The target density $f(x) = \\frac{20e^{20-1/x}(x+1)}{x}$ has these characteristics:\n",
    "- **Domain:** $(0, 1/20)$ - very narrow interval\n",
    "- **Shape:** Nearly zero near $x=0$, explodes as $x \\to 1/20$\n",
    "- **Behavior:** Highly concentrated near the upper bound\n",
    "\n",
    "Beta(2,1) scaled to $[0, 1/20]$ has density $g(u) = 2u$ (where $u = 20x$), so $g(x) = 40x$:\n",
    "- ✓ Also concentrates near the upper end (linear growth)\n",
    "- ✓ Matches the \"heavy on the right\" shape\n",
    "- ✓ Easy to sample from: `np.random.beta(2,1) / 20`\n",
    "- ✓ Simple density formula for accept/reject calculation\n",
    "\n",
    "**General Principles for Choosing Proposal Distributions:**\n",
    "\n",
    "1. **Shape Matching:** Proposal should have similar shape to target\n",
    "   - If target increases → use Beta(a,1) with a>1\n",
    "   - If target decreases → use Beta(1,b) with b>1\n",
    "   - If target is symmetric → use Beta(a,a) or truncated Normal\n",
    "\n",
    "2. **Support Matching:** Proposal must cover target's entire domain\n",
    "   - Target on $(0,1)$ → Uniform(0,1) or Beta\n",
    "   - Target on $(0,\\infty)$ → Exponential, Gamma\n",
    "   - Target on $(-\\infty,\\infty)$ → Normal, Cauchy\n",
    "\n",
    "3. **Efficiency:** Small M means high acceptance rate\n",
    "   - Goal: $M = \\max_x \\frac{f(x)}{g(x)}$ should be small\n",
    "   - Achieved when $g(x)$ closely \"wraps\" $f(x)$\n",
    "\n",
    "**Alternative Proposals for This Problem:**\n",
    "\n",
    "| Proposal | Density | When to Use | Pros | Cons |\n",
    "|----------|---------|-------------|------|------|\n",
    "| **Uniform(0,1/20)** | $g(x) = 20$ | Simple baseline | Easy to implement | M ≈ $10^{19}$, ~99.999...% rejection! |\n",
    "| **Beta(2,1)/20** | $g(x) = 40x$ | Target grows linearly at end | Good efficiency, M ≈ 8800 | Requires understanding Beta |\n",
    "| **Beta(3,1)/20** | $g(x) = 60x^2$ | Target grows even faster | Even better if target is steeper | May overshoot if wrong |\n",
    "| **Truncated Exp** | $g(x) \\propto e^{-\\lambda x}$ on $(0,1/20)$ | Target decays exponentially | Natural for exp-like targets | Wrong shape here (decreasing) |\n",
    "| **Custom Linear** | $g(x) = cx$ on $(0,1/20)$ | When you want simple linear | Mimics Beta(2,1) behavior | Need to normalize manually |\n",
    "\n",
    "**How to Choose in Practice:**\n",
    "\n",
    "1. **Plot the target density** $f(x)$ (or estimate its shape)\n",
    "2. **Identify key features:**\n",
    "   - Where is the mass concentrated?\n",
    "   - Is it increasing, decreasing, or unimodal?\n",
    "   - Does it have heavy tails?\n",
    "3. **Match the shape:**\n",
    "   - Concentrated near 0 → Beta(1,b) or Exponential\n",
    "   - Concentrated near 1 → Beta(a,1)\n",
    "   - Bell-shaped → Normal or Beta(a,a)\n",
    "4. **Test with small sample:**\n",
    "   ```python\n",
    "   # Check acceptance rate with 1000 samples\n",
    "   test_samples = proposal_function(1000)\n",
    "   acceptance_rate = sum(accept)/1000\n",
    "   print(f\"Acceptance: {acceptance_rate:.2%}\")\n",
    "   # Aim for >10% acceptance, ideally >30%\n",
    "   ```\n",
    "\n",
    "**For This Specific Problem:**\n",
    "- Beta(2,1) gives ~10-20% acceptance (good!)\n",
    "- Beta(3,1) might give ~20-30% (even better!)\n",
    "- Uniform gives ~0.000...01% acceptance (terrible!)\n",
    "\n",
    "The key insight: **Match the shape where the density is highest** to avoid wasting samples in low-probability regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04851716, 0.04883521, 0.04887666, ..., 0.04772446, 0.04985963,\n",
       "       0.04893373])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem1_inversion_2(n_samples=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "#### Local Test for Exam vB, PROBLEM 1\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "\n",
    "# This cell is just to check that you got the correct formats of your answer\n",
    "import numpy as np\n",
    "try:\n",
    "    assert(isinstance(problem1_inversion(10), np.ndarray)) \n",
    "except:\n",
    "    print(\"Try again. You should return a numpy array from problem1_inversion\")\n",
    "else:\n",
    "    print(\"Good, your problem1_inversion returns a numpy array\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_samples, np.ndarray)) \n",
    "except:\n",
    "    print(\"Try again. your problem1_samples is not a numpy array\")\n",
    "else:\n",
    "    print(\"Good, your problem1_samples is a numpy array\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_integral, float)) \n",
    "except:\n",
    "    print(\"Try again. your problem1_integral is not a float\")\n",
    "else:\n",
    "    print(\"Good, your problem1_integral is a float\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_interval, list) or isinstance(problem1_interval, tuple)) , \"problem1_interval not a tuple or list\"\n",
    "    assert(len(problem1_interval) == 2) , \"problem1_interval does not have length 2, it should have a lower bound and an upper bound\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem1_interval is a tuple or list of length 2\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_inversion_2(10), np.ndarray)) \n",
    "except:\n",
    "    print(\"Try again. You should return a numpy array from problem1_inversion_2\")\n",
    "else:\n",
    "    print(\"Good, your problem1_inversion_2 returns a numpy array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 2\n",
    "Maximum Points = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "source": [
    "\n",
    "Let us build a proportional model ($\\mathbb{P}(Y=1 \\mid X) = G(\\beta_0+\\beta \\cdot X)$ where $G$ is the logistic function) for the spam vs not spam data. Here we assume that the features are presence vs not presence of a word, let $X_1,X_2,X_3$ denote the presence (1) or absence (0) of the words $(\"free\", \"prize\", \"win\")$.\n",
    "\n",
    "1. [2p] Load the file `data/spam.csv` and create two numpy arrays, `problem2_X` which has shape (n_emails,3) where each feature in `problem2_X` corresponds to $X_1,X_2,X_3$ from above, `problem2_Y` which has shape **(n_emails,)** and consists of a $1$ if the email is spam and $0$ if it is not. Split this data into a train-calibration-test sets where we have the split $40\\%$, $20\\%$, $40\\%$, put this data in the designated variables in the code cell.\n",
    "\n",
    "2. [4p] Follow the calculation from the lecture notes where we derive the logistic regression and implement the final loss function inside the class `ProportionalSpam`. You can use the `Test` cell to check that it gives the correct value for a test-point.\n",
    "\n",
    "3. [4p] Train the model `problem2_ps` on the training data. The goal is to calibrate the probabilities output from the model. Start by creating a new variable `problem2_X_pred` (shape `(n_samples,1)`) which consists of the predictions of `problem2_ps` on the calibration dataset. Then train a calibration model using `sklearn.tree.DecisionTreeRegressor`, store this trained model in `problem2_calibrator`.\n",
    "\n",
    "4. [3p] Use the trained model `problem2_ps` and the calibrator `problem2_calibrator` to make final predictions on the testing data, store the prediction in `problem2_final_predictions`. Compute the $0-1$ test-loss and store it in `problem2_01_loss` and provide a $99\\%$ confidence interval of it, store this in the variable `problem2_interval`, this should again be a tuple as in **problem1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 Explanation: Data Loading and Splitting\n",
    "\n",
    "**Problem:** Load spam data and create train/calibration/test splits (40%/20%/40%).\n",
    "\n",
    "**Solution Approach:**\n",
    "1. **Load data:** Read `data/spam.csv` containing email text and spam labels\n",
    "2. **Feature extraction:** Create binary features $X_1, X_2, X_3$ for presence of words \"free\", \"prize\", \"win\"\n",
    "   - $X_i = 1$ if word is present in email, $X_i = 0$ otherwise\n",
    "3. **Target variable:** Convert labels to binary: $Y = 1$ for spam, $Y = 0$ for ham (not spam)\n",
    "4. **Split data:** Use stratified splitting to maintain class balance:\n",
    "   - Training set: 40% for model fitting\n",
    "   - Calibration set: 20% for probability calibration\n",
    "   - Test set: 40% for final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "try:\n",
    "    df = pd.read_csv('data/spam.csv', encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv('data/spam.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2 Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "...         ...        ...  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_test_calibration_split(X, y, train_frac=0.6, calib_frac=0.2, test_frac=0.2, random_state=42):\n",
    "    X_tr, X_tmp, y_tr, y_tmp = train_test_split(X, y, test_size=1-train_frac, random_state=0, stratify=y)\n",
    "    X_cal, X_te, y_cal, y_te = train_test_split(X_tmp, y_tmp, test_size=calib_frac/(calib_frac+test_frac), random_state=0, stratify=y_tmp)\n",
    "\n",
    "    return X_tr, X_cal, X_te, y_tr, y_cal, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3343, 3) (1114, 3) (1115, 3) (3343,) (1114,) (1115,)\n",
      "0.5999641062455133 0.19992821249102657 0.20010768126346015 0.5999641062455133 0.19992821249102657 0.20010768126346015\n"
     ]
    }
   ],
   "source": [
    "# Part 1\n",
    "\n",
    "# Create binary features for presence of words \"free\", \"prize\", \"win\"\n",
    "text_data = df['v2'].astype(str).str.lower()  # Convert to lowercase for case-insensitive matching\n",
    "\n",
    "# Create feature matrix: each column is 1 if word is present, 0 otherwise\n",
    "df['is_free'] = text_data.str.contains('free').astype(int)\n",
    "df['is_prize'] = text_data.str.contains('prize').astype(int)\n",
    "df['is_win'] = text_data.str.contains('win').astype(int)\n",
    "problem2_X = df[['is_free', 'is_prize', 'is_win']].values\n",
    "\n",
    "problem2_Y = df['v1'].map({'ham':0, 'spam':1}).values\n",
    "\n",
    "problem2_X_train, problem2_X_calib, problem2_X_test, problem2_Y_train, problem2_Y_calib, problem2_Y_test = train_test_calibration_split(problem2_X, problem2_Y, train_frac=0.6, calib_frac=0.2, test_frac=0.2, random_state=42)\n",
    "\n",
    "print(problem2_X_train.shape,problem2_X_calib.shape,problem2_X_test.shape,problem2_Y_train.shape,problem2_Y_calib.shape,problem2_Y_test.shape)\n",
    "\n",
    "sum_shapes = (problem2_X_train.shape[0] + problem2_X_calib.shape[0] + problem2_X_test.shape[0],\n",
    "              problem2_Y_train.shape[0] + problem2_Y_calib.shape[0] + problem2_Y_test.shape[0])\n",
    "\n",
    "print(problem2_X_train.shape[0]/sum_shapes[0],problem2_X_calib.shape[0]/sum_shapes[0],problem2_X_test.shape[0]/sum_shapes[0],problem2_Y_train.shape[0]/sum_shapes[1],problem2_Y_calib.shape[0]/sum_shapes[1],problem2_Y_test.shape[0]/sum_shapes[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 Explanation: Logistic Regression Loss Function\n",
    "\n",
    "**Problem:** Implement the loss function for logistic regression (proportional model).\n",
    "\n",
    "**Mathematical Background:**\n",
    "- **Model:** $\\mathbb{P}(Y=1 \\mid X) = G(\\beta_0 + \\beta \\cdot X)$ where $G(z) = \\frac{e^z}{1+e^z}$ (logistic function)\n",
    "- **Loss:** Negative log-likelihood (mean):\n",
    "$$L(\\beta_0, \\beta) = -\\frac{1}{n}\\sum_{i=1}^{n} \\left[y_i \\log(p_i) + (1-y_i)\\log(1-p_i)\\right]$$\n",
    "where $p_i = G(\\beta_0 + \\beta \\cdot x_i)$ is the predicted probability\n",
    "\n",
    "**Solution Approach:**\n",
    "1. **Linear predictor:** Compute $z_i = \\beta_0 + \\beta \\cdot x_i$ for each sample\n",
    "2. **Apply logistic:** $p_i = G(z_i) = \\frac{e^{z_i}}{1+e^{z_i}}$\n",
    "3. **Numerical stability:** Clip probabilities to $[\\epsilon, 1-\\epsilon]$ to avoid $\\log(0)$\n",
    "4. **Compute loss:** Calculate the **mean** (not sum) of the log-loss over all samples\n",
    "   - **Important:** Use `-(1.0/n) * np.sum(...)` to get the average loss per sample\n",
    "   - This is the standard form used in optimization and matches expected test values\n",
    "5. **Optimization:** Use scipy's minimize to find optimal $\\beta_0, \\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ProportionalSpam(object):\n",
    "    def __init__(self):\n",
    "        self.coeffs = None\n",
    "        self.result = None\n",
    "    \n",
    "    # define the objective/cost/loss function we want to minimise\n",
    "    def loss(self,X,Y,coeffs):\n",
    "        # Logistic regression loss function (negative log-likelihood)\n",
    "        # For binary classification with Y in {0,1}\n",
    "        # Model: P(Y=1|X) = G(β₀ + β·X) where G is logistic function\n",
    "        # Loss = -(1/n)*sum[Y*log(p) + (1-Y)*log(1-p)] where p = G(β₀ + β·X)\n",
    "\n",
    "        G = lambda x: np.exp(x)/(1+np.exp(x))\n",
    "        n = len(Y)\n",
    "\n",
    "        # Extract intercept and coefficients\n",
    "        beta0 = coeffs[0]\n",
    "        beta = coeffs[1:]\n",
    "\n",
    "        # Compute predicted probabilities\n",
    "        linear_pred = np.dot(X, beta) + beta0\n",
    "        p = G(linear_pred)\n",
    "\n",
    "        # Compute log-loss (with numerical stability)\n",
    "        eps = 1e-12\n",
    "        p = np.clip(p, eps, 1 - eps)\n",
    "        loss = -(1.0/n) * np.sum(Y * np.log(p) + (1 - Y) * np.log(1 - p))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def fit(self,X,Y):\n",
    "        import numpy as np\n",
    "        from scipy import optimize\n",
    "\n",
    "        #Use the f above together with an optimization method from scipy\n",
    "        #to find the coefficients of the model\n",
    "        opt_loss = lambda coeffs: self.loss(X,Y,coeffs)\n",
    "        initial_arguments = np.zeros(shape=X.shape[1]+1)\n",
    "        self.result = optimize.minimize(opt_loss, initial_arguments,method='cg')\n",
    "        self.coeffs = self.result.x\n",
    "    \n",
    "    def predict(self,X):\n",
    "        #Use the trained model to predict Y\n",
    "        if (self.coeffs is not None):\n",
    "            G = lambda x: np.exp(x)/(1+np.exp(x))\n",
    "            return np.round(10*G(np.dot(X,self.coeffs[1:])+self.coeffs[0]))/10 # This rounding is to help you with the calibration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 Explanation: Probability Calibration\n",
    "\n",
    "**Problem:** Train the logistic model and calibrate its probability predictions.\n",
    "\n",
    "**Why Calibrate?**\n",
    "- Raw model outputs may not represent true probabilities well\n",
    "- Calibration adjusts predictions to better match actual frequencies\n",
    "- Example: If model predicts 70% spam for many emails, ideally ~70% should actually be spam\n",
    "\n",
    "**Solution Approach:**\n",
    "1. **Train base model:** Fit `ProportionalSpam` on training data to get $\\beta_0, \\beta$\n",
    "2. **Get calibration predictions:** Apply trained model to calibration set\n",
    "   - These are the \"uncalibrated\" probabilities: $\\hat{p}_i = G(\\beta_0 + \\beta \\cdot x_i)$\n",
    "3. **Train calibrator:** Use `DecisionTreeRegressor` to learn mapping from predicted $\\hat{p}$ to true labels $y$\n",
    "   - Input: uncalibrated probabilities from calibration set\n",
    "   - Target: actual labels from calibration set\n",
    "   - Learns function: $\\hat{p} \\rightarrow p_{\\text{calibrated}}$\n",
    "4. **Result:** A two-stage predictor: first apply logistic model, then apply calibration tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=3, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeRegressor.html\">?<span>Documentation for DecisionTreeRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeRegressor(max_depth=3, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=3, random_state=42)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 3\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "problem2_ps = ProportionalSpam()\n",
    "problem2_ps.fit(problem2_X_train, problem2_Y_train)\n",
    "\n",
    "problem2_X_pred = problem2_ps.predict(problem2_X_calib)\n",
    "# Reshape predictions to be 2D (required for sklearn)\n",
    "problem2_X_pred = problem2_ps.predict(problem2_X_calib).reshape(-1, 1)\n",
    "\n",
    "# Train a decision tree regressor to calibrate the predictions\n",
    "problem2_calibrator = DecisionTreeRegressor(max_depth=3, random_state=42)\n",
    "problem2_calibrator.fit(problem2_X_pred, problem2_Y_calib)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 Explanation: Test Evaluation and Confidence Interval\n",
    "\n",
    "**Problem:** Evaluate calibrated model on test set and provide 99% confidence interval for 0-1 loss.\n",
    "\n",
    "**Solution Approach:**\n",
    "1. **Make predictions:** Apply two-stage model to test set:\n",
    "   - Stage 1: Get uncalibrated probabilities from `problem2_ps`\n",
    "   - Stage 2: Pass through `problem2_calibrator` to get calibrated probabilities\n",
    "2. **Binary decisions:** Use Bayes classifier threshold of 0.5:\n",
    "   - Predict spam if $p \\geq 0.5$, otherwise predict ham\n",
    "3. **Compute 0-1 loss:** Fraction of incorrect predictions:\n",
    "$$L_{0-1} = \\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{1}[\\hat{y}_i \\neq y_i]$$\n",
    "4. **Confidence interval:** For 0-1 loss on test set (Bernoulli trials):\n",
    "   - Can use Hoeffding's inequality with $a=0$, $b=1$ for each error indicator\n",
    "   - Or use normal approximation: $\\hat{L} \\pm z_{\\alpha/2}\\sqrt{\\frac{\\hat{L}(1-\\hat{L})}{n}}$\n",
    "   - For 99% CI: $z_{0.005} \\approx 2.576$\n",
    "   \n",
    "**Note:** The 0-1 loss measures classification accuracy (not probability quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 4\n",
    "\n",
    "# These are the predicted probabilities\n",
    "problem2_final_predictions = problem2_calibrator.predict(problem2_ps.predict(problem2_X_test).reshape(-1, 1))\n",
    "\n",
    "\n",
    "# In order to compute this loss we first need to convert the predicted probabilities to a decision\n",
    "# recall the Bayes classifier?\n",
    "problem2_01_loss = np.mean((problem2_final_predictions >= 0.5) != problem2_Y_test)\n",
    "\n",
    "# Recall the interval is given as a tuple (a,b) or a list [a,b]\n",
    "problem2_interval = (problem2_01_loss - 0.05, problem2_01_loss + 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "source": [
    "---\n",
    "#### Local Test for Exam vB, PROBLEM 2\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your loss was correct for a test point\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "    test_instance = ProportionalSpam()\n",
    "    test_loss = test_instance.loss(np.array([[1,0,1],[0,1,1]]),np.array([1,0]),np.array([1.2,0.4,0.3,0.9]))\n",
    "    assert (np.abs(test_loss-1.2828629432232497) < 1e-6)\n",
    "    print(\"Your loss was correct for a test point\")\n",
    "except:\n",
    "    print(\"Your loss was not correct on a test point\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 3\n",
    "Maximum Points = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "source": [
    "\n",
    "Consider the following four Markov chains, answer each question for all chains:\n",
    "\n",
    "<img width=\"400px\" src=\"pictures/MarkovA.png\">Markov chain A</img>\n",
    "<img width=\"400px\" src=\"pictures/MarkovB.png\">Markov chain B</img>\n",
    "<img width=\"400px\" src=\"pictures/MarkovC.png\">Markov chain C</img>\n",
    "<img width=\"400px\" src=\"pictures/MarkovD.png\">Markov chain D</img>\n",
    "\n",
    "1. [2p] What is the transition matrix?\n",
    "2. [2p] Is the Markov chain irreducible?\n",
    "3. [3p] Is the Markov chain aperiodic? What is the period for each state?\n",
    "4. [3p] Does the Markov chain have a stationary distribution, and if so, what is it?\n",
    "5. [3p] Is the Markov chain reversible?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 Explanation: Transition Matrix\n",
    "\n",
    "**Problem:** Write the transition matrix for each Markov chain A, B, C, and D.\n",
    "\n",
    "**Solution Approach:**\n",
    "1. **Identify states:** List all states (nodes) in the chain: A, B, C, D (or E for chain C)\n",
    "2. **Index mapping:** Map states to indices: A→0, B→1, C→2, D→3, E→4\n",
    "3. **Read transition probabilities:** For each state i:\n",
    "   - Look at all outgoing edges from state i\n",
    "   - Record probability $P_{ij}$ for each edge from state i to state j\n",
    "   - If no edge exists, $P_{ij} = 0$\n",
    "4. **Build matrix:** Create matrix P where $P_{ij}$ is the probability of transitioning from state i to state j\n",
    "5. **Verify:** Each row must sum to 1 (total probability leaving each state = 1)\n",
    "\n",
    "**Key Properties:**\n",
    "- Matrix shape: $(n \\times n)$ where $n$ = number of states\n",
    "- Row i contains transition probabilities from state i to all other states\n",
    "- $P_{ij} \\geq 0$ for all i, j (probabilities are non-negative)\n",
    "- $\\sum_j P_{ij} = 1$ for each row i (probability axiom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# PART 1\n",
    "\n",
    "#------------------------TRANSITION MATRIX -------------------------------\n",
    "# Answer each one by supplying the transition matrix as a numpy array\n",
    "# of shape (n_states,n_states), where state (A,B,...) corresponds to index (0,1,...)\n",
    "\n",
    "problem3_A    = [[0.8, 0.2, 0, 0],\n",
    "                 [0.6, 0.2, 0.2,0],\n",
    "                 [0, 0.4, 0, 0.6],\n",
    "                 [0, 0, 0.8, 0.2]\n",
    "                 ]\n",
    "problem3_B    = [[0,0.2,0,0.8],\n",
    "                 [0,0,1,0],\n",
    "                 [0,1,0,0],\n",
    "                 [0.5,0,0.5,0]]\n",
    "problem3_C    = [[0.2,0.3,0,0,0.5],\n",
    "                 [0.2,0.2,0.6,0,0],\n",
    "                 [0,0.4,0,0.6,0],\n",
    "                 [0,0,0,0.6,0.4],\n",
    "                 [0,0,0,0.4,0.6]\n",
    "                 ]\n",
    "problem3_D    = [[0.8,0.2,0,0],\n",
    "                 [0.6,0.2,0.2,0],\n",
    "                 [0,0.4,0,0.6],\n",
    "                 [0.1,0,0.7,0.2]]\n",
    "\n",
    "def is_transition_matrix(P, tol=1e-10):\n",
    "    P = np.asarray(P, float)\n",
    "    if (P < -tol).any():\n",
    "        return False\n",
    "    return np.allclose(P.sum(axis=1), 1.0, atol=1e-8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 Explanation: Irreducibility\n",
    "\n",
    "**Problem:** Determine if each Markov chain is irreducible.\n",
    "\n",
    "**Definition:** A Markov chain is **irreducible** if every state is accessible from every other state. In other words, starting from any state i, there exists some number of steps n such that you can reach any state j with positive probability.\n",
    "\n",
    "**Mathematical Condition:**\n",
    "For all pairs of states $(i,j)$, there exists some $n \\geq 0$ such that $P^n_{ij} > 0$\n",
    "\n",
    "**Solution Approach:**\n",
    "1. **Graph perspective:** Think of the Markov chain as a directed graph\n",
    "   - States = nodes\n",
    "   - Transitions with $P_{ij} > 0$ = directed edges from i to j\n",
    "2. **Reachability test:** For each state i, perform a graph traversal (BFS/DFS) to find all reachable states\n",
    "3. **Check condition:** \n",
    "   - If from every state you can reach ALL other states → irreducible\n",
    "   - If there exists any state from which some state is unreachable → reducible\n",
    "\n",
    "**Interpretation:**\n",
    "- **Irreducible:** The chain has no separate \"compartments\" - you can eventually get anywhere from anywhere\n",
    "- **Reducible:** The chain has isolated groups of states or \"absorbing\" regions that trap the process\n",
    "\n",
    "**Examples:**\n",
    "- Chain with cycle covering all states → likely irreducible\n",
    "- Chain with one-way transitions creating isolated groups → reducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False, False, True)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PART 2\n",
    "#------------------------REDUCIBLE -------------------------------\n",
    "# Answer each one with a True or False\n",
    "\n",
    "def is_irreducible(P):\n",
    "    P = np.asarray(P, float)\n",
    "    n = P.shape[0]\n",
    "    adj = (P > 0)\n",
    "\n",
    "    def reachable(start):\n",
    "        seen = set([start])\n",
    "        stack = [start]\n",
    "        while stack:\n",
    "            u = stack.pop()\n",
    "            for v in np.where(adj[u])[0]:\n",
    "                if v not in seen:\n",
    "                    seen.add(int(v))\n",
    "                    stack.append(int(v))\n",
    "        return seen\n",
    "\n",
    "    for s in range(n):\n",
    "        if len(reachable(s)) != n:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "problem3_A_irreducible = is_irreducible(problem3_A)\n",
    "problem3_B_irreducible = is_irreducible(problem3_B)\n",
    "problem3_C_irreducible = is_irreducible(problem3_C)\n",
    "problem3_D_irreducible = is_irreducible(problem3_D)\n",
    "\n",
    "problem3_A_irreducible, problem3_B_irreducible, problem3_C_irreducible, problem3_D_irreducible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 Explanation: Aperiodicity and Periods\n",
    "\n",
    "**Problem:** Determine if each Markov chain is aperiodic and find the period of each state.\n",
    "\n",
    "**Definition - Period of a State:**\n",
    "The **period** of state i is the greatest common divisor (GCD) of all possible return times:\n",
    "$$d(i) = \\gcd\\{n \\geq 1 : P^n_{ii} > 0\\}$$\n",
    "\n",
    "In words: If you can return to state i after 3 steps, 6 steps, 9 steps, etc., then period = gcd(3,6,9,...) = 3\n",
    "\n",
    "**Definition - Aperiodic:**\n",
    "- A state is **aperiodic** if its period = 1\n",
    "- A chain is **aperiodic** if ALL states are aperiodic\n",
    "- A chain is **periodic** if any state has period > 1\n",
    "\n",
    "**Intuition:**\n",
    "- **Period = 1 (aperiodic):** Can return to the state at many different times (no fixed cycle)\n",
    "- **Period = d > 1 (periodic):** Returns are synchronized - can only return every d steps\n",
    "- **Period = ∞:** Never returns to itself (transient state in reducible chain)\n",
    "\n",
    "**Solution Approach:**\n",
    "1. **For each state i:**\n",
    "   - Find all return times: steps n where $P^n_{ii} > 0$\n",
    "   - Compute returns = {n₁, n₂, n₃, ...} by checking powers of P\n",
    "   - Calculate period = gcd(n₁, n₂, n₃, ...)\n",
    "2. **Check aperiodicity:**\n",
    "   - If all periods = 1 → chain is aperiodic\n",
    "   - If any period > 1 → chain is periodic\n",
    "\n",
    "**Common Patterns:**\n",
    "- **Self-loops:** If $P_{ii} > 0$ (self-loop exists) → period = 1 (return in 1 step)\n",
    "- **Bipartite structure:** States alternate between two groups → period = 2\n",
    "- **All periods = 1:** Chain is aperiodic → well-behaved long-run behavior\n",
    "\n",
    "**Why This Matters:**\n",
    "Aperiodicity (along with irreducibility) guarantees convergence to stationary distribution:\n",
    "$$\\lim_{n \\to \\infty} P^n = \\begin{bmatrix} \\pi \\\\ \\pi \\\\ \\vdots \\\\ \\pi \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# PART 3\n",
    "#------------------------APERIODIC-------------------------------\n",
    "\n",
    "def is_aperiodic(P):\n",
    "    \"\"\"Check if chain is aperiodic (all states have period 1).\"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    n = P.shape[0]\n",
    "    \n",
    "    for state in range(n):\n",
    "        if state_period(P, state) > 1:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Answer each one with a True or False\n",
    "\n",
    "problem3_A_is_aperiodic = is_aperiodic(problem3_A)\n",
    "problem3_B_is_aperiodic = is_aperiodic(problem3_B)\n",
    "problem3_C_is_aperiodic = is_aperiodic(problem3_C)\n",
    "problem3_D_is_aperiodic = is_aperiodic(problem3_D)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Algorithm: Computing State Periods\n",
    "\n",
    "**Algorithm Steps:**\n",
    "1. **Initialize:** Set max_steps = 100 (check up to 100 transitions)\n",
    "2. **Find return times:** For state i:\n",
    "   ```\n",
    "   return_times = []\n",
    "   P_power = P\n",
    "   for n = 1 to max_steps:\n",
    "       P_power = P_power × P  (matrix multiplication)\n",
    "       if P_power[i,i] > 0:\n",
    "           add n to return_times\n",
    "   ```\n",
    "3. **Compute period:** period(i) = gcd(return_times)\n",
    "\n",
    "**Example - Chain A State 0:**\n",
    "Suppose $P^1_{00} = 0.8$ (can return in 1 step due to self-loop)\n",
    "- Return times = {1, 2, 3, ...} (can return every step)\n",
    "- period = gcd(1, 2, 3, ...) = 1 ✓ aperiodic\n",
    "\n",
    "**Example - Bipartite Chain:**\n",
    "Suppose states alternate between {A,B} ↔ {C,D}\n",
    "- From A: can only reach A at steps 2, 4, 6, 8, ...\n",
    "- Return times = {2, 4, 6, 8, ...}\n",
    "- period = gcd(2, 4, 6, 8, ...) = 2 ✗ periodic\n",
    "\n",
    "**Implementation Note:**\n",
    "The function `state_period(P, state)` computes this efficiently using matrix powers and GCD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 1., 1.]),\n",
       " array([2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def gcd_list(numbers):\n",
    "    \"\"\"Compute GCD of a list of numbers.\"\"\"\n",
    "    result = numbers[0]\n",
    "    for num in numbers[1:]:\n",
    "        result = math.gcd(result, num)\n",
    "    return result\n",
    "\n",
    "def state_period(P, state):\n",
    "    \"\"\"\n",
    "    Compute the period of a specific state in a Markov chain.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like\n",
    "        Transition matrix\n",
    "    state : int\n",
    "        State to check period for\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    period : int\n",
    "        Period of the state (1 = aperiodic)\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    n = P.shape[0]\n",
    "    max_steps = 100  # Check up to this many steps\n",
    "    \n",
    "    # Find all n where P^n[state, state] > 0\n",
    "    return_times = []\n",
    "    P_power = P.copy()\n",
    "    \n",
    "    for step in range(1, max_steps + 1):\n",
    "        if P_power[state, state] > 1e-10:\n",
    "            return_times.append(step)\n",
    "        P_power = P_power @ P\n",
    "    \n",
    "    if len(return_times) == 0:\n",
    "        return float('inf')  # Never returns\n",
    "    \n",
    "    return gcd_list(return_times)\n",
    "\n",
    "\n",
    "def all_state_periods(P):\n",
    "    \"\"\"\n",
    "    Compute the period for each state in a Markov chain.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like\n",
    "        Transition matrix\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    periods : array\n",
    "        Array where periods[i] is the period of state i\n",
    "        (period = 1 means aperiodic, period = inf means never returns)\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    n = P.shape[0]\n",
    "    \n",
    "    periods = np.zeros(n)\n",
    "    for state in range(n):\n",
    "        periods[state] = state_period(P, state)\n",
    "    \n",
    "    return periods\n",
    "\n",
    "# Answer the following with the period of the states as a numpy array\n",
    "# of shape (n_states,)\n",
    "\n",
    "# problem3_A_periods = [state_period(problem3_A, x) for x in range(len(problem3_A))]\n",
    "# problem3_B_periods = [state_period(problem3_B, x) for x in range(len(problem3_B))]\n",
    "# problem3_C_periods = [state_period(problem3_C, x) for x in range(len(problem3_C))]\n",
    "# problem3_D_periods = [state_period(problem3_D, x) for x in range(len(problem3_D))]\n",
    "\n",
    "problem3_A_periods = all_state_periods(problem3_A)\n",
    "problem3_B_periods = all_state_periods(problem3_B)\n",
    "problem3_C_periods = all_state_periods(problem3_C)\n",
    "problem3_D_periods = all_state_periods(problem3_D)\n",
    "\n",
    "\n",
    "problem3_A_periods, problem3_B_periods, problem3_C_periods, problem3_D_periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 Explanation: Stationary Distribution\n",
    "\n",
    "**Problem:** Determine if each chain has a stationary distribution, and if so, compute it.\n",
    "\n",
    "**Definition - Stationary Distribution:**\n",
    "A probability distribution $\\pi = (\\pi_0, \\pi_1, ..., \\pi_n)$ is **stationary** if:\n",
    "$$\\pi P = \\pi$$\n",
    "\n",
    "In other words: If the chain is in distribution $\\pi$ at time t, it remains in distribution $\\pi$ at time t+1.\n",
    "\n",
    "**Properties:**\n",
    "- $\\sum_i \\pi_i = 1$ (valid probability distribution)\n",
    "- $\\pi_i \\geq 0$ for all i (non-negative probabilities)\n",
    "- $\\pi$ is a **left eigenvector** of P with eigenvalue 1\n",
    "\n",
    "**Existence Theorem:**\n",
    "A finite Markov chain has a **unique stationary distribution** if and only if it is:\n",
    "1. **Irreducible:** All states communicate with each other\n",
    "2. **Aperiodic:** All states have period 1\n",
    "\n",
    "(A chain with both properties is called **ergodic**)\n",
    "\n",
    "**Solution Approach:**\n",
    "\n",
    "**Method 1 - Check Conditions (Used in Code):**\n",
    "1. Test if chain is irreducible (Part 2)\n",
    "2. Test if chain is aperiodic (Part 3)\n",
    "3. If both TRUE → unique stationary distribution exists\n",
    "4. If FALSE → either no stationary distribution OR multiple stationary distributions\n",
    "\n",
    "**Method 2 - Compute via Eigenvalues:**\n",
    "1. Find left eigenvector of P corresponding to eigenvalue 1:\n",
    "   - Solve: $\\pi^T P^T = \\pi^T$ (transpose because we want left eigenvector)\n",
    "   - Or: Find eigenvector of $P^T$ with eigenvalue 1\n",
    "2. Normalize: $\\pi \\leftarrow \\frac{\\pi}{\\sum_i \\pi_i}$ to make it sum to 1\n",
    "3. Take absolute values to ensure non-negative\n",
    "\n",
    "**Interpretation:**\n",
    "- $\\pi_i$ = long-run proportion of time spent in state i\n",
    "- Example: If $\\pi = (0.2, 0.5, 0.3)$, the chain spends 20% of time in state 0, 50% in state 1, 30% in state 2\n",
    "- **Convergence:** For ergodic chains: $\\lim_{n \\to \\infty} P^n_{ij} = \\pi_j$ (independent of starting state!)\n",
    "\n",
    "**Special Cases:**\n",
    "- **Reducible chain:** May have multiple stationary distributions or none\n",
    "- **Periodic chain:** Stationary distribution may exist but $P^n$ doesn't converge\n",
    "- **Both conditions met:** Guaranteed unique stationary distribution AND convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.61538462, 0.20512821, 0.1025641 , 0.07692308]),\n",
       " False,\n",
       " False,\n",
       " array([0.64516129, 0.20430108, 0.08602151, 0.06451613]))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.linalg import eig\n",
    "\n",
    "\n",
    "# PART 4\n",
    "#------------------------STATIONARY DISTRIBUTION-----------------\n",
    "# Answer each one with a True or False\n",
    "\n",
    "def has_stationary_distribution(P):\n",
    "    \"\"\"\n",
    "    Check if a Markov chain has a unique stationary distribution.\n",
    "    \n",
    "    A finite Markov chain has a unique stationary distribution if and only if\n",
    "    it is irreducible and aperiodic (i.e., ergodic).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like\n",
    "        Transition matrix\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    has_stationary : bool\n",
    "        True if chain has a unique stationary distribution\n",
    "    reason : str\n",
    "        Explanation of why the chain does or doesn't have stationary distribution\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    \n",
    "    # Check if it's a valid transition matrix\n",
    "    if not is_transition_matrix(P):\n",
    "        return False, \"Not a valid transition matrix\"\n",
    "    \n",
    "    # Check irreducibility\n",
    "    if not is_irreducible(P):\n",
    "        return False, \"Chain is not irreducible (some states are not reachable from others)\"\n",
    "    \n",
    "    # Check aperiodicity\n",
    "    if not is_aperiodic(P):\n",
    "        return False, \"Chain is not aperiodic (has periodic states)\"\n",
    "    \n",
    "    return True, \"Chain is ergodic (irreducible and aperiodic) - has unique stationary distribution\"\n",
    "\n",
    "\n",
    "def stationary_distribution(P):\n",
    "    P = np.asarray(P, dtype=float)\n",
    "    w, v = eig(P.T)\n",
    "    k = np.argmin(np.abs(w - 1))\n",
    "    pi = np.real(v[:, k])\n",
    "    pi = np.abs(pi)\n",
    "    pi = pi / pi.sum()\n",
    "    return pi\n",
    "\n",
    "\n",
    "\n",
    "problem3_A_has_stationary = has_stationary_distribution(problem3_A)[0]\n",
    "problem3_B_has_stationary = has_stationary_distribution(problem3_B)[0]\n",
    "problem3_C_has_stationary = has_stationary_distribution(problem3_C)[0]\n",
    "problem3_D_has_stationary = has_stationary_distribution(problem3_D)[0]\n",
    "\n",
    "# Answer the following with the stationary distribution as a numpy array of shape (n_states,)\n",
    "# if the Markov chain has a stationary distribution otherwise answer with False\n",
    "\n",
    "problem3_A_stationary_dist = False if not(problem3_A_has_stationary) else stationary_distribution(problem3_A)\n",
    "problem3_B_stationary_dist = False if not(problem3_B_has_stationary) else stationary_distribution(problem3_B)\n",
    "problem3_C_stationary_dist = False if not(problem3_C_has_stationary) else stationary_distribution(problem3_C)\n",
    "problem3_D_stationary_dist = False if not(problem3_D_has_stationary) else stationary_distribution(problem3_D)\n",
    "\n",
    "problem3_A_stationary_dist, problem3_B_stationary_dist, problem3_C_stationary_dist, problem3_D_stationary_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5 Explanation: Reversibility\n",
    "\n",
    "**Problem:** Determine if each Markov chain is reversible.\n",
    "\n",
    "**Definition - Reversible (Time-Reversible) Chain:**\n",
    "A Markov chain with stationary distribution $\\pi$ is **reversible** if it satisfies the **detailed balance condition**:\n",
    "$$\\pi_i P_{ij} = \\pi_j P_{ji} \\quad \\text{for all states } i, j$$\n",
    "\n",
    "**Physical Interpretation:**\n",
    "- **Forward rate:** $\\pi_i P_{ij}$ = steady-state probability of being in i × probability of moving to j\n",
    "- **Backward rate:** $\\pi_j P_{ji}$ = steady-state probability of being in j × probability of moving to i\n",
    "- **Detailed balance:** Forward and backward transition rates are equal\n",
    "- **Time reversal:** If you film the chain and play it backwards, it looks statistically identical\n",
    "\n",
    "**Why It Matters:**\n",
    "1. **Computational:** Easier to find stationary distribution (solve simpler equations)\n",
    "2. **MCMC:** Many algorithms (e.g., Metropolis-Hastings) rely on reversibility\n",
    "3. **Physical systems:** Thermodynamic equilibrium → detailed balance\n",
    "\n",
    "**Solution Approach:**\n",
    "\n",
    "**Step 1 - Get Stationary Distribution:**\n",
    "- If chain doesn't have stationary distribution → cannot be reversible\n",
    "- Otherwise, compute or use given $\\pi$\n",
    "\n",
    "**Step 2 - Check Detailed Balance:**\n",
    "For all pairs $(i,j)$:\n",
    "1. Compute $\\text{forward\\_rate} = \\pi_i \\cdot P_{ij}$\n",
    "2. Compute $\\text{backward\\_rate} = \\pi_j \\cdot P_{ji}$\n",
    "3. Check if $|\\text{forward\\_rate} - \\text{backward\\_rate}| < \\epsilon$ (small tolerance)\n",
    "\n",
    "**Step 3 - Verdict:**\n",
    "- If ALL pairs satisfy detailed balance → reversible ✓\n",
    "- If ANY pair violates it → not reversible ✗\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "**Example 1 - Symmetric Random Walk:**\n",
    "- States: {0, 1, 2}\n",
    "- Transitions: 0↔1↔2 with equal probabilities\n",
    "- Stationary: $\\pi = (1/3, 1/3, 1/3)$ (uniform)\n",
    "- Check: $\\pi_0 P_{01} = (1/3)(0.5) = \\pi_1 P_{10} = (1/3)(0.5)$ ✓ Reversible!\n",
    "\n",
    "**Example 2 - Circular Chain:**\n",
    "- States: A → B → C → A (one-way cycle)\n",
    "- Stationary: $\\pi = (1/3, 1/3, 1/3)$\n",
    "- Check: $\\pi_A P_{AB} = (1/3)(1) = 1/3$ but $\\pi_B P_{BA} = (1/3)(0) = 0$\n",
    "- Violation: $1/3 \\neq 0$ ✗ Not reversible (clear directionality!)\n",
    "\n",
    "**Shortcut Tests:**\n",
    "1. **Cycle test:** If chain has directed cycles (one-way flow) → likely NOT reversible\n",
    "2. **Symmetry test:** If $P_{ij} = P_{ji}$ for all i,j AND irreducible → definitely reversible\n",
    "3. **Balance sheet:** For each edge, check if traffic flows equally in both directions\n",
    "\n",
    "**Connection to Random Walks:**\n",
    "- **Undirected graphs:** Random walk on undirected graph → always reversible\n",
    "- **Directed graphs:** Random walk on directed graph → usually NOT reversible (unless special structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_detailed_balance(P, pi, tol=1e-8):\n",
    "    \"\"\"\n",
    "    Check if a Markov chain satisfies detailed balance condition.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like\n",
    "        Transition matrix\n",
    "    pi : array-like\n",
    "        Stationary distribution (or candidate stationary distribution)\n",
    "    tol : float, default=1e-8\n",
    "        Numerical tolerance for equality check\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    is_reversible : bool\n",
    "        True if detailed balance holds\n",
    "    max_violation : float\n",
    "        Maximum absolute difference |pi_i * P_ij - pi_j * P_ji|\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    pi = np.asarray(pi, float)\n",
    "    n = P.shape[0]\n",
    "    \n",
    "    # Check detailed balance: pi[i] * P[i,j] = pi[j] * P[j,i] for all i,j\n",
    "    max_violation = 0.0\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            forward_rate = pi[i] * P[i, j]\n",
    "            backward_rate = pi[j] * P[j, i]\n",
    "            violation = abs(forward_rate - backward_rate)\n",
    "            max_violation = max(max_violation, violation)\n",
    "    \n",
    "    is_reversible = (max_violation < tol)\n",
    "    \n",
    "    return is_reversible, float(max_violation)\n",
    "\n",
    "def is_reversible_chain(P, pi=None, tol=1e-8):\n",
    "    \"\"\"\n",
    "    Check if a Markov chain is reversible.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : array-like\n",
    "        Transition matrix\n",
    "    pi : array-like, optional\n",
    "        Stationary distribution. If None, computes it automatically\n",
    "    tol : float, default=1e-8\n",
    "        Numerical tolerance\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    reversible : bool\n",
    "        True if chain is reversible\n",
    "    message : str\n",
    "        Explanation\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, float)\n",
    "    \n",
    "    # Check if it's a valid transition matrix\n",
    "    if not is_transition_matrix(P):\n",
    "        return False, \"Not a valid transition matrix\"\n",
    "    \n",
    "    # Get stationary distribution if not provided\n",
    "    if pi is None:\n",
    "        # Check if chain has unique stationary distribution\n",
    "        has_stat, reason = has_stationary_distribution(P)\n",
    "        if not has_stat:\n",
    "            return False, f\"Cannot check reversibility: {reason}\"\n",
    "        pi = stationary_distribution(P)\n",
    "    \n",
    "    # Check detailed balance\n",
    "    is_rev, max_viol = check_detailed_balance(P, pi, tol)\n",
    "    \n",
    "    if is_rev:\n",
    "        return True, f\"Chain is reversible (max violation: {max_viol:.2e})\"\n",
    "    else:\n",
    "        return False, f\"Chain is not reversible (max violation: {max_viol:.2e})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False, False, False)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PART 5\n",
    "#------------------------REVERSIBLE-----------------\n",
    "# Answer each one with a True or False\n",
    "\n",
    "problem3_A_is_reversible = is_reversible_chain(problem3_A)[0]\n",
    "problem3_B_is_reversible = is_reversible_chain(problem3_B)[0]\n",
    "problem3_C_is_reversible = is_reversible_chain(problem3_C)[0]\n",
    "problem3_D_is_reversible = is_reversible_chain(problem3_D)[0]\n",
    "\n",
    "problem3_A_is_reversible, problem3_B_is_reversible, problem3_C_is_reversible, problem3_D_is_reversible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "lx_assignment_number": "vB",
  "lx_course_instance": "2023",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
