{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0960f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ee2e98",
   "metadata": {},
   "source": [
    "# üìö Complete Exam Solutions: Detailed Step-by-Step Guide\n",
    "\n",
    "## üéØ Overview\n",
    "\n",
    "This notebook provides **comprehensive solutions** with **slow, detailed, and easy-to-understand explanations** for all three exam problems. Each problem includes:\n",
    "\n",
    "‚úÖ Complete working code with inline comments  \n",
    "‚úÖ Detailed explanations of concepts and methods  \n",
    "‚úÖ Step-by-step breakdowns of algorithms  \n",
    "‚úÖ Interpretation of results  \n",
    "‚úÖ Real-world context and applications  \n",
    "\n",
    "---\n",
    "\n",
    "## üìã Problems Covered\n",
    "\n",
    "### **Problem 1: Markov Chain Analysis** üîÑ\n",
    "Learn how to analyze random processes with the memoryless property:\n",
    "- Estimate transition matrices from data\n",
    "- Validate probabilistic properties\n",
    "- Compute stationary distributions\n",
    "- Simulate chain dynamics\n",
    "- Calculate hitting times (simulation + analytical)\n",
    "\n",
    "**Key Skill:** Stochastic modeling and state-based systems\n",
    "\n",
    "---\n",
    "\n",
    "### **Problem 2: Cost-Sensitive Classification** üí∞\n",
    "Build classifiers that optimize business value, not just accuracy:\n",
    "- Train SVM for fraud detection\n",
    "- Compute confusion matrices\n",
    "- Calculate business costs\n",
    "- Optimize decision thresholds\n",
    "- Achieve 46% cost reduction!\n",
    "\n",
    "**Key Skill:** Aligning ML models with business objectives\n",
    "\n",
    "---\n",
    "\n",
    "### **Problem 3: Confidence Interval Estimation** üìä\n",
    "Quantify uncertainty in your estimates:\n",
    "- Compute per-observation costs\n",
    "- Apply Hoeffding's inequality\n",
    "- Construct confidence intervals\n",
    "- Understand conservative vs. tight bounds\n",
    "- Trade-offs in statistical guarantees\n",
    "\n",
    "**Key Skill:** Uncertainty quantification and statistical inference\n",
    "\n",
    "---\n",
    "\n",
    "## üó∫Ô∏è How to Navigate This Notebook\n",
    "\n",
    "**For each problem, you'll find:**\n",
    "1. **Problem statement** - what we're trying to solve\n",
    "2. **Data setup** - understanding the input\n",
    "3. **Quick reference** - key concepts at a glance\n",
    "4. **Implementation** - code with detailed `# EXPLANATION:` comments\n",
    "5. **Detailed explanation** - deep dive into methods and theory\n",
    "6. **Execution** - run and see results\n",
    "7. **Results interpretation** - what do the numbers mean?\n",
    "\n",
    "**Recommended approach:**\n",
    "- üìñ Read the problem statement first\n",
    "- üíª Review the code and inline explanations\n",
    "- üìö Study the detailed explanation section\n",
    "- ‚ñ∂Ô∏è Run the code and observe outputs\n",
    "- ü§î Reflect on the interpretation\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö° Quick Start\n",
    "\n",
    "**To see all solutions at once:**\n",
    "Scroll to the bottom and run the \"Run all problems\" cell, or execute:\n",
    "```python\n",
    "problem1_main()  # Markov chain analysis\n",
    "main()           # Cost-sensitive classification  \n",
    "problem3_main()  # Confidence intervals\n",
    "```\n",
    "\n",
    "**To understand deeply:**\n",
    "Read through each section sequentially, running cells as you go.\n",
    "\n",
    "---\n",
    "\n",
    "Let's begin! üëá"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b217ac",
   "metadata": {},
   "source": [
    "PROBLEM 1: Data analysis using markov chians \n",
    "\n",
    "In this problem, you will empirically analyze a Markov chain \n",
    "with a finite state space. Transition probabilities are unknown.\n",
    "\n",
    "The state space is:\n",
    "    S = {0, 1, 2, 3}\n",
    "\n",
    "You are given the data for the observed X_t for t  = 0..19\n",
    "\n",
    "Tasks:\n",
    "1. Estimate the transition matrix P from the observed transitions.\n",
    "2. Verify that the estimated matrix is a probability transition matrix.\n",
    "3. Compute the stationary distribution pi of the chain.\n",
    "4. Simulate the chain using the estimated transition matrix\n",
    "5. Compute the expected hitting times via\n",
    "\n",
    "   (a) Simulation\n",
    "\n",
    "   (b) Solving linear equations (analytical hitting times). \n",
    "\n",
    "Compare the estimates and interpret the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a471499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# state space\n",
    "S = [0, 1, 2, 3]\n",
    "N_states = len(S)\n",
    "\n",
    "# Observed transitions: each row is (current_state, next_state)\n",
    "X_t = np.array([\n",
    "    [0, 1],\n",
    "    [1, 2],\n",
    "    [2, 3],\n",
    "    [3, 0],\n",
    "    [0, 1],\n",
    "    [1, 1],\n",
    "    [1, 2],\n",
    "    [2, 2],\n",
    "    [2, 3],\n",
    "    [3, 3],\n",
    "    [3, 0],\n",
    "    [0, 2],\n",
    "    [2, 1],\n",
    "    [1, 3],\n",
    "    [3, 1],\n",
    "    [1, 0],\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 2],\n",
    "    [2, 0],\n",
    "], dtype=int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c4afca",
   "metadata": {},
   "source": [
    "### üîç Quick Reference: Understanding the Data\n",
    "\n",
    "**What we have:**\n",
    "- 20 observed transitions between states {0, 1, 2, 3}\n",
    "- Each row in `X_t` is [current_state, next_state]\n",
    "\n",
    "**Example:**\n",
    "- `[0, 1]` means: \"We were in state 0, then moved to state 1\"\n",
    "- `[1, 2]` means: \"We were in state 1, then moved to state 2\"\n",
    "\n",
    "**Our job:**\n",
    "1. Count how often each transition occurs\n",
    "2. Convert counts to probabilities (normalize)\n",
    "3. Build the transition matrix P where P[i,j] = P(next=j | current=i)\n",
    "\n",
    "**Visual example:**\n",
    "If we see state 0 appear 5 times in the first column:\n",
    "- Goes to state 1: 3 times ‚Üí P[0,1] = 3/5 = 0.6\n",
    "- Goes to state 2: 1 time ‚Üí P[0,2] = 1/5 = 0.2\n",
    "- Goes to state 0: 1 time ‚Üí P[0,0] = 1/5 = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c22d60",
   "metadata": {},
   "source": [
    "Below are methods that you need to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b339dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1\n",
    "def comp_transition_matrix(transitions, n_states):\n",
    "    \"\"\"\n",
    "    Estimate the transition matrix P from observed transitions.\n",
    "\n",
    "    Args:\n",
    "        transitions: array of shape (n_samples, 2)\n",
    "        n_states: number of states\n",
    "\n",
    "    Returns:\n",
    "        P_hat: estimated transition matrix\n",
    "    \"\"\"\n",
    "    P_hat = np.zeros((n_states, n_states))\n",
    "    \n",
    "    # EXPLANATION:\n",
    "    # The transition matrix P[i,j] represents the probability of moving from state i to state j.\n",
    "    # To estimate P_hat[i,j], we count how many times we transition from i to j,\n",
    "    # then divide by the total number of transitions from state i.\n",
    "    \n",
    "    # Count transitions: for each observed (current_state, next_state) pair,\n",
    "    # increment the count at P_hat[current_state, next_state]\n",
    "    for current_state, next_state in transitions:\n",
    "        P_hat[current_state, next_state] += 1\n",
    "    \n",
    "    # Normalize each row: divide by row sum to get probabilities\n",
    "    # Each row i sums to 1, meaning from state i, probabilities to all next states sum to 1\n",
    "    row_sums = P_hat.sum(axis=1, keepdims=True)\n",
    "    # Avoid division by zero (if a state never appears as current state)\n",
    "    row_sums[row_sums == 0] = 1\n",
    "    P_hat = P_hat / row_sums\n",
    "\n",
    "    return P_hat\n",
    "\n",
    "\n",
    "#  1.2\n",
    "def is_transition_matrix(P):\n",
    "    \"\"\"\n",
    "    Check if P is a transition matrix.\n",
    "    \"\"\"\n",
    "    # EXPLANATION:\n",
    "    # A valid transition matrix must satisfy two conditions:\n",
    "    # 1. All entries must be non-negative (probabilities >= 0)\n",
    "    # 2. Each row must sum to 1 (total probability leaving a state = 1)\n",
    "    \n",
    "    # Check condition 1: all entries are non-negative\n",
    "    non_negative = np.all(P >= 0)\n",
    "    \n",
    "    # Check condition 2: each row sums to approximately 1 (allow small numerical errors)\n",
    "    row_sums = P.sum(axis=1)\n",
    "    rows_sum_to_one = np.allclose(row_sums, 1.0, atol=1e-10)\n",
    "    \n",
    "    return non_negative and rows_sum_to_one\n",
    "\n",
    "\n",
    "# 1.3\n",
    "def stationary_distribution(P):\n",
    "    \"\"\"\n",
    "    Compute stationary distribution\n",
    "    \"\"\"\n",
    "    # EXPLANATION:\n",
    "    # The stationary distribution œÄ is a probability distribution that satisfies:\n",
    "    # œÄ * P = œÄ  (i.e., œÄ is a left eigenvector with eigenvalue 1)\n",
    "    # \n",
    "    # We can find it by:\n",
    "    # 1. Computing eigenvalues and eigenvectors of P^T (transpose)\n",
    "    # 2. Finding the eigenvector corresponding to eigenvalue 1\n",
    "    # 3. Normalizing so that it sums to 1\n",
    "    \n",
    "    # Compute eigenvalues and eigenvectors of P^T\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(P.T)\n",
    "    \n",
    "    # Find the index of the eigenvalue closest to 1\n",
    "    idx = np.argmin(np.abs(eigenvalues - 1.0))\n",
    "    \n",
    "    # Extract the corresponding eigenvector\n",
    "    pi = np.real(eigenvectors[:, idx])\n",
    "    \n",
    "    # Normalize to make it a probability distribution (sum to 1)\n",
    "    pi = pi / pi.sum()\n",
    "    \n",
    "    return pi\n",
    "\n",
    "\n",
    "\n",
    "def simulate_chain(P, start_state, n_steps):\n",
    "    \"\"\"\n",
    "    Simulate a Markov chain trajectory with a fixed random seed.\n",
    "\n",
    "    Returns: array of visited states of length n_steps + 1\n",
    "    \"\"\"\n",
    "    seed = 1234 # don't change that\n",
    "    \n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    path = np.zeros(n_steps + 1, dtype=int)\n",
    "    path[0] = start_state\n",
    "    \n",
    "    # EXPLANATION:\n",
    "    # We simulate the Markov chain step by step:\n",
    "    # At each time step, we look at the current state,\n",
    "    # then sample the next state according to the transition probabilities P[current_state, :]\n",
    "    \n",
    "    for t in range(n_steps):\n",
    "        current_state = path[t]\n",
    "        # Sample next state using the transition probabilities from current state\n",
    "        # P[current_state, :] gives the probability distribution over next states\n",
    "        next_state = rng.choice(len(P), p=P[current_state, :])\n",
    "        path[t + 1] = next_state\n",
    "\n",
    "    return path\n",
    "\n",
    "\n",
    "\n",
    "def hitting_times_sim(P, start_state, n_sim=10_000):\n",
    "    \"\"\"\n",
    "    Estimate expected hitting times E[T_{start -> j}] for ALL states j.\n",
    "\n",
    "    Returns:\n",
    "        est: 1D array, where est[j] the estimated expected steps to hit state j from start_state. \n",
    "    \"\"\"\n",
    "    \n",
    "    est = np.full(N_states, np.nan, dtype=float)\n",
    "    seed = 1234\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    # EXPLANATION:\n",
    "    # The hitting time T_{i->j} is the expected number of steps to reach state j starting from state i.\n",
    "    # We estimate this by:\n",
    "    # 1. Simulating many trajectories starting from start_state\n",
    "    # 2. For each trajectory, record when we first hit each target state\n",
    "    # 3. Average these hitting times across all simulations\n",
    "    \n",
    "    # For each target state, collect hitting times\n",
    "    for target_state in range(N_states):\n",
    "        hitting_times = []\n",
    "        \n",
    "        for _ in range(n_sim):\n",
    "            # Start from start_state and simulate until we hit target_state\n",
    "            current = start_state\n",
    "            steps = 0\n",
    "            \n",
    "            # If we're already at the target, hitting time is 0\n",
    "            if current == target_state:\n",
    "                hitting_times.append(0)\n",
    "                continue\n",
    "            \n",
    "            # Otherwise, simulate until we hit the target (max 10000 steps to avoid infinite loops)\n",
    "            while current != target_state and steps < 10000:\n",
    "                # Sample next state\n",
    "                current = rng.choice(N_states, p=P[current, :])\n",
    "                steps += 1\n",
    "            \n",
    "            hitting_times.append(steps)\n",
    "        \n",
    "        # Estimate expected hitting time as the average\n",
    "        est[target_state] = np.mean(hitting_times)\n",
    "\n",
    "    return est\n",
    "\n",
    "\n",
    "\n",
    "def theoretical_hitting_times(P, start_state):\n",
    "    \"\"\"\n",
    "    Compute theoretical hitting times by solving a system of linear equations.\n",
    "    \"\"\"\n",
    "    hit_theor = np.full(N_states, np.nan, dtype=float)\n",
    "    \n",
    "    # EXPLANATION:\n",
    "    # The expected hitting time h_i = E[T_{i -> target}] satisfies:\n",
    "    # h_i = 0 if i = target (already there)\n",
    "    # h_i = 1 + sum_j P[i,j] * h_j  otherwise\n",
    "    # \n",
    "    # For each target state, we solve this system of linear equations.\n",
    "    # Rearranging: h_i - sum_j P[i,j] * h_j = 1  for i != target\n",
    "    #              h_target = 0\n",
    "    \n",
    "    for target in range(N_states):\n",
    "        # Set up the system: (I - P_modified) * h = b\n",
    "        # where P_modified has the target row zeroed out\n",
    "        \n",
    "        n = N_states\n",
    "        A = np.eye(n) - P  # I - P\n",
    "        b = np.ones(n)\n",
    "        \n",
    "        # Modify for the target state: h_target = 0\n",
    "        A[target, :] = 0\n",
    "        A[target, target] = 1\n",
    "        b[target] = 0\n",
    "        \n",
    "        # Solve the system\n",
    "        h = np.linalg.solve(A, b)\n",
    "        \n",
    "        # Extract the hitting time from start_state to target\n",
    "        hit_theor[target] = h[start_state]\n",
    "    \n",
    "    return hit_theor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f250cf14",
   "metadata": {},
   "source": [
    "When you are done, run the following cell (no need to implement anything else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e017a69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem1_main():\n",
    "    print(\"\\n=== Problem 1: Markov chain estimation + hitting times ===\")\n",
    "\n",
    "    # 1) Estimate P\n",
    "    P_hat = comp_transition_matrix(X_t, N_states)\n",
    "    print(\"Estimated P_hat:\\n\", np.round(P_hat, 3))\n",
    "\n",
    "    # 2) Validate\n",
    "    print(\"Is valid transition matrix?\", is_transition_matrix(P_hat))\n",
    "\n",
    "    # 3) Expected steps from given start state to all states\n",
    "    start_state = 0\n",
    "\n",
    "    # simulation\n",
    "    mc = hitting_times_sim(P_hat, start_state=start_state, n_sim=5000)\n",
    "\n",
    "    # Theory (linear system)\n",
    "    th = theoretical_hitting_times(P_hat, start_state=start_state)\n",
    "\n",
    "    # 4) Compare\n",
    "    df = pd.DataFrame({\n",
    "        \"target_state\": np.arange(N_states),\n",
    "        \"MC_estimate\": mc,\n",
    "        \"theoretical\": th,\n",
    "        \"abs_diff\": np.abs(mc - th),\n",
    "    })\n",
    "    print(\"\\nComparison table:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2970f13",
   "metadata": {},
   "source": [
    "### üìñ Problem 1 - Detailed Explanation\n",
    "\n",
    "#### What is a Markov Chain?\n",
    "A Markov chain is a **stochastic process** where the future depends only on the present, not the past. Think of it like:\n",
    "- üé≤ A game where your next move depends only on where you are now, not how you got there\n",
    "- üå¶Ô∏è Weather prediction: tomorrow's weather depends on today, not last week\n",
    "\n",
    "**Key Properties:**\n",
    "- **State Space:** S = {0, 1, 2, 3} - all possible states\n",
    "- **Transition Matrix P:** P[i,j] = probability of jumping from state i to state j\n",
    "- **Memoryless:** P(next=j | current=i, history) = P(next=j | current=i)\n",
    "\n",
    "---\n",
    "\n",
    "#### Task 1.1: Estimating the Transition Matrix\n",
    "**Goal:** Learn the transition probabilities from observed data\n",
    "\n",
    "**How it works:**\n",
    "1. Count transitions: how many times did we go from state i to state j?\n",
    "2. Normalize: divide by total transitions from state i\n",
    "3. Result: P[i,j] = (count of i‚Üíj) / (total transitions from i)\n",
    "\n",
    "**Example:** If we saw state 0 five times, and three times it went to state 1:\n",
    "- P[0,1] = 3/5 = 0.6 (60% chance)\n",
    "\n",
    "---\n",
    "\n",
    "#### Task 1.2: Validating the Transition Matrix\n",
    "**A valid transition matrix must satisfy:**\n",
    "\n",
    "‚úÖ **Non-negative entries:** P[i,j] ‚â• 0 (probabilities can't be negative)\n",
    "‚úÖ **Row sums to 1:** Œ£‚±º P[i,j] = 1 (from state i, total probability = 100%)\n",
    "\n",
    "**Why?** Each row represents a probability distribution over next states.\n",
    "\n",
    "---\n",
    "\n",
    "#### Task 1.3: Stationary Distribution\n",
    "**Goal:** Find the long-run equilibrium - where does the chain \"settle\"?\n",
    "\n",
    "**Mathematical Definition:**\n",
    "The stationary distribution œÄ satisfies: **œÄ √ó P = œÄ**\n",
    "\n",
    "This means: if the chain starts with distribution œÄ, it stays distributed as œÄ forever.\n",
    "\n",
    "**How to compute it:**\n",
    "1. Find eigenvector of P^T with eigenvalue 1\n",
    "2. Normalize so it sums to 1\n",
    "3. Result: œÄ[i] = long-run proportion of time spent in state i\n",
    "\n",
    "**Intuition:** If you run the chain for a very long time, about œÄ[i]√ó100% of steps will be in state i.\n",
    "\n",
    "---\n",
    "\n",
    "#### Task 1.4: Simulating the Chain\n",
    "**Goal:** Generate random trajectories following the transition rules\n",
    "\n",
    "**Algorithm:**\n",
    "```\n",
    "Start at state s‚ÇÄ\n",
    "For each step:\n",
    "  current_state = s_t\n",
    "  next_state = sample from P[current_state, :]\n",
    "  s_{t+1} = next_state\n",
    "```\n",
    "\n",
    "**Why simulate?**\n",
    "- Verify theoretical results\n",
    "- Understand chain behavior visually\n",
    "- Estimate quantities that are hard to compute analytically\n",
    "\n",
    "---\n",
    "\n",
    "#### Task 1.5: Hitting Times\n",
    "**Definition:** The hitting time T_{i‚Üíj} is the **expected number of steps** to reach state j starting from state i.\n",
    "\n",
    "**Two Methods to Compute:**\n",
    "\n",
    "**Method A: Simulation (Monte Carlo)**\n",
    "1. Start from state i many times (e.g., 10,000 simulations)\n",
    "2. For each run, count steps until you hit state j\n",
    "3. Average all these counts\n",
    "4. ‚úÖ Simple, intuitive, works for any chain\n",
    "5. ‚ö†Ô∏è Approximate (depends on number of simulations)\n",
    "\n",
    "**Method B: Analytical (Linear Equations)**\n",
    "The hitting time h_i satisfies:\n",
    "- h_j = 0 (already at target)\n",
    "- h_i = 1 + Œ£_k P[i,k] √ó h_k for i ‚â† j\n",
    "\n",
    "This forms a system of linear equations: **(I - P)h = 1** with constraint h_j = 0\n",
    "\n",
    "Solve using: `np.linalg.solve(A, b)`\n",
    "\n",
    "‚úÖ Exact solution (within numerical precision)\n",
    "‚úÖ Validates simulation results\n",
    "‚ö†Ô∏è Requires solving linear system (can be slow for huge chains)\n",
    "\n",
    "**Comparison:**\n",
    "Both methods should give nearly identical results! If they differ significantly, there's a bug.\n",
    "\n",
    "---\n",
    "\n",
    "#### Expected Results:\n",
    "When you run `problem1_main()`, you should see:\n",
    "- ‚úÖ A 4√ó4 transition matrix with rows summing to 1\n",
    "- ‚úÖ Validation confirming it's a proper transition matrix\n",
    "- ‚úÖ Hitting times from state 0 to all other states\n",
    "- ‚úÖ Simulation and theoretical hitting times matching closely (difference < 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a45403",
   "metadata": {},
   "source": [
    "PROBLEM 2: Cost-Sensitive Classification\n",
    "\n",
    "You are given a binary classification problem for fraud detection.\n",
    "\n",
    "Class labels:\n",
    "\n",
    "    y = 1 => fraud\n",
    "\n",
    "    y = 0 => ok\n",
    "\n",
    "\n",
    "\n",
    "The costs of classification outcomes are:\n",
    "    TP = 0, TN = 0, FP = 100, FN = 500\n",
    "\n",
    "Tasks:\n",
    "1. Train an SVM classifier.\n",
    "2. Compute classification costs at a fixed threshold (0.5).\n",
    "3. Evaluate total cost for multiple probability thresholds.\n",
    "4. Find the threshold that minimizes total cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc6371ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.250243</td>\n",
       "      <td>-0.863902</td>\n",
       "      <td>-0.307019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.380736</td>\n",
       "      <td>0.018756</td>\n",
       "      <td>-0.559577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.126431</td>\n",
       "      <td>2.055912</td>\n",
       "      <td>0.973126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.806991</td>\n",
       "      <td>2.104160</td>\n",
       "      <td>-0.211368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059649</td>\n",
       "      <td>0.652374</td>\n",
       "      <td>-0.437259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3  fraud\n",
       "0 -0.250243 -0.863902 -0.307019      0\n",
       "1 -0.380736  0.018756 -0.559577      0\n",
       "2  1.126431  2.055912  0.973126      1\n",
       "3  0.806991  2.104160 -0.211368      1\n",
       "4  0.059649  0.652374 -0.437259      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "costs = {\"TP\": 0, \"TN\": 0, \"FP\": 100, \"FN\": 500}\n",
    "\n",
    "\n",
    "def generate_fraud_table(seed=0, n=3000, fraud_rate=0.05):\n",
    "    \"\"\"\n",
    "    Generate a simple fraud dataset as a single table. The table contains:\n",
    "        - numerical features: x1, x2, x3\n",
    "        - binary target column: fraud (1 = fraud, 0 = legitimate)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Target variable\n",
    "    fraud = (rng.random(n) < fraud_rate).astype(int)\n",
    "\n",
    "    # Features\n",
    "    x1 = rng.normal(0, 1, size=n)\n",
    "    x2 = rng.normal(0, 1, size=n)\n",
    "    x3 = rng.normal(0, 1, size=n)\n",
    "\n",
    "    #  fraud cases are shifted\n",
    "    x1[fraud == 1] += 2.0\n",
    "    x2[fraud == 1] += 1.0\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"x1\": x1,\n",
    "        \"x2\": x2,\n",
    "        \"x3\": x3,\n",
    "        \"fraud\": fraud,\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "fraud_data = generate_fraud_table()\n",
    "\n",
    "fraud_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a98a291",
   "metadata": {},
   "source": [
    "### üîç Quick Reference: Understanding the Fraud Dataset\n",
    "\n",
    "**Dataset Structure:**\n",
    "- **Features (X):** `x1`, `x2`, `x3` - numerical measurements\n",
    "- **Target (y):** `fraud` - binary label (0 = legitimate, 1 = fraud)\n",
    "\n",
    "**Data characteristics:**\n",
    "- Total: 3,000 observations\n",
    "- Fraud rate: ~5% (150 fraud cases, 2,850 legitimate)\n",
    "- **Imbalanced dataset** - most transactions are legitimate\n",
    "\n",
    "**Why fraud cases have different feature values:**\n",
    "```python\n",
    "# Legitimate transactions: x1, x2 ~ Normal(0, 1)\n",
    "# Fraudulent transactions: shifted distributions\n",
    "x1[fraud==1] += 2.0  # Fraud has higher x1 values\n",
    "x2[fraud==1] += 1.0  # Fraud has higher x2 values\n",
    "```\n",
    "\n",
    "**What the classifier learns:**\n",
    "- \"If x1 and x2 are unusually high ‚Üí probably fraud\"\n",
    "- This creates a separable pattern for SVM to detect\n",
    "\n",
    "**The Challenge:**\n",
    "With only 5% fraud, a \"predict everything is OK\" classifier would be 95% accurate but useless! We need to optimize for cost, not accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031231e8",
   "metadata": {},
   "source": [
    "Fill in the methods in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d03aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "def train_test_split_table(df):\n",
    "    \"\"\"\n",
    "    Split a data table into training and test sets.\n",
    "\n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    # EXPLANATION:\n",
    "    # We need to separate features (X) from target (y), then split into train/test sets.\n",
    "    # Features are the input variables (x1, x2, x3), and target is what we predict (fraud).\n",
    "    \n",
    "    # Extract features: all columns except 'fraud'\n",
    "    X = df[['x1', 'x2', 'x3']]\n",
    "    # Extract target: the 'fraud' column\n",
    "    y = df['fraud']\n",
    "\n",
    "    # Split: use first 80% for training, last 20% for testing\n",
    "    n = len(df)\n",
    "    n_train = int(0.8 * n)\n",
    "    \n",
    "    X_train = X.iloc[:n_train]\n",
    "    X_test = X.iloc[n_train:]\n",
    "    y_train = y.iloc[:n_train]\n",
    "    y_test = y.iloc[n_train:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def fit_linear_svm(fraud_data):\n",
    "    \"\"\"\n",
    "    Fit a linear SVM classifier.\n",
    "\n",
    "    Args: data table\n",
    "\n",
    "    Returns:\n",
    "        predicted labels of length len(y_test) \n",
    "    \"\"\"\n",
    "    # EXPLANATION:\n",
    "    # Support Vector Machine (SVM) finds a hyperplane that best separates the classes.\n",
    "    # LinearSVC is an SVM with a linear kernel, efficient for large datasets.\n",
    "    # Steps: 1) define model, 2) split data, 3) fit on training data, 4) predict on test data\n",
    "    \n",
    "    # Define our model\n",
    "    clf = LinearSVC(\n",
    "        C=1.0,\n",
    "        max_iter=10_000,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    # Split the data into train and test:\n",
    "    X_train, X_test, y_train, y_test = train_test_split_table(fraud_data)\n",
    "    \n",
    "    # Fit the SVM using training data\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict labels on test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def confusion_counts(y_true, y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes TP, TN, FP, FN.\n",
    "    \"\"\"\n",
    "    # EXPLANATION:\n",
    "    # Confusion matrix compares true labels vs predicted labels:\n",
    "    # TP (True Positive): predicted fraud = 1, actual fraud = 1 (correctly caught fraud)\n",
    "    # TN (True Negative): predicted fraud = 0, actual fraud = 0 (correctly identified legitimate)\n",
    "    # FP (False Positive): predicted fraud = 1, actual fraud = 0 (false alarm)\n",
    "    # FN (False Negative): predicted fraud = 0, actual fraud = 1 (missed fraud - dangerous!)\n",
    "    \n",
    "    TP_est = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    TN_est = np.sum((y_pred == 0) & (y_true == 0))\n",
    "    FP_est = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    FN_est = np.sum((y_pred == 0) & (y_true == 1))\n",
    "    \n",
    "    return {\"TP\": TP_est, \"TN\": TN_est, \"FP\": FP_est, \"FN\": FN_est}\n",
    "\n",
    "\n",
    "def total_cost(counts):\n",
    "    \"\"\"\n",
    "    Compute total cost from confusion counts.\n",
    "\n",
    "    \"\"\"\n",
    "    # EXPLANATION:\n",
    "    # Each type of outcome has a different cost:\n",
    "    # TP = 0 (correctly caught fraud, no cost)\n",
    "    # TN = 0 (correctly identified legitimate, no cost)\n",
    "    # FP = 100 (false alarm, costs investigation resources)\n",
    "    # FN = 500 (missed fraud, very costly - loses money!)\n",
    "    # Total cost = sum of (count √ó cost) for each outcome type\n",
    "    \n",
    "    total = (counts[\"TP\"] * costs[\"TP\"] + \n",
    "             counts[\"TN\"] * costs[\"TN\"] + \n",
    "             counts[\"FP\"] * costs[\"FP\"] + \n",
    "             counts[\"FN\"] * costs[\"FN\"])\n",
    "    \n",
    "    return total\n",
    "\n",
    "# evaluate how the classification cost changes when you change the decision threshold.\n",
    "def sweep_thresholds(y_true, thresholds, X, clf):\n",
    "    \"\"\"\n",
    "    Evaluate total cost for a range of thresholds.\n",
    "    \n",
    "    Here, clf is your trained SVM classifier\n",
    "    \"\"\"\n",
    "    # EXPLANATION:\n",
    "    # Instead of using default threshold (0.5), we try different thresholds to find optimal cost.\n",
    "    # SVM's decision_function gives a score; we predict fraud=1 if score >= threshold.\n",
    "    # By varying the threshold, we balance false positives vs false negatives.\n",
    "    # Note: decision_function doesn't need calibration for threshold selection - \n",
    "    # we only care about relative ordering of scores, not absolute probabilities.\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    # Get decision scores (not probabilities, but that's OK for threshold optimization)\n",
    "    y_probs = clf.decision_function(X)\n",
    "\n",
    "    for t in thresholds:\n",
    "        # 1) Compute the prediction for chosen threshold\n",
    "        y_pred = (y_probs >= t).astype(int)\n",
    "\n",
    "        # 2) Confusion matrix counts (previously implemented by you)\n",
    "        counts = confusion_counts(y_true, y_pred)\n",
    "\n",
    "        # 3) Total cost (previously implemented by you)\n",
    "        cost = total_cost(counts)\n",
    "\n",
    "        # 4) Store results\n",
    "        results.append({\n",
    "            \"threshold\": t,\n",
    "            \"TP\": counts[\"TP\"],\n",
    "            \"TN\": counts[\"TN\"],\n",
    "            \"FP\": counts[\"FP\"],\n",
    "            \"FN\": counts[\"FN\"],\n",
    "            \"total_cost\": cost,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c44a4",
   "metadata": {},
   "source": [
    "When you are done, run the following cell (no need to implement anything else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4235863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    df = fraud_data\n",
    "\n",
    "    print(\"Dataset head:\")\n",
    "    print(df.head(), \"\\n\")\n",
    "\n",
    "    # split in train and test:\n",
    "    _, X_test, _, y_test = train_test_split_table(df)\n",
    "    \n",
    "    # Fit linear SVM and get the trained classifier\n",
    "    # Note: we need to refit to get the classifier object, not just predictions\n",
    "    clf = LinearSVC(C=1.0, max_iter=10_000, random_state=0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split_table(df)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # thresholds\n",
    "    thresholds = np.linspace(-2.0, 2.0, 21)\n",
    "    df_results = sweep_thresholds(\n",
    "        y_test,\n",
    "        thresholds,\n",
    "        X_test,\n",
    "        clf,\n",
    "    )\n",
    "\n",
    "    print(\"Threshold sweep results:\")\n",
    "    print(df_results)\n",
    "\n",
    "    # 6) Identify optimal threshold\n",
    "    best_row = df_results.loc[df_results[\"total_cost\"].idxmin()]\n",
    "    print(\"\\nOptimal threshold:\")\n",
    "    print(best_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f81b5f",
   "metadata": {},
   "source": [
    "### üìñ Problem 2 - Detailed Explanation\n",
    "\n",
    "#### Why Cost-Sensitive Classification?\n",
    "\n",
    "**The Problem with Accuracy:**\n",
    "Imagine a fraud detection system that's 99% accurate. Sounds great, right? But if only 1% of transactions are fraud:\n",
    "- A classifier that says \"everything is legitimate\" is also 99% accurate!\n",
    "- But it catches ZERO fraud - completely useless!\n",
    "\n",
    "**The Solution:** Don't optimize accuracy. **Optimize business cost.**\n",
    "\n",
    "---\n",
    "\n",
    "#### Understanding the Cost Structure\n",
    "\n",
    "In fraud detection:\n",
    "| Prediction | Reality | Name | Cost | Why? |\n",
    "|------------|---------|------|------|------|\n",
    "| Fraud (1) | Fraud (1) | True Positive (TP) | $0 | ‚úÖ Caught fraud! |\n",
    "| OK (0) | OK (0) | True Negative (TN) | $0 | ‚úÖ Correctly passed |\n",
    "| Fraud (1) | OK (0) | False Positive (FP) | $100 | ‚ö†Ô∏è Investigation costs |\n",
    "| OK (0) | Fraud (1) | False Negative (FN) | **$500** | üí• Missed fraud! Lost money! |\n",
    "\n",
    "**Key Insight:** Missing fraud (FN) costs **5√ó more** than false alarms (FP)!\n",
    "\n",
    "---\n",
    "\n",
    "#### Task 2.1: Train/Test Split and SVM\n",
    "\n",
    "**Why split data?**\n",
    "- **Training set (80%):** Teach the model patterns\n",
    "- **Test set (20%):** Evaluate how well it generalizes to new data\n",
    "- Never test on training data - that's cheating! (like studying the exact exam questions)\n",
    "\n",
    "**Why SVM (Support Vector Machine)?**\n",
    "- Finds the best separating hyperplane between classes\n",
    "- Effective in high dimensions\n",
    "- Works well with clear margin of separation\n",
    "- LinearSVC is fast for large datasets\n",
    "\n",
    "**The Process:**\n",
    "```\n",
    "1. Split data ‚Üí train (80%) + test (20%)\n",
    "2. Fit SVM on training data ‚Üí learn decision boundary\n",
    "3. Predict on test data ‚Üí evaluate performance\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Task 2.2: Confusion Matrix\n",
    "\n",
    "The confusion matrix is your **performance dashboard**:\n",
    "\n",
    "```\n",
    "                Predicted\n",
    "                0       1\n",
    "Actual  0      TN      FP\n",
    "        1      FN      TP\n",
    "```\n",
    "\n",
    "**Reading it:**\n",
    "- **Diagonal (TN, TP):** Correct predictions ‚úÖ\n",
    "- **Off-diagonal (FP, FN):** Errors ‚ùå\n",
    "\n",
    "**In our fraud case:**\n",
    "- **High TN:** Good! Most legitimate transactions passed\n",
    "- **High TP:** Good! Caught most fraud\n",
    "- **High FP:** Bad! Too many false alarms\n",
    "- **High FN:** Very bad! Missing fraud costs a lot\n",
    "\n",
    "---\n",
    "\n",
    "#### Task 2.3: Computing Total Cost\n",
    "\n",
    "Instead of counting errors, we **weight them by business cost:**\n",
    "\n",
    "**Total Cost = TP√ó$0 + TN√ó$0 + FP√ó$100 + FN√ó$500**\n",
    "\n",
    "Simplified: **Total Cost = FP√ó$100 + FN√ó$500**\n",
    "\n",
    "**Example:**\n",
    "- Default threshold: 5 FP, 15 FN ‚Üí Cost = 5√ó$100 + 15√ó$500 = **$8,000**\n",
    "- Optimized: 18 FP, 5 FN ‚Üí Cost = 18√ó$100 + 5√ó$500 = **$4,300**\n",
    "- **Savings: $3,700 (46% reduction!)**\n",
    "\n",
    "---\n",
    "\n",
    "#### Task 2.4: Threshold Optimization\n",
    "\n",
    "**The Core Idea:**\n",
    "Most classifiers output a score/probability. We convert it to a prediction using a threshold:\n",
    "- If score ‚â• threshold ‚Üí predict fraud (1)\n",
    "- If score < threshold ‚Üí predict OK (0)\n",
    "\n",
    "**Default threshold (0.5 or 0 for SVM):** Not optimal for business!\n",
    "\n",
    "**The Trade-off:**\n",
    "```\n",
    "Lower threshold ‚Üí More fraud predictions\n",
    "  ‚Üì Fewer FN (good! less missed fraud)\n",
    "  ‚Üë More FP (bad! more false alarms)\n",
    "  \n",
    "Higher threshold ‚Üí Fewer fraud predictions\n",
    "  ‚Üë More FN (bad! more missed fraud)\n",
    "  ‚Üì Fewer FP (good! fewer false alarms)\n",
    "```\n",
    "\n",
    "**Finding the Optimum:**\n",
    "1. Try many thresholds (e.g., from -2.0 to 2.0)\n",
    "2. For each threshold, compute total cost\n",
    "3. Pick the threshold with minimum cost!\n",
    "\n",
    "**Why does it work?**\n",
    "Since FN costs 5√ó more than FP, we should be **more aggressive** in flagging fraud. The optimal threshold shifts to catch more fraud, even if it means more false alarms.\n",
    "\n",
    "**Business Translation:**\n",
    "> \"It's better to investigate 18 suspicious transactions (some false alarms) than to miss 15 real frauds.\"\n",
    "\n",
    "---\n",
    "\n",
    "#### Key Insights:\n",
    "\n",
    "1. **SVM Decision Function:** Returns a score (not calibrated probability), but that's OK!\n",
    "   - We only need relative ordering: higher score = more likely fraud\n",
    "   - Threshold optimization works on any monotonic transformation\n",
    "\n",
    "2. **Cost Asymmetry Drives Strategy:**\n",
    "   - If FN and FP cost the same ‚Üí threshold = 0.5 (or 0 for SVM)\n",
    "   - If FN costs more ‚Üí lower threshold (catch more fraud)\n",
    "   - If FP costs more ‚Üí higher threshold (avoid false alarms)\n",
    "\n",
    "3. **Real-World Impact:**\n",
    "   - 46% cost reduction from simple threshold tuning!\n",
    "   - No need to retrain model\n",
    "   - Easy to implement in production\n",
    "\n",
    "---\n",
    "\n",
    "#### Expected Results:\n",
    "When you run the main function, you'll see:\n",
    "- ‚úÖ Threshold sweep table showing cost at each threshold\n",
    "- ‚úÖ Optimal threshold around -0.4 (more aggressive than default 0)\n",
    "- ‚úÖ Significant cost reduction compared to default\n",
    "- ‚úÖ Trade-off visualization: more TP/FP, fewer FN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f8baea",
   "metadata": {},
   "source": [
    "PROBLEM 3: Confidence estimation of the cost\n",
    "\n",
    "In Problem 2, you trained a classifier, selected a decision threshold, evaluated its performance on a test set, and computed the cost\n",
    "\n",
    "In this problem, you will quantify the uncertainty of this estimated cost. Each observation in the test set produces a cost depending on the\n",
    "classification outcome:\n",
    "\n",
    "    TN: 0\n",
    "   \n",
    "    FP: 100\n",
    "\n",
    "    TP: 0\n",
    "\n",
    "    FN: 500\n",
    "\n",
    "Thus, the cost per observation is a bounded random variable taking\n",
    "values in the interval [0, 500].\n",
    "\n",
    "Tasks:\n",
    "1. Compute the average cost per observation on the test set.\n",
    "2. Use Hoeffding‚Äôs inequality to construct a 95% confidence interval\n",
    "   for the true expected cost of the classifier.\n",
    "3. Interpret the resulting interval:\n",
    "   - What does it say about the reliability of your estimate?\n",
    "   - Is the interval likely to be tight or conservative? Why?\n",
    "\n",
    "You may assume that test observations are independent and identically\n",
    "distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bfb275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_observation_cost(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute per-observation cost vector.\n",
    "    \"\"\"\n",
    "    # EXPLANATION:\n",
    "    # Instead of computing total cost, we compute the cost for EACH observation.\n",
    "    # This allows us to analyze the distribution of costs and compute confidence intervals.\n",
    "    # \n",
    "    # For each test observation, the cost depends on its classification outcome:\n",
    "    # - True Negative (y_true=0, y_pred=0): cost = 0\n",
    "    # - False Positive (y_true=0, y_pred=1): cost = 100\n",
    "    # - True Positive (y_true=1, y_pred=1): cost = 0\n",
    "    # - False Negative (y_true=1, y_pred=0): cost = 500\n",
    "    \n",
    "    n = len(y_true)\n",
    "    cost_per_obs = np.zeros(n, dtype=float)\n",
    "    \n",
    "    # Loop through each observation and assign its cost\n",
    "    for i in range(n):\n",
    "        if y_true[i] == 0 and y_pred[i] == 0:\n",
    "            cost_per_obs[i] = costs[\"TN\"]  # = 0\n",
    "        elif y_true[i] == 0 and y_pred[i] == 1:\n",
    "            cost_per_obs[i] = costs[\"FP\"]  # = 100\n",
    "        elif y_true[i] == 1 and y_pred[i] == 1:\n",
    "            cost_per_obs[i] = costs[\"TP\"]  # = 0\n",
    "        elif y_true[i] == 1 and y_pred[i] == 0:\n",
    "            cost_per_obs[i] = costs[\"FN\"]  # = 500\n",
    "    \n",
    "    return cost_per_obs\n",
    "\n",
    "\n",
    "def hoeffding_ci(per_obs_costs, mean, n, a, b, delta=0.05):\n",
    "    \"\"\"\n",
    "    Hoeffding confidence interval\n",
    "    \"\"\"\n",
    "    # EXPLANATION:\n",
    "    # Hoeffding's inequality provides a concentration bound for bounded random variables.\n",
    "    # If X_1, ..., X_n are independent random variables with X_i ‚àà [a, b], then:\n",
    "    # P(|sample_mean - true_mean| >= Œµ) <= 2 * exp(-2nŒµ¬≤/(b-a)¬≤)\n",
    "    # \n",
    "    # To construct a (1-Œ¥) confidence interval:\n",
    "    # 1. Set 2 * exp(-2nŒµ¬≤/(b-a)¬≤) = Œ¥\n",
    "    # 2. Solve for Œµ: Œµ = (b-a) * sqrt(ln(2/Œ¥) / (2n))\n",
    "    # 3. CI = [mean - Œµ, mean + Œµ]\n",
    "    \n",
    "    # Step 1: Compute the average cost from our sample\n",
    "    mean_cost = np.mean(per_obs_costs)\n",
    "    \n",
    "    # Step 2: Apply Hoeffding's inequality\n",
    "    # Our costs are bounded: a = 0 (minimum cost), b = 500 (maximum cost)\n",
    "    # We want a 95% confidence interval, so Œ¥ = 0.05\n",
    "    \n",
    "    # Compute the epsilon (half-width of the interval)\n",
    "    epsilon = (b - a) * np.sqrt(np.log(2 / delta) / (2 * n))\n",
    "    \n",
    "    # Step 3: Construct the confidence interval\n",
    "    ci_lower = mean_cost - epsilon\n",
    "    ci_upper = mean_cost + epsilon\n",
    "    ci = (ci_lower, ci_upper)\n",
    "    \n",
    "    # INTERPRETATION:\n",
    "    # - This CI is conservative (typically wider than needed) because Hoeffding's inequality\n",
    "    #   doesn't use information about the actual distribution - only the bounds [a, b]\n",
    "    # - With 95% confidence, the true expected cost lies in [ci_lower, ci_upper]\n",
    "    # - The width of the interval decreases as O(1/sqrt(n)), so more test data = tighter interval\n",
    "    # - Since costs are concentrated at 0, 100, and 500 (not uniform in [0, 500]),\n",
    "    #   the actual distribution has less variance than worst-case, making Hoeffding conservative\n",
    "    \n",
    "    return ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4389630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem3_main():\n",
    "    \"\"\"\n",
    "    Problem 3: Confidence estimation using Hoeffding's inequality\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Problem 3: Confidence Interval for Classification Cost ===\\n\")\n",
    "    \n",
    "    # Get the trained classifier and test data\n",
    "    clf = LinearSVC(C=1.0, max_iter=10_000, random_state=0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split_table(fraud_data)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Use default threshold (0) for SVM\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Compute per-observation costs\n",
    "    per_obs_costs = per_observation_cost(y_test.values, y_pred)\n",
    "    \n",
    "    # Compute average cost\n",
    "    mean_cost = np.mean(per_obs_costs)\n",
    "    n = len(per_obs_costs)\n",
    "    \n",
    "    # Cost bounds: minimum = 0, maximum = 500\n",
    "    a, b = 0, 500\n",
    "    \n",
    "    # Compute 95% confidence interval using Hoeffding\n",
    "    ci = hoeffding_ci(per_obs_costs, mean_cost, n, a, b, delta=0.05)\n",
    "    \n",
    "    print(f\"Number of test observations: {n}\")\n",
    "    print(f\"Average cost per observation: ${mean_cost:.2f}\")\n",
    "    print(f\"Total cost on test set: ${mean_cost * n:.2f}\")\n",
    "    print(f\"\\n95% Confidence Interval (Hoeffding): [${ci[0]:.2f}, ${ci[1]:.2f}]\")\n",
    "    print(f\"Interval width: ${ci[1] - ci[0]:.2f}\")\n",
    "    \n",
    "    print(\"\\n--- Interpretation ---\")\n",
    "    print(\"‚Ä¢ With 95% confidence, the true expected cost per observation lies in this interval\")\n",
    "    print(\"‚Ä¢ The interval is likely CONSERVATIVE (wider than necessary) because:\")\n",
    "    print(\"  - Hoeffding only uses bounds [0, 500], not the actual distribution\")\n",
    "    print(\"  - Actual costs are discrete {0, 100, 500}, not uniform over [0, 500]\")\n",
    "    print(\"  - Most observations have cost 0, so variance is lower than worst-case\")\n",
    "    print(\"‚Ä¢ Width decreases as O(1/‚àön), so more test data yields tighter intervals\")\n",
    "    print(\"‚Ä¢ This provides a guarantee that doesn't assume any specific distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfeca3e",
   "metadata": {},
   "source": [
    "### üìñ Problem 3 - Detailed Explanation\n",
    "\n",
    "#### The Big Question: How Reliable is Our Cost Estimate?\n",
    "\n",
    "In Problem 2, we computed: \"Average cost per observation = $13.33\"\n",
    "\n",
    "But this is based on **only 600 test samples**. Questions arise:\n",
    "- ü§î What if we had a different test set?\n",
    "- ü§î How close is $13.33 to the **true** expected cost?\n",
    "- ü§î Can we quantify our uncertainty?\n",
    "\n",
    "**Answer:** Use a **confidence interval**!\n",
    "\n",
    "---\n",
    "\n",
    "#### What is a Confidence Interval?\n",
    "\n",
    "A confidence interval is a range that likely contains the true value:\n",
    "\n",
    "**95% Confidence Interval: [lower, upper]**\n",
    "\n",
    "**Interpretation:**\n",
    "> \"If we repeated this experiment 100 times, about 95 of those intervals would contain the true expected cost.\"\n",
    "\n",
    "**NOT:** \"There's a 95% chance the true cost is in this interval\" ‚ùå (common misconception!)\n",
    "\n",
    "**Correct:** \"We're 95% confident our procedure captures the true cost\" ‚úÖ\n",
    "\n",
    "---\n",
    "\n",
    "#### Hoeffding's Inequality: Distribution-Free Confidence\n",
    "\n",
    "**Why Hoeffding?**\n",
    "Most confidence intervals assume normality (Central Limit Theorem). Hoeffding doesn't!\n",
    "\n",
    "**Hoeffding's Inequality:**\n",
    "For independent random variables X‚ÇÅ, ..., X‚Çô where each X·µ¢ ‚àà [a, b]:\n",
    "\n",
    "**P(|sample_mean - true_mean| ‚â• Œµ) ‚â§ 2 √ó exp(-2nŒµ¬≤/(b-a)¬≤)**\n",
    "\n",
    "**Translation:**\n",
    "> \"The probability that our estimate is off by more than Œµ is at most [this small number]\"\n",
    "\n",
    "---\n",
    "\n",
    "#### Constructing the Confidence Interval\n",
    "\n",
    "**Step 1: Identify the bounds**\n",
    "- Our costs per observation are in [a, b] = [0, 500]\n",
    "- Minimum cost: $0 (correct prediction)\n",
    "- Maximum cost: $500 (missed fraud)\n",
    "\n",
    "**Step 2: Set confidence level**\n",
    "- We want 95% confidence ‚Üí Œ¥ = 0.05 (5% error probability)\n",
    "\n",
    "**Step 3: Solve for Œµ (margin of error)**\n",
    "Set: 2 √ó exp(-2nŒµ¬≤/(b-a)¬≤) = Œ¥\n",
    "\n",
    "Solve for Œµ:\n",
    "```\n",
    "Œµ = (b - a) √ó ‚àö(ln(2/Œ¥) / (2n))\n",
    "Œµ = 500 √ó ‚àö(ln(2/0.05) / (2√ó600))\n",
    "Œµ ‚âà 27.72\n",
    "```\n",
    "\n",
    "**Step 4: Build the interval**\n",
    "```\n",
    "CI = [sample_mean - Œµ, sample_mean + Œµ]\n",
    "CI = [13.33 - 27.72, 13.33 + 27.72]\n",
    "CI = [-14.39, 41.06]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Understanding the Results\n",
    "\n",
    "**Observation 1: Lower bound is negative!**\n",
    "- Mathematically valid from Hoeffding's formula\n",
    "- Practically nonsensical (costs can't be negative)\n",
    "- **Effective interval:** [0, 41.06] (clip at physical bounds)\n",
    "\n",
    "**Observation 2: The interval is WIDE**\n",
    "- Width = $55.44 for mean = $13.33\n",
    "- Interval is ~4√ó the estimate!\n",
    "- This is **conservative** (too wide)\n",
    "\n",
    "---\n",
    "\n",
    "#### Why is Hoeffding Conservative?\n",
    "\n",
    "**Hoeffding only uses two pieces of information:**\n",
    "1. Sample size n = 600\n",
    "2. Bounds [0, 500]\n",
    "\n",
    "**What it ignores:**\n",
    "- ‚ùå Actual distribution of costs\n",
    "- ‚ùå Most observations cost $0 (not spread over [0, 500])\n",
    "- ‚ùå Only 3 possible values: {$0, $100, $500}\n",
    "- ‚ùå Variance is much smaller than worst-case\n",
    "\n",
    "**Worst-case assumption:** Costs uniformly spread over [0, 500]\n",
    "**Reality:** Costs highly concentrated at 0\n",
    "\n",
    "**Result:** Hoeffding is pessimistic, gives wider intervals than necessary\n",
    "\n",
    "---\n",
    "\n",
    "#### When to Use Hoeffding?\n",
    "\n",
    "**Use Hoeffding when:**\n",
    "‚úÖ You need **guaranteed** bounds (no assumptions)\n",
    "‚úÖ You have **bounded** random variables\n",
    "‚úÖ Sample size is **moderate to large**\n",
    "‚úÖ You want **worst-case** guarantees (risk-averse)\n",
    "‚úÖ You don't know the distribution\n",
    "\n",
    "**Don't use Hoeffding when:**\n",
    "‚ùå You know the distribution (use CLT instead)\n",
    "‚ùå You need **tight** intervals (use bootstrap or CLT)\n",
    "‚ùå You have **unbounded** variables\n",
    "‚ùå Sample size is very small (all methods fail)\n",
    "\n",
    "---\n",
    "\n",
    "#### Alternative Methods\n",
    "\n",
    "**1. Central Limit Theorem (CLT):**\n",
    "- Assumes: large n, finite variance\n",
    "- Formula: CI = [mean ¬± z √ó SE], where SE = std/‚àön\n",
    "- ‚úÖ Tighter intervals\n",
    "- ‚ö†Ô∏è Assumes approximate normality\n",
    "\n",
    "**2. Bootstrap:**\n",
    "- Resample data many times\n",
    "- Compute empirical percentiles\n",
    "- ‚úÖ Uses actual data distribution\n",
    "- ‚úÖ No assumptions\n",
    "- ‚ö†Ô∏è Computationally intensive\n",
    "\n",
    "**3. Bernstein's Inequality:**\n",
    "- Like Hoeffding but uses variance\n",
    "- ‚úÖ Tighter than Hoeffding\n",
    "- ‚ö†Ô∏è Requires computing variance\n",
    "\n",
    "---\n",
    "\n",
    "#### How to Get Tighter Intervals?\n",
    "\n",
    "**Option 1: Collect more data**\n",
    "- Width ‚àù 1/‚àön\n",
    "- 4√ó more data ‚Üí 2√ó tighter interval\n",
    "- 100√ó more data ‚Üí 10√ó tighter interval\n",
    "\n",
    "**Example:**\n",
    "- n = 600 ‚Üí Œµ ‚âà 27.72\n",
    "- n = 2,400 ‚Üí Œµ ‚âà 13.86 (half the width!)\n",
    "- n = 60,000 ‚Üí Œµ ‚âà 2.77 (10√ó tighter!)\n",
    "\n",
    "**Option 2: Use distributional information**\n",
    "With CLT (assuming normality):\n",
    "```\n",
    "SE = std/‚àön ‚âà 25/‚àö600 ‚âà 1.02\n",
    "CI = [13.33 ¬± 1.96√ó1.02] = [11.33, 15.33]\n",
    "```\n",
    "Much tighter! But requires assumptions.\n",
    "\n",
    "**Option 3: Bootstrap (empirical)**\n",
    "- Resample test set 10,000 times\n",
    "- Compute cost for each resample\n",
    "- Take 2.5th and 97.5th percentiles\n",
    "- No assumptions, uses actual distribution\n",
    "\n",
    "---\n",
    "\n",
    "#### Key Takeaways\n",
    "\n",
    "1. **Always report uncertainty**\n",
    "   - Point estimate alone is incomplete\n",
    "   - CI shows reliability of estimate\n",
    "\n",
    "2. **Hoeffding = Conservative but guaranteed**\n",
    "   - Works for any bounded distribution\n",
    "   - No assumptions needed\n",
    "   - Price: wider intervals\n",
    "\n",
    "3. **Trade-offs everywhere**\n",
    "   - Guaranteed validity ‚Üî Tight intervals\n",
    "   - No assumptions ‚Üî Stronger conclusions\n",
    "   - Simple computation ‚Üî Better estimates\n",
    "\n",
    "4. **Sample size matters**\n",
    "   - More data ‚Üí more confidence\n",
    "   - Width decreases as O(1/‚àön)\n",
    "   - Need 4√ó data for 2√ó precision\n",
    "\n",
    "5. **Context matters**\n",
    "   - Risk-averse decisions ‚Üí use Hoeffding\n",
    "   - Precision matters ‚Üí use CLT/Bootstrap\n",
    "   - Unknown distribution ‚Üí use Hoeffding\n",
    "\n",
    "---\n",
    "\n",
    "#### Expected Results:\n",
    "When you run `problem3_main()`, you'll see:\n",
    "- ‚úÖ Average cost per observation from test set\n",
    "- ‚úÖ 95% confidence interval (likely including negative bound)\n",
    "- ‚úÖ Interpretation of conservativeness\n",
    "- ‚úÖ Comparison of interval width to estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4575c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                            COMPLETE EXAM SOLUTIONS                             \n",
      "================================================================================\n",
      "\n",
      "=== Problem 1: Markov chain estimation + hitting times ===\n",
      "Estimated P_hat:\n",
      " [[0.2   0.6   0.2   0.   ]\n",
      " [0.167 0.167 0.5   0.167]\n",
      " [0.2   0.2   0.2   0.4  ]\n",
      " [0.5   0.25  0.    0.25 ]]\n",
      "Is valid transition matrix? True\n",
      "\n",
      "Comparison table:\n",
      "    target_state  MC_estimate  theoretical  abs_diff\n",
      "0             0       0.0000     0.000000  0.000000\n",
      "1             1       2.0154     2.024390  0.008990\n",
      "2             2       3.2912     3.317073  0.025873\n",
      "3             3       5.6374     5.682927  0.045527\n",
      "\n",
      "================================================================================\n",
      "\n",
      "=== Problem 2: Cost-Sensitive Classification ===\n",
      "\n",
      "Dataset head:\n",
      "         x1        x2        x3  fraud\n",
      "0 -0.250243 -0.863902 -0.307019      0\n",
      "1 -0.380736  0.018756 -0.559577      0\n",
      "2  1.126431  2.055912  0.973126      1\n",
      "3  0.806991  2.104160 -0.211368      1\n",
      "4  0.059649  0.652374 -0.437259      0 \n",
      "\n",
      "Threshold sweep results:\n",
      "    threshold  TP   TN   FP  FN  total_cost\n",
      "0        -2.0  29  185  386   0       38600\n",
      "1        -1.8  29  241  330   0       33000\n",
      "2        -1.6  29  306  265   0       26500\n",
      "3        -1.4  29  387  184   0       18400\n",
      "4        -1.2  29  438  133   0       13300\n",
      "5        -1.0  29  482   89   0        8900\n",
      "6        -0.8  27  518   53   2        6300\n",
      "7        -0.6  26  537   34   3        4900\n",
      "8        -0.4  24  553   18   5        4300\n",
      "9        -0.2  19  564    7  10        5700\n",
      "10        0.0  14  566    5  15        8000\n",
      "11        0.2  12  567    4  17        8900\n",
      "12        0.4   7  568    3  22       11300\n",
      "13        0.6   3  569    2  26       13200\n",
      "14        0.8   2  571    0  27       13500\n",
      "15        1.0   1  571    0  28       14000\n",
      "16        1.2   1  571    0  28       14000\n",
      "17        1.4   0  571    0  29       14500\n",
      "18        1.6   0  571    0  29       14500\n",
      "19        1.8   0  571    0  29       14500\n",
      "20        2.0   0  571    0  29       14500\n",
      "\n",
      "Optimal threshold:\n",
      "threshold       -0.4\n",
      "TP              24.0\n",
      "TN             553.0\n",
      "FP              18.0\n",
      "FN               5.0\n",
      "total_cost    4300.0\n",
      "Name: 8, dtype: float64\n",
      "\n",
      "=== Problem 3: Confidence Interval for Classification Cost ===\n",
      "\n",
      "Number of test observations: 600\n",
      "Average cost per observation: $13.33\n",
      "Total cost on test set: $8000.00\n",
      "\n",
      "95% Confidence Interval (Hoeffding): [$-14.39, $41.06]\n",
      "Interval width: $55.44\n",
      "\n",
      "--- Interpretation ---\n",
      "‚Ä¢ With 95% confidence, the true expected cost per observation lies in this interval\n",
      "‚Ä¢ The interval is likely CONSERVATIVE (wider than necessary) because:\n",
      "  - Hoeffding only uses bounds [0, 500], not the actual distribution\n",
      "  - Actual costs are discrete {0, 100, 500}, not uniform over [0, 500]\n",
      "  - Most observations have cost 0, so variance is lower than worst-case\n",
      "‚Ä¢ Width decreases as O(1/‚àön), so more test data yields tighter intervals\n",
      "‚Ä¢ This provides a guarantee that doesn't assume any specific distribution\n",
      "\n",
      "================================================================================\n",
      "                             ALL PROBLEMS COMPLETED                             \n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Run all problems\n",
    "print(\"=\"*80)\n",
    "print(\" COMPLETE EXAM SOLUTIONS \".center(80))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Problem 1\n",
    "problem1_main()\n",
    "\n",
    "# Problem 2  \n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\n=== Problem 2: Cost-Sensitive Classification ===\\n\")\n",
    "main()\n",
    "\n",
    "# Problem 3\n",
    "problem3_main()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" ALL PROBLEMS COMPLETED \".center(80))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfbbde8",
   "metadata": {},
   "source": [
    "## üìä Summary of Results\n",
    "\n",
    "### Problem 1: Markov Chain Analysis ‚úÖ\n",
    "\n",
    "**Estimated Transition Matrix:**\n",
    "```\n",
    "From\\To   0      1      2      3\n",
    "   0    0.20   0.60   0.20   0.00\n",
    "   1    0.17   0.17   0.50   0.17\n",
    "   2    0.20   0.20   0.20   0.40\n",
    "   3    0.50   0.25   0.00   0.25\n",
    "```\n",
    "\n",
    "**Key Findings:**\n",
    "- ‚úÖ Valid transition matrix (all checks passed)\n",
    "- Starting from state 0: takes ~2 steps to reach state 1, ~5.7 steps to reach state 3\n",
    "- Simulation matches theory perfectly (validates implementation)\n",
    "\n",
    "---\n",
    "\n",
    "### Problem 2: Cost-Sensitive Classification ‚úÖ\n",
    "\n",
    "**Performance at Optimal Threshold (-0.4):**\n",
    "- **Total Cost: $4,300** (vs $8,000 at default threshold)\n",
    "- **Cost Reduction: 46%** ($3,700 savings)\n",
    "- Caught 24/29 fraud cases (83% detection rate)\n",
    "- 18 false alarms (acceptable given savings)\n",
    "\n",
    "**Business Impact:**\n",
    "> By being more aggressive in flagging potential fraud, we save $3,700 despite generating more false alarms. Missing fraud costs 5√ó more than investigating false alarms!\n",
    "\n",
    "---\n",
    "\n",
    "### Problem 3: Confidence Estimation ‚úÖ\n",
    "\n",
    "**Cost Estimate with Uncertainty:**\n",
    "- Average cost: $13.33 per observation\n",
    "- 95% CI: [‚àí$14.39, $41.06] ‚Üí effective: [$0, $41.06]\n",
    "- Interval width: $55.44 (conservative due to Hoeffding)\n",
    "\n",
    "**Interpretation:**\n",
    "- With 95% confidence, true expected cost ‚â§ $41.06\n",
    "- Hoeffding is conservative (wide interval) but guaranteed\n",
    "- Tighter intervals possible with CLT or Bootstrap\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Key Takeaways\n",
    "\n",
    "1. **Markov Chains:** Theory and simulation agree ‚Üí validates both methods\n",
    "2. **Cost-Sensitive Learning:** 46% cost reduction from threshold tuning alone\n",
    "3. **Uncertainty Quantification:** Always report confidence intervals with estimates\n",
    "4. **Real-World Impact:** Small methodological improvements ‚Üí big business value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4f508e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Visualization Insights:\n",
      "======================================================================\n",
      "LEFT PLOT: Shows how total cost changes with threshold\n",
      "  ‚Ä¢ Lower threshold ‚Üí flag more as fraud ‚Üí fewer FN, more FP\n",
      "  ‚Ä¢ Higher threshold ‚Üí flag less as fraud ‚Üí more FN, fewer FP\n",
      "  ‚Ä¢ Optimal threshold minimizes total cost\n",
      "\n",
      "RIGHT PLOT: Shows the trade-off between FP and FN\n",
      "  ‚Ä¢ As threshold decreases, FP increases (green line up)\n",
      "  ‚Ä¢ As threshold decreases, FN decreases (red line down)\n",
      "  ‚Ä¢ Optimal threshold balances these based on costs ($100 vs $500)\n",
      "  ‚Ä¢ Since FN costs 5√ó more, we tolerate more FP to reduce FN\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# BONUS: Visualize the threshold optimization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Get the data for plotting\n",
    "clf = LinearSVC(C=1.0, max_iter=10_000, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split_table(fraud_data)\n",
    "clf.fit(X_train, y_train)\n",
    "thresholds = np.linspace(-2.0, 2.0, 21)\n",
    "df_results = sweep_thresholds(y_test, thresholds, X_test, clf)\n",
    "\n",
    "# Plot 1: Total Cost vs Threshold\n",
    "axes[0].plot(df_results['threshold'], df_results['total_cost'], 'b-o', linewidth=2, markersize=6)\n",
    "optimal_idx = df_results['total_cost'].idxmin()\n",
    "optimal_threshold = df_results.loc[optimal_idx, 'threshold']\n",
    "optimal_cost = df_results.loc[optimal_idx, 'total_cost']\n",
    "axes[0].plot(optimal_threshold, optimal_cost, 'r*', markersize=20, label=f'Optimal: {optimal_threshold:.1f}')\n",
    "axes[0].axhline(y=optimal_cost, color='r', linestyle='--', alpha=0.3)\n",
    "axes[0].set_xlabel('Decision Threshold', fontsize=12)\n",
    "axes[0].set_ylabel('Total Cost ($)', fontsize=12)\n",
    "axes[0].set_title('Cost vs Decision Threshold', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend(fontsize=11)\n",
    "\n",
    "# Plot 2: FP and FN counts\n",
    "axes[1].plot(df_results['threshold'], df_results['FP'], 'g-o', linewidth=2, label='False Positives (FP)', markersize=5)\n",
    "axes[1].plot(df_results['threshold'], df_results['FN'], 'r-s', linewidth=2, label='False Negatives (FN)', markersize=5)\n",
    "axes[1].axvline(x=optimal_threshold, color='orange', linestyle='--', linewidth=2, label=f'Optimal threshold')\n",
    "axes[1].set_xlabel('Decision Threshold', fontsize=12)\n",
    "axes[1].set_ylabel('Count', fontsize=12)\n",
    "axes[1].set_title('False Positives vs False Negatives', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].legend(fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('threshold_optimization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Visualization Insights:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"LEFT PLOT: Shows how total cost changes with threshold\")\n",
    "print(\"  ‚Ä¢ Lower threshold ‚Üí flag more as fraud ‚Üí fewer FN, more FP\")\n",
    "print(\"  ‚Ä¢ Higher threshold ‚Üí flag less as fraud ‚Üí more FN, fewer FP\")\n",
    "print(\"  ‚Ä¢ Optimal threshold minimizes total cost\")\n",
    "print()\n",
    "print(\"RIGHT PLOT: Shows the trade-off between FP and FN\")\n",
    "print(\"  ‚Ä¢ As threshold decreases, FP increases (green line up)\")\n",
    "print(\"  ‚Ä¢ As threshold decreases, FN decreases (red line down)\")  \n",
    "print(\"  ‚Ä¢ Optimal threshold balances these based on costs ($100 vs $500)\")\n",
    "print(\"  ‚Ä¢ Since FN costs 5√ó more, we tolerate more FP to reduce FN\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
