{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a60c27c",
   "metadata": {},
   "source": [
    "# Lecture Notes Toolkit - Finite Markov Chains (Chapter 7)\n",
    "\n",
    "## üìö What are Markov Chains?\n",
    "\n",
    "A **Markov chain** is a mathematical model that describes a sequence of events where the probability of each event depends **only on the state of the previous event**, not on the entire history. This is called the **Markov property** or \"memorylessness.\"\n",
    "\n",
    "### üéØ Real-World Examples:\n",
    "- **Weather**: Tomorrow's weather depends mainly on today's weather, not last week's\n",
    "- **Stock prices**: Tomorrow's price movements depend on today's price\n",
    "- **Web browsing**: The next page you visit depends on your current page (basis of Google's PageRank!)\n",
    "- **Text generation**: The next word depends on the current word (simple language models)\n",
    "- **Games**: Moving between game states based on current position\n",
    "\n",
    "### üìñ What This Notebook Covers\n",
    "\n",
    "This notebook provides a complete toolkit for working with **finite Markov chains** (chains with a countable number of states). We cover both theory and practical implementations based on notes from pages 110-122.\n",
    "\n",
    "---\n",
    "\n",
    "## üóÇÔ∏è Content Overview\n",
    "\n",
    "### **Part 1: Foundations** (Sections 0-1)\n",
    "‚úÖ **Core Concepts & Validation**\n",
    "- What is a transition matrix `P`?\n",
    "- Row-stochastic property (rows sum to 1)\n",
    "- Helper functions for validation and normalization\n",
    "\n",
    "‚úÖ **Distributions Over Time: `Œº_t`**\n",
    "- Computing state distributions after `t` steps\n",
    "- Homogeneous chains (constant `P`) vs. inhomogeneous chains (time-varying `P_t`)\n",
    "- Expected values of functions at time `t`\n",
    "\n",
    "---\n",
    "\n",
    "### **Part 2: Simulation** (Section 2)\n",
    "‚úÖ **Random Mapping Representation (RMR)**\n",
    "- How to simulate Markov chains efficiently\n",
    "- Inversion sampling method (Theorem 7.14)\n",
    "- Simulating both homogeneous and inhomogeneous chains\n",
    "\n",
    "---\n",
    "\n",
    "### **Part 3: Structure & Properties** (Sections 3-4)\n",
    "‚úÖ **Irreducibility & Communication**\n",
    "- Can you reach any state from any other state?\n",
    "- Finding communication classes\n",
    "- Why irreducibility matters for long-run behavior\n",
    "\n",
    "‚úÖ **Return Times, Period & Aperiodicity**\n",
    "- How often does a chain return to a state?\n",
    "- Periodic vs. aperiodic chains\n",
    "- Impact on convergence to equilibrium\n",
    "\n",
    "---\n",
    "\n",
    "### **Part 4: Long-Run Behavior** (Sections 5-6)\n",
    "‚úÖ **Stationary Distributions: `œÄ`**\n",
    "- The equilibrium distribution (`œÄP = œÄ`)\n",
    "- When does it exist? When is it unique?\n",
    "- Two methods: solving linear systems vs. power iteration\n",
    "\n",
    "‚úÖ **Reversibility (Detailed Balance)**\n",
    "- What does it mean for a chain to be reversible?\n",
    "- Connection between reversibility and stationarity\n",
    "- Physical interpretation\n",
    "\n",
    "---\n",
    "\n",
    "### **Part 5: Applications** (Sections 7-9)\n",
    "‚úÖ **Random Walks on Graphs**\n",
    "- Modeling movement on networks\n",
    "- Computing stationary distributions from graph structure\n",
    "- PageRank-style random surfer with teleportation\n",
    "\n",
    "‚úÖ **Exercise 1: Text as a Markov Chain**\n",
    "- Building word-level language models\n",
    "- Estimating transition probabilities from text\n",
    "- Generating sentences\n",
    "\n",
    "‚úÖ **Exercise 2: Branching Processes**\n",
    "- Population dynamics and extinction\n",
    "- Galton-Watson processes\n",
    "- Estimating extinction times\n",
    "\n",
    "---\n",
    "\n",
    "## üéì Learning Approach\n",
    "\n",
    "This notebook is designed for **step-by-step learning**:\n",
    "1. **Read the explanations** in markdown cells carefully\n",
    "2. **Study the code** with inline comments explaining each step\n",
    "3. **Run the examples** to see concepts in action\n",
    "4. **Modify parameters** in demo cells to build intuition\n",
    "5. **Reuse functions** for your own problems (everything is modular!)\n",
    "\n",
    "Let's begin! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bb7511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, Dict, Iterable, List, Optional, Sequence, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc36b7c",
   "metadata": {},
   "source": [
    "## 0) Core Helpers: Understanding Transition Matrices\n",
    "\n",
    "### üéØ What is a Transition Matrix?\n",
    "\n",
    "A **transition matrix** `P` encodes the probabilities of moving between states in a Markov chain.\n",
    "\n",
    "**Structure:**\n",
    "- `P` is a square matrix of size `k √ó k` (where `k` = number of states)\n",
    "- Entry `P[i,j]` = probability of moving from state `i` to state `j` in one step\n",
    "- States are typically numbered `0, 1, 2, ..., k-1`\n",
    "\n",
    "**Example:** 3-state weather model (Sunny=0, Cloudy=1, Rainy=2)\n",
    "```\n",
    "       To: S    C    R\n",
    "From S:  [0.7  0.2  0.1]   ‚Üê If sunny today, 70% chance sunny tomorrow\n",
    "From C:  [0.3  0.4  0.3]   ‚Üê If cloudy today, 40% chance cloudy tomorrow  \n",
    "From R:  [0.2  0.3  0.5]   ‚Üê If rainy today, 50% chance rainy tomorrow\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üìè The Row-Stochastic Property\n",
    "\n",
    "For `P` to be a valid transition matrix, it must be **row-stochastic**:\n",
    "\n",
    "1. **Non-negative entries:** `P[i,j] ‚â• 0` (probabilities can't be negative!)\n",
    "2. **Rows sum to 1:** `Œ£‚±º P[i,j] = 1` (from any state, total probability must be 100%)\n",
    "\n",
    "This makes sense: from state `i`, you must go *somewhere* with total probability 1.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö†Ô∏è Why Validate?\n",
    "\n",
    "Before using a matrix as `P`, we must ensure it's row-stochastic:\n",
    "- **Normalization errors:** Floating-point arithmetic can cause small deviations\n",
    "- **User input errors:** Manually entered matrices might have mistakes\n",
    "- **Construction bugs:** Programmatically built matrices might have logical errors\n",
    "\n",
    "The functions below handle validation, normalization, and error-checking automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60353638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_rows(P: np.ndarray, eps: float = 1e-12) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalize each row of matrix P to sum to 1.\n",
    "    \n",
    "    This ensures the matrix is row-stochastic (each row is a probability distribution).\n",
    "    \n",
    "    Args:\n",
    "        P: Input matrix (will be converted to float array)\n",
    "        eps: Small threshold to avoid division by zero (default 1e-12)\n",
    "        \n",
    "    Returns:\n",
    "        Normalized matrix where each row sums to 1\n",
    "        \n",
    "    How it works:\n",
    "        1. Compute the sum of each row\n",
    "        2. If a row sum is < eps (essentially zero), replace with 1.0 to avoid division by zero\n",
    "        3. Divide each row by its sum to normalize\n",
    "        \n",
    "    Example:\n",
    "        >>> P = np.array([[1, 2], [3, 1]])\n",
    "        >>> normalize_rows(P)\n",
    "        array([[0.333, 0.667],   # row 0: sum was 3, now 1/3 and 2/3\n",
    "               [0.75,  0.25]])    # row 1: sum was 4, now 3/4 and 1/4\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, dtype=float)  # Convert to numpy float array\n",
    "    row_sums = P.sum(axis=1, keepdims=True)  # Sum each row, keep 2D shape for broadcasting\n",
    "    row_sums = np.where(row_sums < eps, 1.0, row_sums)  # Replace near-zero sums with 1.0\n",
    "    return P / row_sums  # Divide each element by its row sum\n",
    "\n",
    "def is_row_stochastic(P: np.ndarray, tol: float = 1e-9) -> bool:\n",
    "    \"\"\"\n",
    "    Check if matrix P is row-stochastic (valid transition matrix).\n",
    "    \n",
    "    A matrix is row-stochastic if:\n",
    "        - All entries are non-negative (>= 0)\n",
    "        - Each row sums to 1 (within tolerance)\n",
    "    \n",
    "    Args:\n",
    "        P: Matrix to check\n",
    "        tol: Tolerance for row sums being equal to 1 (default 1e-9)\n",
    "        \n",
    "    Returns:\n",
    "        True if P is row-stochastic, False otherwise\n",
    "        \n",
    "    Example:\n",
    "        >>> P = np.array([[0.7, 0.3], [0.4, 0.6]])\n",
    "        >>> is_row_stochastic(P)\n",
    "        True\n",
    "        >>> P_bad = np.array([[0.5, 0.3], [0.4, 0.6]])  # first row sums to 0.8\n",
    "        >>> is_row_stochastic(P_bad)\n",
    "        False\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, dtype=float)\n",
    "    \n",
    "    # Check 1: No negative entries\n",
    "    if np.any(P < -tol):\n",
    "        return False\n",
    "    \n",
    "    # Check 2: Each row sums to 1 (within tolerance)\n",
    "    row_sums = P.sum(axis=1)\n",
    "    return bool(np.all(np.abs(row_sums - 1.0) <= tol))\n",
    "\n",
    "def ensure_row_stochastic(P: np.ndarray, tol: float = 1e-9) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Ensure matrix P is row-stochastic by normalizing if needed.\n",
    "    \n",
    "    This is the main validation function used throughout the toolkit.\n",
    "    It normalizes rows to sum to 1 and raises an error if there are negative entries.\n",
    "    \n",
    "    Args:\n",
    "        P: Input matrix (potential transition matrix)\n",
    "        tol: Tolerance for validation checks\n",
    "        \n",
    "    Returns:\n",
    "        Normalized row-stochastic matrix\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If P has negative entries or cannot be normalized to valid probabilities\n",
    "        \n",
    "    Usage:\n",
    "        Call this at the start of every function that requires a transition matrix.\n",
    "        It ensures safety and consistency across all operations.\n",
    "    \"\"\"\n",
    "    P = np.asarray(P, dtype=float)\n",
    "    \n",
    "    # Check for negative entries (probabilities can't be negative!)\n",
    "    if np.any(P < -tol):\n",
    "        raise ValueError(\"Transition matrix has negative entries.\")\n",
    "    \n",
    "    # Normalize rows to sum to 1\n",
    "    Pn = normalize_rows(P)\n",
    "    \n",
    "    # Verify the result is actually row-stochastic\n",
    "    if not is_row_stochastic(Pn, tol=1e-6):\n",
    "        raise ValueError(\"Could not normalize rows to a valid transition matrix.\")\n",
    "    \n",
    "    return Pn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9e9020",
   "metadata": {},
   "source": [
    "## 1) Distributions Over Time: Understanding `Œº_t`\n",
    "\n",
    "### üéØ What is `Œº_t`?\n",
    "\n",
    "`Œº_t` (pronounced \"mu at time t\") is a **probability distribution over states at time `t`**.\n",
    "\n",
    "- `Œº_t[i]` = probability of being in state `i` at time `t`\n",
    "- `Œº_t` is a row vector with `k` elements (one per state)\n",
    "- `Œº_t` sums to 1 (it's a probability distribution)\n",
    "- `Œº_0` is the **initial distribution** (where we start)\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Œº_0 = [1.0, 0.0, 0.0]  ‚Üê Start in state 0 with certainty\n",
    "Œº_0 = [0.5, 0.3, 0.2]  ‚Üê Start in state 0 with 50%, state 1 with 30%, state 2 with 20%\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üìê The Chapman-Kolmogorov Equation\n",
    "\n",
    "The fundamental relationship is:\n",
    "$$\\mu_{t+1} = \\mu_t P$$\n",
    "\n",
    "This tells us: **multiply the current distribution by the transition matrix to get the next distribution.**\n",
    "\n",
    "**Intuition:** The probability of being in state `j` at time `t+1` is the sum over all states `i` of:\n",
    "- (probability of being in state `i` at time `t`) √ó (probability of transitioning from `i` to `j`)\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ Homogeneous Chains: When `P` is Constant\n",
    "\n",
    "If the transition matrix doesn't change over time, we can apply it repeatedly:\n",
    "$$\\mu_t = \\mu_0 P^t$$\n",
    "\n",
    "Where `P^t` means \"`P` multiplied by itself `t` times\" (matrix power).\n",
    "\n",
    "**Why this works:**\n",
    "- `Œº_1 = Œº_0 P`\n",
    "- `Œº_2 = Œº_1 P = (Œº_0 P) P = Œº_0 P¬≤`\n",
    "- `Œº_3 = Œº_2 P = Œº_0 P¬≥`\n",
    "- And so on...\n",
    "\n",
    "**Physical interpretation:** `P^t[i,j]` = probability of going from state `i` to state `j` in exactly `t` steps.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÄ Inhomogeneous Chains: When `P` Changes Over Time\n",
    "\n",
    "Sometimes the transition probabilities change with time (e.g., seasonal weather patterns):\n",
    "- At time 1, use transition matrix `P_1`\n",
    "- At time 2, use transition matrix `P_2`\n",
    "- etc.\n",
    "\n",
    "Then:\n",
    "$$\\mu_t = \\mu_0 P_1 P_2 \\cdots P_t$$\n",
    "\n",
    "We multiply the matrices in sequence (order matters!).\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Expected Values at Time `t`\n",
    "\n",
    "If you have a function `f` that assigns a value to each state (e.g., temperature in a weather model), you can compute the expected value at time `t`:\n",
    "$$\\mathbb{E}[f(X_t)] = (P^t f)[x]$$\n",
    "\n",
    "This is useful for:\n",
    "- Average rewards in reinforcement learning\n",
    "- Expected costs/benefits at future times\n",
    "- Long-run averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02b564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_step_transition(P: np.ndarray, t: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the t-step transition matrix P^t.\n",
    "    \n",
    "    P^t[i,j] = probability of going from state i to state j in exactly t steps.\n",
    "    \n",
    "    Args:\n",
    "        P: One-step transition matrix (k √ó k)\n",
    "        t: Number of steps (must be >= 0)\n",
    "        \n",
    "    Returns:\n",
    "        P^t: The t-step transition matrix\n",
    "        \n",
    "    Special cases:\n",
    "        - t=0: Returns identity matrix (stay in same state)\n",
    "        - t=1: Returns P itself\n",
    "        - t=2: Returns P @ P (two-step transitions)\n",
    "        \n",
    "    Example:\n",
    "        If P = [[0.5, 0.5], [0.3, 0.7]], then P^2 tells us two-step probabilities.\n",
    "    \"\"\"\n",
    "    if t < 0:\n",
    "        raise ValueError(\"t must be >= 0.\")\n",
    "    P = ensure_row_stochastic(P)\n",
    "    return np.linalg.matrix_power(P, t)  # Efficiently compute P^t\n",
    "\n",
    "def dist_after_t_homogeneous(mu0: np.ndarray, P: np.ndarray, t: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the distribution Œº_t = Œº_0 P^t for a homogeneous Markov chain.\n",
    "    \n",
    "    This answers: \"If I start with distribution Œº_0, what distribution will I have after t steps?\"\n",
    "    \n",
    "    Args:\n",
    "        mu0: Initial distribution (length k, sums to 1)\n",
    "        P: Transition matrix (k √ó k, constant over time)\n",
    "        t: Number of steps\n",
    "        \n",
    "    Returns:\n",
    "        Œº_t: Distribution at time t (length k, sums to 1)\n",
    "        \n",
    "    Example:\n",
    "        >>> mu0 = np.array([1.0, 0.0])  # Start in state 0\n",
    "        >>> P = np.array([[0.7, 0.3], [0.4, 0.6]])\n",
    "        >>> dist_after_t_homogeneous(mu0, P, t=1)\n",
    "        array([0.7, 0.3])  # After 1 step, 70% in state 0, 30% in state 1\n",
    "    \"\"\"\n",
    "    if t < 0:\n",
    "        raise ValueError(\"t must be >= 0.\")\n",
    "    P = ensure_row_stochastic(P)\n",
    "    mu0 = np.asarray(mu0, dtype=float).reshape(1, -1)  # Ensure row vector shape\n",
    "    \n",
    "    # Validate dimensions match\n",
    "    if mu0.shape[1] != P.shape[0]:\n",
    "        raise ValueError(\"mu0 length must match P dimension.\")\n",
    "    \n",
    "    # Compute P^t then multiply: Œº_0 @ P^t\n",
    "    Pt = n_step_transition(P, t)\n",
    "    return (mu0 @ Pt).ravel()  # Return as 1D array\n",
    "\n",
    "def dist_after_t_inhomogeneous(mu0: np.ndarray, Ps: Sequence[np.ndarray], t: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute Œº_t = Œº_0 P_1 P_2 ... P_t for an inhomogeneous chain.\n",
    "    \n",
    "    Use this when transition probabilities change over time (e.g., seasonal effects).\n",
    "    \n",
    "    Args:\n",
    "        mu0: Initial distribution\n",
    "        Ps: Sequence of transition matrices [P_1, P_2, ..., P_T]\n",
    "            Ps[0] is the transition matrix used at step 1\n",
    "            Ps[1] is used at step 2, etc.\n",
    "        t: Number of steps to simulate\n",
    "        \n",
    "    Returns:\n",
    "        Œº_t: Distribution after t steps\n",
    "        \n",
    "    Note:\n",
    "        We need at least t matrices in Ps to compute t steps.\n",
    "    \"\"\"\n",
    "    if t < 0:\n",
    "        raise ValueError(\"t must be >= 0.\")\n",
    "    mu0 = np.asarray(mu0, dtype=float).reshape(1, -1)\n",
    "    \n",
    "    # Special case: at time 0, return initial distribution\n",
    "    if t == 0:\n",
    "        return mu0.ravel()\n",
    "    \n",
    "    # Check we have enough transition matrices\n",
    "    if t > len(Ps):\n",
    "        raise ValueError(\"Need at least t matrices in Ps.\")\n",
    "    \n",
    "    k = mu0.shape[1]\n",
    "    mu = mu0\n",
    "    \n",
    "    # Multiply through the sequence: Œº_0 @ P_1 @ P_2 @ ... @ P_t\n",
    "    for i in range(t):\n",
    "        Pi = ensure_row_stochastic(Ps[i])\n",
    "        if Pi.shape != (k, k):\n",
    "            raise ValueError(\"All matrices must match state dimension.\")\n",
    "        mu = mu @ Pi  # Update distribution by multiplying with next P\n",
    "    \n",
    "    return mu.ravel()\n",
    "\n",
    "def expected_f_at_t(P: np.ndarray, f: np.ndarray, t: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute expected value of function f at time t, starting from each state.\n",
    "    \n",
    "    Returns g where g[x] = E_x[f(X_t)] = expected value of f(X_t) starting from state x.\n",
    "    This is computed as (P^t @ f)[x].\n",
    "    \n",
    "    Args:\n",
    "        P: Transition matrix\n",
    "        f: Function values at each state (length k)\n",
    "        t: Time step\n",
    "        \n",
    "    Returns:\n",
    "        Array g where g[x] = expected value of f at time t starting from state x\n",
    "        \n",
    "    Example:\n",
    "        If states are temperatures and f = [10, 20, 30] (degrees),\n",
    "        then g[0] tells us the expected temperature at time t if we start in state 0.\n",
    "    \"\"\"\n",
    "    P = ensure_row_stochastic(P)\n",
    "    f = np.asarray(f, dtype=float).reshape(-1)\n",
    "    \n",
    "    if f.shape[0] != P.shape[0]:\n",
    "        raise ValueError(\"f length must match P dimension.\")\n",
    "    \n",
    "    # P^t gives t-step transition probabilities\n",
    "    # (P^t @ f)[x] = sum over all states y of: P^t[x,y] * f[y]\n",
    "    # This is the expected value of f, starting from x, after t steps\n",
    "    Pt = n_step_transition(P, t)\n",
    "    return Pt @ f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02fd6aa",
   "metadata": {},
   "source": [
    "### Mini demo (replace `P_demo` / `mu0`)\n",
    "\n",
    "We create a 3-state chain and show `Œº_t`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d8edab",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_demo = np.array([\n",
    "    [0.1, 0.6, 0.3],\n",
    "    [0.2, 0.7, 0.1],\n",
    "    [0.5, 0.2, 0.3],\n",
    "], dtype=float)\n",
    "\n",
    "mu0 = np.array([1.0, 0.0, 0.0])  # start surely in state 0\n",
    "\n",
    "for t in [0, 1, 2, 5, 10]:\n",
    "    print(t, dist_after_t_homogeneous(mu0, P_demo, t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb97099",
   "metadata": {},
   "source": [
    "## 2) Simulation via Random Mapping Representation (RMR)\n",
    "\n",
    "### üéØ The Goal: Simulate Random Paths\n",
    "\n",
    "We want to generate actual sample paths (trajectories) of a Markov chain:\n",
    "```\n",
    "X_0 ‚Üí X_1 ‚Üí X_2 ‚Üí X_3 ‚Üí ...\n",
    "```\n",
    "where each transition follows the probabilities in `P`.\n",
    "\n",
    "**Why simulate?**\n",
    "- Estimate long-run behavior empirically\n",
    "- Generate sample data for testing\n",
    "- Visualize typical trajectories\n",
    "- Monte Carlo estimation of expectations\n",
    "\n",
    "---\n",
    "\n",
    "### üé≤ The Challenge: How to Sample Transitions?\n",
    "\n",
    "Given we're in state `i`, we need to randomly choose the next state `j` with probabilities `P[i,j]`.\n",
    "\n",
    "**Example:** If `P[i,:] = [0.1, 0.6, 0.3]`, we need:\n",
    "- 10% chance of choosing state 0\n",
    "- 60% chance of choosing state 1  \n",
    "- 30% chance of choosing state 2\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Solution: Inversion Sampling (Theorem 7.14)\n",
    "\n",
    "The **Random Mapping Representation (RMR)** uses **inversion sampling** to convert uniform random numbers into state transitions.\n",
    "\n",
    "**The Algorithm:**\n",
    "\n",
    "1. **Precompute cumulative probabilities** for each row of `P`:\n",
    "   ```\n",
    "   CDF[i,0] = P[i,0]\n",
    "   CDF[i,1] = P[i,0] + P[i,1]\n",
    "   CDF[i,2] = P[i,0] + P[i,1] + P[i,2]\n",
    "   ...\n",
    "   CDF[i,k-1] = 1.0\n",
    "   ```\n",
    "\n",
    "2. **Draw a uniform random number** `u ~ Uniform(0,1)`\n",
    "\n",
    "3. **Find the first index** `j` where `u ‚â§ CDF[i,j]`\n",
    "\n",
    "4. **Next state is `j`**\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Why This Works: Visual Intuition\n",
    "\n",
    "Think of the interval [0,1] divided into segments proportional to probabilities:\n",
    "\n",
    "```\n",
    "Current state i has P[i,:] = [0.1, 0.6, 0.3]\n",
    "\n",
    "[0.0 -------- 0.1|------- 0.7|---- 1.0]\n",
    "     State 0       State 1    State 2\n",
    "     (10%)          (60%)      (30%)\n",
    "```\n",
    "\n",
    "When we draw `u ~ Uniform(0,1)`:\n",
    "- If `u ‚àà [0.0, 0.1)` ‚Üí choose state 0 (happens 10% of the time)\n",
    "- If `u ‚àà [0.1, 0.7)` ‚Üí choose state 1 (happens 60% of the time)\n",
    "- If `u ‚àà [0.7, 1.0]` ‚Üí choose state 2 (happens 30% of the time)\n",
    "\n",
    "This exactly matches the probabilities in `P[i,:]`!\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö° Efficiency\n",
    "\n",
    "By precomputing the CDF for all rows, we can:\n",
    "1. Generate many transitions quickly\n",
    "2. Reuse the same RMR for multiple simulations\n",
    "3. Use efficient binary search (`np.searchsorted`) to find the right state\n",
    "\n",
    "This is **much faster** than alternatives like `np.random.choice` for large numbers of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70237065",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RMR:\n",
    "    \"\"\"\n",
    "    Random Mapping Representation: Precomputed data for efficient simulation.\n",
    "    \n",
    "    Attributes:\n",
    "        P: The transition matrix (k √ó k)\n",
    "        cdf_rows: Cumulative distribution function for each row (k √ó k)\n",
    "                  cdf_rows[i,j] = sum of P[i,0] + P[i,1] + ... + P[i,j]\n",
    "    \"\"\"\n",
    "    P: np.ndarray\n",
    "    cdf_rows: np.ndarray  # cumulative sums per row, shape (k,k)\n",
    "\n",
    "def build_rmr(P: np.ndarray) -> RMR:\n",
    "    \"\"\"\n",
    "    Build a Random Mapping Representation from a transition matrix.\n",
    "    \n",
    "    This precomputes the cumulative distribution functions (CDFs) for all rows,\n",
    "    enabling fast sampling of next states.\n",
    "    \n",
    "    Args:\n",
    "        P: Transition matrix (will be validated and normalized)\n",
    "        \n",
    "    Returns:\n",
    "        RMR object containing P and precomputed CDFs\n",
    "        \n",
    "    Example:\n",
    "        >>> P = np.array([[0.1, 0.6, 0.3], [0.5, 0.3, 0.2]])\n",
    "        >>> rmr = build_rmr(P)\n",
    "        >>> rmr.cdf_rows\n",
    "        array([[0.1, 0.7, 1.0],     # cumulative: 0.1, 0.1+0.6=0.7, 0.7+0.3=1.0\n",
    "               [0.5, 0.8, 1.0]])     # cumulative: 0.5, 0.5+0.3=0.8, 0.8+0.2=1.0\n",
    "    \"\"\"\n",
    "    P = ensure_row_stochastic(P)  # Validate and normalize\n",
    "    cdf = np.cumsum(P, axis=1)    # Cumulative sum along each row\n",
    "    cdf[:, -1] = 1.0              # Fix last column to exactly 1.0 (avoid floating point drift)\n",
    "    return RMR(P=P, cdf_rows=cdf)\n",
    "\n",
    "def rmr_step(rmr: RMR, x: int, u: float) -> int:\n",
    "    \"\"\"\n",
    "    Take one step in the Markov chain using the RMR and a uniform random number.\n",
    "    \n",
    "    Args:\n",
    "        rmr: Random Mapping Representation (precomputed)\n",
    "        x: Current state (0 ‚â§ x < k)\n",
    "        u: Uniform random number in [0, 1]\n",
    "        \n",
    "    Returns:\n",
    "        Next state j, chosen according to probabilities P[x,:]\n",
    "        \n",
    "    How it works:\n",
    "        1. Get the CDF for row x: [CDF[x,0], CDF[x,1], ..., CDF[x,k-1]]\n",
    "        2. Find the first index j where u ‚â§ CDF[x,j]\n",
    "        3. This j is chosen with probability P[x,j]\n",
    "        \n",
    "    Example:\n",
    "        If P[x,:] = [0.2, 0.5, 0.3], then CDF[x,:] = [0.2, 0.7, 1.0]\n",
    "        - If u = 0.15 ‚Üí j = 0 (since 0.15 ‚â§ 0.2)\n",
    "        - If u = 0.5  ‚Üí j = 1 (since 0.2 < 0.5 ‚â§ 0.7)\n",
    "        - If u = 0.9  ‚Üí j = 2 (since 0.7 < 0.9 ‚â§ 1.0)\n",
    "    \"\"\"\n",
    "    row = rmr.cdf_rows[x]  # Get CDF for current state x\n",
    "    # Binary search to find first j where u <= row[j]\n",
    "    # searchsorted with side=\"right\" finds the insertion point\n",
    "    return int(np.searchsorted(row, u, side=\"right\"))\n",
    "\n",
    "def simulate_markov_chain(P: np.ndarray, x0: int, n_steps: int, seed: Optional[int] = 0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simulate a trajectory of a homogeneous Markov chain.\n",
    "    \n",
    "    Generates a path: X_0, X_1, X_2, ..., X_{n_steps}\n",
    "    \n",
    "    Args:\n",
    "        P: Transition matrix (k √ó k, constant over time)\n",
    "        x0: Initial state (0 ‚â§ x0 < k)\n",
    "        n_steps: Number of steps to simulate (length of output will be n_steps + 1)\n",
    "        seed: Random seed for reproducibility (None for random behavior)\n",
    "        \n",
    "    Returns:\n",
    "        Array of states [X_0, X_1, ..., X_{n_steps}] of length (n_steps + 1)\n",
    "        \n",
    "    Example:\n",
    "        >>> P = np.array([[0.5, 0.5], [0.3, 0.7]])\n",
    "        >>> path = simulate_markov_chain(P, x0=0, n_steps=5, seed=42)\n",
    "        >>> path\n",
    "        array([0, 1, 1, 0, 0, 1])  # Started in state 0, took 5 steps\n",
    "    \"\"\"\n",
    "    if n_steps < 0:\n",
    "        raise ValueError(\"n_steps must be >= 0.\")\n",
    "    \n",
    "    P = ensure_row_stochastic(P)\n",
    "    k = P.shape[0]\n",
    "    \n",
    "    if not (0 <= x0 < k):\n",
    "        raise ValueError(\"x0 out of range.\")\n",
    "    \n",
    "    # Build the RMR once (precompute CDFs)\n",
    "    rmr = build_rmr(P)\n",
    "    \n",
    "    # Initialize random number generator\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    # Allocate array for the trajectory\n",
    "    xs = np.empty(n_steps + 1, dtype=int)\n",
    "    xs[0] = x0  # Set initial state\n",
    "    \n",
    "    x = x0\n",
    "    # Generate each transition\n",
    "    for t in range(1, n_steps + 1):\n",
    "        u = rng.random()           # Draw uniform random number\n",
    "        x = rmr_step(rmr, x, u)    # Use RMR to get next state\n",
    "        xs[t] = x                   # Store it\n",
    "    \n",
    "    return xs\n",
    "\n",
    "def simulate_inhomogeneous_chain(Ps: Sequence[np.ndarray], x0: int, seed: Optional[int] = 0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simulate an inhomogeneous Markov chain (time-varying transition matrices).\n",
    "    \n",
    "    At each time step t, uses transition matrix Ps[t-1] to go from X_{t-1} to X_t.\n",
    "    \n",
    "    Args:\n",
    "        Ps: Sequence of transition matrices [P_1, P_2, ..., P_T]\n",
    "            Ps[0] is used for the first transition (X_0 ‚Üí X_1)\n",
    "            Ps[1] is used for the second transition (X_1 ‚Üí X_2)\n",
    "            etc.\n",
    "        x0: Initial state\n",
    "        seed: Random seed\n",
    "        \n",
    "    Returns:\n",
    "        Array [X_0, X_1, ..., X_T] of length (T + 1), where T = len(Ps)\n",
    "        \n",
    "    Example:\n",
    "        Use when transition probabilities change over time (e.g., seasonal patterns).\n",
    "    \"\"\"\n",
    "    T = len(Ps)\n",
    "    \n",
    "    # Special case: no transitions\n",
    "    if T == 0:\n",
    "        return np.array([x0], dtype=int)\n",
    "    \n",
    "    k = Ps[0].shape[0]  # Number of states\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    # Allocate trajectory array\n",
    "    xs = np.empty(T + 1, dtype=int)\n",
    "    xs[0] = x0\n",
    "    \n",
    "    x = x0\n",
    "    # At each time step, use the corresponding transition matrix\n",
    "    for t in range(1, T + 1):\n",
    "        Pt = ensure_row_stochastic(Ps[t-1])  # Get and validate P_t\n",
    "        rmr = build_rmr(Pt)                   # Build RMR for this time step\n",
    "        u = rng.random()                      # Draw random number\n",
    "        x = rmr_step(rmr, x, u)               # Transition\n",
    "        xs[t] = x\n",
    "    \n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48b9ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo trajectory\n",
    "traj = simulate_markov_chain(P_demo, x0=0, n_steps=25, seed=42)\n",
    "traj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972156e3",
   "metadata": {},
   "source": [
    "## 3) Irreducibility: Can We Reach Everywhere?\n",
    "\n",
    "### üéØ What is Irreducibility?\n",
    "\n",
    "A Markov chain is **irreducible** if you can eventually reach any state from any other state (possibly in multiple steps).\n",
    "\n",
    "**Formal definition:** State `i` **communicates** with state `j` (written `i ‚Üî j`) if:\n",
    "- You can reach `j` from `i`: there exists some `t` where `P^t[i,j] > 0`\n",
    "- You can reach `i` from `j`: there exists some `s` where `P^s[j,i] > 0`\n",
    "\n",
    "The chain is **irreducible** if all states communicate with each other.\n",
    "\n",
    "---\n",
    "\n",
    "### üó∫Ô∏è Visual Examples\n",
    "\n",
    "**Example 1: Irreducible chain (3 states)**\n",
    "```\n",
    "    ‚îå‚îÄ‚Üí 0 ‚Üê‚îÄ‚îê\n",
    "    ‚îÇ   ‚Üì   ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ 1 ‚Üí 2\n",
    "```\n",
    "From any state, you can eventually reach any other state. ‚úÖ Irreducible\n",
    "\n",
    "**Example 2: Reducible chain (2 separate groups)**\n",
    "```\n",
    "    0 ‚Üî 1       2 ‚Üî 3\n",
    "    (Group A)   (Group B)\n",
    "```\n",
    "Once you're in Group A, you can never reach Group B (and vice versa). ‚ùå Not irreducible\n",
    "\n",
    "**Example 3: Absorbing state**\n",
    "```\n",
    "    0 ‚Üí 1 ‚Üí 2\n",
    "        ‚Üì\n",
    "        2 (self-loop, P[2,2]=1)\n",
    "```\n",
    "State 2 is **absorbing** (once you enter, you never leave). You can't return to states 0 or 1. ‚ùå Not irreducible\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Communication Classes\n",
    "\n",
    "If a chain is not irreducible, it splits into **communication classes**:\n",
    "- **Class** = maximal set of states that all communicate with each other\n",
    "- States in different classes don't communicate\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "States: {0, 1, 2, 3, 4}\n",
    "P shows: 0‚Üî1, 2‚Üî3‚Üî4\n",
    "Classes: {0,1} and {2,3,4}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Why Irreducibility Matters\n",
    "\n",
    "1. **Unique stationary distribution:** Irreducible + aperiodic chains have exactly one stationary distribution `œÄ`\n",
    "2. **Convergence:** The distribution `Œº_t` converges to `œÄ` regardless of starting point\n",
    "3. **Ergodic theorem:** Time averages equal space averages (law of large numbers for Markov chains)\n",
    "\n",
    "If the chain is **not** irreducible:\n",
    "- Multiple stationary distributions may exist\n",
    "- Long-run behavior depends on where you start\n",
    "- Different classes behave independently\n",
    "\n",
    "---\n",
    "\n",
    "### üîß How to Check: Graph Approach\n",
    "\n",
    "View the chain as a directed graph:\n",
    "- Vertices = states\n",
    "- Edge `i ‚Üí j` exists if `P[i,j] > 0`\n",
    "\n",
    "The chain is irreducible ‚ü∫ the graph is **strongly connected** (you can reach any vertex from any other vertex following directed edges)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d93cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacency_from_P(P: np.ndarray, tol: float = 0.0) -> List[List[int]]:\n",
    "    P = np.asarray(P, dtype=float)\n",
    "    k = P.shape[0]\n",
    "    adj = [[] for _ in range(k)]\n",
    "    for i in range(k):\n",
    "        adj[i] = [j for j in range(k) if P[i, j] > tol]\n",
    "    return adj\n",
    "\n",
    "def _dfs(start: int, adj: List[List[int]]) -> List[bool]:\n",
    "    seen = [False]*len(adj)\n",
    "    stack = [start]\n",
    "    while stack:\n",
    "        v = stack.pop()\n",
    "        if seen[v]:\n",
    "            continue\n",
    "        seen[v] = True\n",
    "        for w in adj[v]:\n",
    "            if not seen[w]:\n",
    "                stack.append(w)\n",
    "    return seen\n",
    "\n",
    "def is_strongly_connected(adj: List[List[int]]) -> bool:\n",
    "    n = len(adj)\n",
    "    # check reachability from 0\n",
    "    seen = _dfs(0, adj)\n",
    "    if not all(seen):\n",
    "        return False\n",
    "    # build reverse graph\n",
    "    radj = [[] for _ in range(n)]\n",
    "    for i in range(n):\n",
    "        for j in adj[i]:\n",
    "            radj[j].append(i)\n",
    "    seen_r = _dfs(0, radj)\n",
    "    return all(seen_r)\n",
    "\n",
    "def is_irreducible(P: np.ndarray, tol: float = 0.0) -> bool:\n",
    "    P = ensure_row_stochastic(P)\n",
    "    return is_strongly_connected(adjacency_from_P(P, tol=tol))\n",
    "\n",
    "is_irreducible(P_demo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27c2f50",
   "metadata": {},
   "source": [
    "## 4) Return Times, Period, and Aperiodicity\n",
    "\n",
    "### üéØ What is the Period of a State?\n",
    "\n",
    "The **period** of a state `x` measures the \"rhythm\" of returns to that state.\n",
    "\n",
    "**Definition:** \n",
    "- Let `T(x) = {t ‚â• 1 : P^t[x,x] > 0}` be the set of all times when return is possible\n",
    "- The **period** of `x` is `d(x) = gcd(T(x))` (greatest common divisor)\n",
    "\n",
    "**Interpretation:**\n",
    "- Period tells you the \"cycle length\" of returns\n",
    "- If `d(x) = 1`, the state is **aperiodic** (returns can happen at irregular times)\n",
    "- If `d(x) > 1`, the state is **periodic** (returns follow a fixed cycle)\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Examples\n",
    "\n",
    "**Example 1: Aperiodic state**\n",
    "```\n",
    "State 0 can return to itself at times: {1, 2, 3, 4, 5, ...}\n",
    "gcd(1, 2, 3, 4, 5, ...) = 1  ‚úÖ Aperiodic\n",
    "```\n",
    "This happens when P[0,0] > 0 (self-loop exists).\n",
    "\n",
    "**Example 2: Period 2 (deterministic cycle)**\n",
    "```\n",
    "     0 ‚Üí 1\n",
    "     ‚Üë   ‚Üì\n",
    "     ‚îî‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "- From state 0: must go to 1, then back to 0\n",
    "- Can only return at times 2, 4, 6, 8, ...\n",
    "- `gcd(2, 4, 6, 8, ...) = 2` ‚úÖ Period = 2\n",
    "\n",
    "**Example 3: Period 3**\n",
    "```\n",
    "     0 ‚Üí 1 ‚Üí 2\n",
    "     ‚Üë       ‚Üì\n",
    "     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "- From state 0: goes 0‚Üí1‚Üí2‚Üí0‚Üí1‚Üí2‚Üí...\n",
    "- Returns possible at times 3, 6, 9, 12, ...\n",
    "- `gcd(3, 6, 9, ...) = 3` ‚úÖ Period = 3\n",
    "\n",
    "**Example 4: Aperiodic (self-loop breaks periodicity)**\n",
    "```\n",
    "     0 ‚Üí 1\n",
    "     ‚Üì ‚Üñ ‚Üì\n",
    "     ‚îî‚îÄ‚Üí‚îÄ‚îò\n",
    "```\n",
    "- State 0 can return in 2 steps (0‚Üí1‚Üí0) or 3 steps (0‚Üí0‚Üí0‚Üí0)\n",
    "- `gcd(2, 3) = 1` ‚úÖ Aperiodic\n",
    "\n",
    "---\n",
    "\n",
    "### üîë Key Facts\n",
    "\n",
    "1. **Irreducible chains:** All states have the same period\n",
    "   - If any one state is aperiodic, the entire chain is aperiodic\n",
    "\n",
    "2. **Self-loops guarantee aperiodicity:** If P[x,x] > 0 for any state x, then d(x) = 1\n",
    "\n",
    "3. **Bipartite graphs:** Chains on bipartite graphs (like checkerboards) have period 2\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Why Periodicity Matters\n",
    "\n",
    "**Aperiodic chains (period = 1):**\n",
    "- `Œº_t` converges smoothly to stationary distribution `œÄ`\n",
    "- `P^t[i,j]` converges to `œÄ[j]` as `t ‚Üí ‚àû`\n",
    "- Nice ergodic properties\n",
    "\n",
    "**Periodic chains (period d > 1):**\n",
    "- `Œº_t` **oscillates** and never converges!\n",
    "- Returns happen in cycles of length `d`\n",
    "- Need to look at averaged behavior: `(P + P^2 + ... + P^d) / d`\n",
    "\n",
    "**Example:** On a 2-state cycle (0 ‚Üî 1):\n",
    "```\n",
    "Start at state 0:\n",
    "t=0: in state 0\n",
    "t=1: in state 1  \n",
    "t=2: in state 0\n",
    "t=3: in state 1\n",
    "... (keeps alternating, never settles down!)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Computational Approach\n",
    "\n",
    "To find the period of state `x`:\n",
    "1. Compute `P^1, P^2, P^3, ...` up to some horizon\n",
    "2. Collect all `t` where `P^t[x,x] > 0`\n",
    "3. Take GCD of these times\n",
    "\n",
    "For irreducible chains, checking one state is enough (all states share the same period)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3125cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_period(P: np.ndarray, x: int, max_t: int = 500, tol: float = 1e-15) -> Optional[int]:\n",
    "    \"\"\"Estimate period of state x by collecting return times up to max_t.\"\"\"\n",
    "    P = ensure_row_stochastic(P)\n",
    "    k = P.shape[0]\n",
    "    if not (0 <= x < k):\n",
    "        raise ValueError(\"x out of range.\")\n",
    "    g = 0\n",
    "    Pt = np.eye(k)\n",
    "    for t in range(1, max_t + 1):\n",
    "        Pt = Pt @ P\n",
    "        if Pt[x, x] > tol:\n",
    "            g = math.gcd(g, t) if g != 0 else t\n",
    "    return g if g != 0 else None  # None means no return detected within max_t\n",
    "\n",
    "def chain_period(P: np.ndarray, max_t: int = 500) -> Optional[int]:\n",
    "    \"\"\"If irreducible, all states share a period; return estimated common period.\"\"\"\n",
    "    P = ensure_row_stochastic(P)\n",
    "    k = P.shape[0]\n",
    "    periods = []\n",
    "    for x in range(k):\n",
    "        px = state_period(P, x, max_t=max_t)\n",
    "        if px is not None:\n",
    "            periods.append(px)\n",
    "    if not periods:\n",
    "        return None\n",
    "    # if irreducible, these should match; we return gcd as a safe summary\n",
    "    g = periods[0]\n",
    "    for p in periods[1:]:\n",
    "        g = math.gcd(g, p)\n",
    "    return g\n",
    "\n",
    "def is_aperiodic(P: np.ndarray, max_t: int = 500) -> bool:\n",
    "    p = chain_period(P, max_t=max_t)\n",
    "    return p == 1\n",
    "\n",
    "chain_period(P_demo), is_aperiodic(P_demo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dc72d8",
   "metadata": {},
   "source": [
    "## 5) Stationary Distribution: The Long-Run Equilibrium\n",
    "\n",
    "### üéØ What is a Stationary Distribution?\n",
    "\n",
    "A **stationary distribution** `œÄ` is a probability distribution over states that doesn't change under the Markov chain transition.\n",
    "\n",
    "**Mathematical definition:**\n",
    "- `œÄ` is a row vector with `k` elements (one per state)\n",
    "- `œÄ[i] ‚â• 0` for all `i`, and `Œ£·µ¢ œÄ[i] = 1` (it's a probability distribution)\n",
    "- **Stationarity property:** `œÄP = œÄ`\n",
    "\n",
    "**Intuition:** If the chain is in distribution `œÄ` at time `t`, it will still be in distribution `œÄ` at time `t+1`, `t+2`, etc. The distribution is \"stuck\" or \"balanced.\"\n",
    "\n",
    "---\n",
    "\n",
    "### üåä Physical Interpretation: Flow Equilibrium\n",
    "\n",
    "Think of states as rooms and transitions as people moving between rooms:\n",
    "\n",
    "- `œÄ[i]` = fraction of people in room `i`\n",
    "- `P[i,j]` = probability someone in room `i` moves to room `j`\n",
    "\n",
    "**Stationarity means:** \n",
    "- The flow of people leaving each room = flow of people entering that room\n",
    "- The distribution is **balanced** ‚Äì no net accumulation or depletion\n",
    "\n",
    "**Example:** 2-state weather model (Sunny ‚Üî Rainy)\n",
    "```\n",
    "If œÄ = [0.6, 0.4]:\n",
    "- 60% sunny days, 40% rainy days in the long run\n",
    "- Flow from S‚ÜíR = 0.6 √ó P[S,R]\n",
    "- Flow from R‚ÜíS = 0.4 √ó P[R,S]\n",
    "- These flows balance out!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîë Existence and Uniqueness\n",
    "\n",
    "**When does `œÄ` exist?**\n",
    "- Finite Markov chains **always** have at least one stationary distribution\n",
    "- But there might be multiple!\n",
    "\n",
    "**When is `œÄ` unique?**\n",
    "- If the chain is **irreducible** (can reach any state from any state)\n",
    "- Then there is **exactly one** stationary distribution\n",
    "- Moreover, if also **aperiodic**, then `Œº_t ‚Üí œÄ` as `t ‚Üí ‚àû` from any starting distribution!\n",
    "\n",
    "**Key theorem (Ergodic Theorem):**\n",
    "> If a chain is **irreducible** and **aperiodic** (called \"ergodic\"), then:\n",
    "> 1. Unique stationary distribution `œÄ` exists\n",
    "> 2. `P^t[i,j] ‚Üí œÄ[j]` as `t ‚Üí ‚àû` (regardless of starting state `i`)\n",
    "> 3. Time averages = space averages\n",
    "\n",
    "---\n",
    "\n",
    "### üõ†Ô∏è Two Methods to Compute `œÄ`\n",
    "\n",
    "#### **Method 1: Solve Linear System (Exact)**\n",
    "\n",
    "Solve the equation `œÄP = œÄ` subject to `Œ£·µ¢ œÄ[i] = 1`.\n",
    "\n",
    "This is equivalent to:\n",
    "- `(P^T - I)œÄ^T = 0` (transpose form)\n",
    "- Plus the constraint `Œ£·µ¢ œÄ[i] = 1`\n",
    "\n",
    "**Pros:**\n",
    "- Exact solution (up to numerical precision)\n",
    "- Works for small to medium chains (k ‚â§ 1000)\n",
    "- Doesn't require irreducibility or aperiodicity\n",
    "\n",
    "**Cons:**\n",
    "- Computationally expensive for large k (need to solve k√ók linear system)\n",
    "- Can be numerically unstable for ill-conditioned matrices\n",
    "\n",
    "---\n",
    "\n",
    "#### **Method 2: Power Iteration (Iterative)**\n",
    "\n",
    "Start with any distribution `Œº_0` (e.g., uniform), then iterate:\n",
    "$$\\mu_{t+1} = \\mu_t P$$\n",
    "\n",
    "For ergodic chains, `Œº_t ‚Üí œÄ` as `t ‚Üí ‚àû`.\n",
    "\n",
    "**Pros:**\n",
    "- Simple to implement\n",
    "- Works for very large chains\n",
    "- Only needs matrix-vector multiplication (fast!)\n",
    "- Intuitive: simulates long-run behavior\n",
    "\n",
    "**Cons:**\n",
    "- Only works for ergodic chains (irreducible + aperiodic)\n",
    "- Convergence can be slow if P has eigenvalues close to 1\n",
    "- Gives approximate solution (stop when change is small)\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Which Method Should You Use?\n",
    "\n",
    "| Situation | Recommended Method |\n",
    "|-----------|-------------------|\n",
    "| Small chain (k < 100) | Linear solve (exact and fast) |\n",
    "| Large chain (k > 1000) | Power iteration |\n",
    "| Don't know if ergodic | Linear solve (more robust) |\n",
    "| Need exact answer | Linear solve |\n",
    "| Just need approximation | Power iteration |\n",
    "| Periodic chain | Linear solve (power iteration won't converge!) |\n",
    "\n",
    "---\n",
    "\n",
    "### üìà Interpreting `œÄ`\n",
    "\n",
    "Once you have `œÄ`, it tells you:\n",
    "1. **Long-run probabilities:** Fraction of time spent in each state\n",
    "2. **Limiting distribution:** Where the chain \"settles down\" (if ergodic)\n",
    "3. **Expected rewards:** If state `i` gives reward `r_i`, average reward = `Œ£·µ¢ œÄ[i] r_i`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a725e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stationary_distribution_solve(P: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Solve œÄP=œÄ with sum(œÄ)=1 (works well for small k).\"\"\"\n",
    "    P = ensure_row_stochastic(P)\n",
    "    k = P.shape[0]\n",
    "    A = (P.T - np.eye(k))\n",
    "    # Replace one equation with normalization sum œÄ = 1\n",
    "    A[-1, :] = 1.0\n",
    "    b = np.zeros(k)\n",
    "    b[-1] = 1.0\n",
    "    pi = np.linalg.solve(A, b)\n",
    "    pi = np.clip(pi, 0.0, None)\n",
    "    pi = pi / pi.sum()\n",
    "    return pi\n",
    "\n",
    "def stationary_distribution_power(P: np.ndarray, tol: float = 1e-12, max_iter: int = 200_000) -> np.ndarray:\n",
    "    \"\"\"Power method: Œº <- ŒºP starting from uniform; good for ergodic chains.\"\"\"\n",
    "    P = ensure_row_stochastic(P)\n",
    "    k = P.shape[0]\n",
    "    mu = np.ones(k) / k\n",
    "    for _ in range(max_iter):\n",
    "        mu_next = mu @ P\n",
    "        if np.max(np.abs(mu_next - mu)) < tol:\n",
    "            mu = mu_next\n",
    "            break\n",
    "        mu = mu_next\n",
    "    mu = np.clip(mu, 0.0, None)\n",
    "    return mu / mu.sum()\n",
    "\n",
    "pi_solve = stationary_distribution_solve(P_demo)\n",
    "pi_power = stationary_distribution_power(P_demo)\n",
    "pi_solve, pi_power\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7bc1ba",
   "metadata": {},
   "source": [
    "## 6) Reversibility: Time-Reversible Chains\n",
    "\n",
    "### üéØ What is Reversibility?\n",
    "\n",
    "A distribution `œÄ` is **reversible** (satisfies **detailed balance**) for transition matrix `P` if:\n",
    "$$\\pi(x) \\cdot P(x,y) = \\pi(y) \\cdot P(y,x) \\quad \\text{for all states } x, y$$\n",
    "\n",
    "**Physical interpretation:**\n",
    "- `œÄ(x) P(x,y)` = flow from state `x` to state `y`\n",
    "- `œÄ(y) P(y,x)` = flow from state `y` to state `x`\n",
    "- **Detailed balance:** Each pair of states has **balanced bidirectional flow**\n",
    "\n",
    "Think of it like traffic: the number of cars going from city A to city B equals the number going from B to A.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ Why \"Reversible\"?\n",
    "\n",
    "If a chain with stationary distribution `œÄ` satisfies detailed balance, then **running the chain backwards in time looks statistically identical to running it forwards!**\n",
    "\n",
    "More precisely: if you record a long trajectory and play it backwards, you can't tell which direction is \"forward\" in time.\n",
    "\n",
    "**Examples of reversible chains:**\n",
    "- Random walk on an undirected graph (symmetric movement)\n",
    "- Metropolis-Hastings MCMC algorithm (by design)\n",
    "- Many physical systems in thermal equilibrium\n",
    "\n",
    "**Examples of non-reversible chains:**\n",
    "- Web surfing (links are directional ‚Äì more incoming than outgoing for popular pages)\n",
    "- Biological evolution (mutations are often directional)\n",
    "- Economic flows (money tends to concentrate)\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Key Theorem (Proposition 7.27)\n",
    "\n",
    "**If `œÄ` satisfies detailed balance for `P`, then `œÄ` is stationary.**\n",
    "\n",
    "**Proof sketch:**\n",
    "```\n",
    "(œÄP)[y] = Œ£‚Çì œÄ(x) P(x,y)         (definition of matrix multiplication)\n",
    "        = Œ£‚Çì œÄ(y) P(y,x)         (by detailed balance)\n",
    "        = œÄ(y) Œ£‚Çì P(y,x)         (factor out œÄ(y))\n",
    "        = œÄ(y) √ó 1               (row y of P sums to 1)\n",
    "        = œÄ(y)                   ‚úÖ\n",
    "```\n",
    "\n",
    "So detailed balance is a **sufficient condition** for stationarity (but not necessary ‚Äì stationary distributions can exist without detailed balance).\n",
    "\n",
    "---\n",
    "\n",
    "### üõ†Ô∏è Using Reversibility\n",
    "\n",
    "**Why check for reversibility?**\n",
    "1. **Easy verification:** If you have a candidate `œÄ`, checking detailed balance is simple\n",
    "2. **Constructive approach:** Design MCMC algorithms by enforcing detailed balance\n",
    "3. **Analytical insights:** Reversible chains have special algebraic properties\n",
    "\n",
    "**How to check:**\n",
    "Verify that the matrix `Œ† P` is symmetric, where `Œ† = diag(œÄ)`.\n",
    "- `(Œ† P)[x,y] = œÄ(x) P(x,y)`\n",
    "- `(Œ† P)[y,x] = œÄ(y) P(y,x)`\n",
    "- Symmetric means `(Œ† P)[x,y] = (Œ† P)[y,x]` ‚ü∫ detailed balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256521ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_reversible(P: np.ndarray, pi: np.ndarray, tol: float = 1e-10) -> bool:\n",
    "    P = ensure_row_stochastic(P)\n",
    "    pi = np.asarray(pi, dtype=float).reshape(-1)\n",
    "    pi = pi / pi.sum()\n",
    "    k = P.shape[0]\n",
    "    if pi.shape[0] != k:\n",
    "        raise ValueError(\"pi length must match P dimension.\")\n",
    "    lhs = pi[:, None] * P\n",
    "    rhs = pi[None, :] * P.T\n",
    "    return bool(np.max(np.abs(lhs - rhs)) <= tol)\n",
    "\n",
    "is_reversible(P_demo, pi_solve)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c63269",
   "metadata": {},
   "source": [
    "## 7) Random Walk on an Undirected Graph\n",
    "\n",
    "### üéØ What is a Random Walk on a Graph?\n",
    "\n",
    "Given an **undirected connected graph** `G = (V, E)`:\n",
    "- **Vertices (V):** Represent states (e.g., web pages, locations, people)\n",
    "- **Edges (E):** Represent connections (e.g., hyperlinks, roads, friendships)\n",
    "\n",
    "A **random walk** on this graph moves from vertex to vertex by:\n",
    "1. Choose one of the current vertex's neighbors **uniformly at random**\n",
    "2. Move to that neighbor\n",
    "3. Repeat\n",
    "\n",
    "---\n",
    "\n",
    "### üìê Transition Probabilities\n",
    "\n",
    "From vertex `v_i`, the probability of moving to `v_j` is:\n",
    "$$P(v_i, v_j) = \\begin{cases}\n",
    "\\frac{1}{\\deg(v_i)} & \\text{if } \\{v_i, v_j\\} \\in E \\text{ (they're neighbors)} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "Where `deg(v_i)` = number of edges connected to `v_i` (the **degree**).\n",
    "\n",
    "**Example:** 4-vertex graph\n",
    "```\n",
    "    1 --- 2\n",
    "    |     |\n",
    "    0 --- 3\n",
    "\n",
    "Degrees: deg(0)=2, deg(1)=2, deg(2)=2, deg(3)=2\n",
    "\n",
    "From vertex 0 (neighbors: 1, 3):\n",
    "  P[0,1] = 1/2, P[0,3] = 1/2, P[0,2] = 0, P[0,0] = 0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üé≤ Stationary Distribution: Proportional to Degree!\n",
    "\n",
    "For a random walk on an undirected connected graph, the stationary distribution is:\n",
    "$$\\pi(v_i) = \\frac{\\deg(v_i)}{2|E|}$$\n",
    "\n",
    "Where `2|E|` = sum of all degrees (each edge contributes to 2 vertices).\n",
    "\n",
    "**Simplified form:**\n",
    "$$\\pi(v_i) = \\frac{\\deg(v_i)}{\\sum_j \\deg(v_j)}$$\n",
    "\n",
    "**Intuition:**\n",
    "- High-degree vertices (hubs) are visited **more often** in the long run\n",
    "- This makes sense: more edges leading in = more likely to arrive there!\n",
    "\n",
    "**Example:** Linear chain `0 --- 1 --- 2 --- 3 --- 4`\n",
    "```\n",
    "Degrees: [1, 2, 2, 2, 1]\n",
    "Sum = 8\n",
    "\n",
    "Stationary distribution:\n",
    "œÄ = [1/8, 2/8, 2/8, 2/8, 1/8] = [0.125, 0.25, 0.25, 0.25, 0.125]\n",
    "\n",
    "The middle vertices are visited twice as often as the endpoints!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Why is This Distribution Stationary?\n",
    "\n",
    "This random walk chain is **reversible** with respect to the degree-based distribution!\n",
    "\n",
    "Check detailed balance:\n",
    "```\n",
    "œÄ(i) P(i,j) = [deg(i) / (2|E|)] √ó [1/deg(i)]     (if i and j are neighbors)\n",
    "            = 1 / (2|E|)\n",
    "\n",
    "œÄ(j) P(j,i) = [deg(j) / (2|E|)] √ó [1/deg(j)]     (symmetric)\n",
    "            = 1 / (2|E|)\n",
    "\n",
    "œÄ(i) P(i,j) = œÄ(j) P(j,i) ‚úÖ  Detailed balance holds!\n",
    "```\n",
    "\n",
    "By Proposition 7.27, this proves `œÄ` is stationary.\n",
    "\n",
    "---\n",
    "\n",
    "### üåê Applications\n",
    "\n",
    "1. **Network analysis:** Find important nodes (high degree = high PageRank)\n",
    "2. **Sampling from graphs:** Generate representative samples\n",
    "3. **Community detection:** Long trajectories tend to stay within communities\n",
    "4. **Load balancing:** Distribute resources proportional to connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9214f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_transition_from_edges(num_nodes: int, edges: Sequence[Tuple[int, int]]) -> np.ndarray:\n",
    "    \"\"\"Build transition matrix for random walk on an undirected graph.\"\"\"\n",
    "    if num_nodes <= 0:\n",
    "        raise ValueError(\"num_nodes must be positive.\")\n",
    "    adj = [[] for _ in range(num_nodes)]\n",
    "    for a, b in edges:\n",
    "        if not (0 <= a < num_nodes and 0 <= b < num_nodes):\n",
    "            raise ValueError(\"Edge has node out of range.\")\n",
    "        if a == b:\n",
    "            continue\n",
    "        adj[a].append(b)\n",
    "        adj[b].append(a)\n",
    "    P = np.zeros((num_nodes, num_nodes), dtype=float)\n",
    "    for i in range(num_nodes):\n",
    "        deg = len(adj[i])\n",
    "        if deg == 0:\n",
    "            raise ValueError(\"Graph has an isolated node; random walk would get stuck.\")\n",
    "        for j in adj[i]:\n",
    "            P[i, j] += 1.0 / deg\n",
    "    return P\n",
    "\n",
    "def stationary_for_undirected_random_walk(num_nodes: int, edges: Sequence[Tuple[int, int]]) -> np.ndarray:\n",
    "    \"\"\"Return œÄ proportional to degree for connected undirected graph random walk.\"\"\"\n",
    "    deg = np.zeros(num_nodes, dtype=float)\n",
    "    for a, b in edges:\n",
    "        if a == b:\n",
    "            continue\n",
    "        deg[a] += 1\n",
    "        deg[b] += 1\n",
    "    if np.any(deg == 0):\n",
    "        raise ValueError(\"Graph has isolated node.\")\n",
    "    pi = deg / deg.sum()\n",
    "    return pi\n",
    "\n",
    "# Demo graph: 5 nodes in a chain 0-1-2-3-4\n",
    "edges_demo = [(0,1),(1,2),(2,3),(3,4)]\n",
    "P_rw = random_walk_transition_from_edges(5, edges_demo)\n",
    "pi_deg = stationary_for_undirected_random_walk(5, edges_demo)\n",
    "\n",
    "is_reversible(P_rw, pi_deg), pi_deg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763cad3c",
   "metadata": {},
   "source": [
    "### Random Surfer / PageRank-Style Chain\n",
    "\n",
    "### üéØ The Problem with Basic Random Walks\n",
    "\n",
    "Basic random walks on graphs can have issues:\n",
    "1. **Dead ends (sinks):** Pages with no outgoing links ‚Üí walker gets stuck!\n",
    "2. **Periodic behavior:** Bipartite graphs ‚Üí oscillation, no convergence\n",
    "3. **Disconnected components:** Can't reach all states\n",
    "\n",
    "**Real-world example:** Web graph\n",
    "- Many pages have no outgoing links (dead ends)\n",
    "- Link structure is highly irregular\n",
    "- Original PageRank needs to handle these cases\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Solution: Random Surfer with Teleportation\n",
    "\n",
    "The **random surfer model** blends two behaviors:\n",
    "1. **With probability `Œ±`:** Follow a link from the current page (normal random walk)\n",
    "2. **With probability `1-Œ±`:** \"Teleport\" to a **random page** uniformly\n",
    "\n",
    "**Modified transition matrix:**\n",
    "$$P' = \\alpha P + (1-\\alpha) \\frac{1}{k} \\mathbf{1}\\mathbf{1}^T$$\n",
    "\n",
    "Where:\n",
    "- `P` = base transition matrix (from graph structure)\n",
    "- `k` = number of states\n",
    "- `1/k ùüôùüô·µÄ` = uniform distribution matrix (all entries = 1/k)\n",
    "- `Œ±` = damping factor (typically 0.85 in PageRank)\n",
    "\n",
    "---\n",
    "\n",
    "### üîë Why This Works\n",
    "\n",
    "**Guarantees ergodicity:**\n",
    "- **Irreducible:** Can reach any state from any state (via teleportation)\n",
    "- **Aperiodic:** Self-loops exist (stay in same state via teleportation with prob. `(1-Œ±)/k > 0`)\n",
    "- ‚ûú Unique stationary distribution exists!\n",
    "- ‚ûú Power method converges!\n",
    "\n",
    "**Physical interpretation:**\n",
    "- Models realistic web surfing: users sometimes type random URLs instead of following links\n",
    "- The `(1-Œ±)` probability prevents getting stuck in dead ends\n",
    "- Higher `Œ±` = more emphasis on link structure; lower `Œ±` = more uniform exploration\n",
    "\n",
    "---\n",
    "\n",
    "### üéõÔ∏è The Parameter `Œ±` (Damping Factor)\n",
    "\n",
    "**Typical value:** `Œ± = 0.85` (from original PageRank paper)\n",
    "\n",
    "| Œ± value | Interpretation |\n",
    "|---------|----------------|\n",
    "| Œ± = 1.0 | Pure random walk (may have problems) |\n",
    "| Œ± = 0.85 | 85% follow links, 15% random jump (standard) |\n",
    "| Œ± = 0.5 | Equal weight to structure vs. uniform |\n",
    "| Œ± = 0.0 | Completely uniform (ignores graph structure!) |\n",
    "\n",
    "**Trade-offs:**\n",
    "- **Higher Œ±:** Stationary distribution more influenced by graph structure, but slower convergence\n",
    "- **Lower Œ±:** Faster convergence, more uniform distribution, less influenced by topology\n",
    "\n",
    "---\n",
    "\n",
    "### üåê PageRank Connection\n",
    "\n",
    "This is essentially **Google's PageRank algorithm**!\n",
    "- States = web pages\n",
    "- Edges = hyperlinks\n",
    "- Stationary distribution `œÄ[i]` = \"importance\" or \"rank\" of page `i`\n",
    "- Sort pages by `œÄ[i]` to rank search results\n",
    "\n",
    "**Why it works:**\n",
    "- Important pages have many incoming links (high degree)\n",
    "- Links from important pages count more (recursive definition!)\n",
    "- Stationary distribution captures this recursive importance naturally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79187f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_surfer_transition(P: np.ndarray, alpha: float = 0.85) -> np.ndarray:\n",
    "    \"\"\"Blend a base transition matrix with uniform teleportation.\"\"\"\n",
    "    if not (0.0 < alpha < 1.0):\n",
    "        raise ValueError(\"alpha must be in (0,1).\")\n",
    "    P = ensure_row_stochastic(P)\n",
    "    k = P.shape[0]\n",
    "    U = np.ones((k, k), dtype=float) / k\n",
    "    return alpha * P + (1 - alpha) * U\n",
    "\n",
    "P_surf = random_surfer_transition(P_rw, alpha=0.85)\n",
    "pi_surf = stationary_distribution_power(P_surf)\n",
    "pi_surf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd14d2b9",
   "metadata": {},
   "source": [
    "## 8) Exercise: Text as a Markov Chain (Word-Level)\n",
    "\n",
    "### üéØ The Idea: Simple Language Modeling\n",
    "\n",
    "Can we model language as a Markov chain? The idea:\n",
    "- **States** = words in vocabulary\n",
    "- **Transitions** = probability of word `w_2` following word `w_1`\n",
    "- **Process:** Given text, estimate `P(w_2 | w_1)` and use it to generate new sentences\n",
    "\n",
    "This is a **very simple language model** (1st-order Markov chain = bigram model).\n",
    "\n",
    "---\n",
    "\n",
    "### üìö Example\n",
    "\n",
    "Given text: \"the cat sat on the mat the cat sat on the rug\"\n",
    "\n",
    "**Word transitions:**\n",
    "```\n",
    "\"the\" ‚Üí \"cat\" (twice)\n",
    "\"the\" ‚Üí \"mat\" (once)  \n",
    "\"the\" ‚Üí \"rug\" (once)\n",
    "\"cat\" ‚Üí \"sat\" (twice)\n",
    "\"sat\" ‚Üí \"on\" (twice)\n",
    "\"on\" ‚Üí \"the\" (twice)\n",
    "\"mat\" ‚Üí \"the\" (once)\n",
    "\"rug\" ‚Üí (end)\n",
    "```\n",
    "\n",
    "**Transition probabilities from \"the\":**\n",
    "```\n",
    "P(\"the\" ‚Üí \"cat\") = 2/4 = 0.5\n",
    "P(\"the\" ‚Üí \"mat\") = 1/4 = 0.25\n",
    "P(\"the\" ‚Üí \"rug\") = 1/4 = 0.25\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîß The Algorithm\n",
    "\n",
    "#### **Step 1: Tokenize**\n",
    "Break text into words (tokens):\n",
    "```\n",
    "\"The cat sat!\" ‚Üí [\"the\", \"cat\", \"sat\"]  (lowercase, remove punctuation)\n",
    "```\n",
    "\n",
    "#### **Step 2: Count Transitions**\n",
    "Build a count matrix:\n",
    "```\n",
    "count[w1, w2] = number of times w2 follows w1 in the text\n",
    "```\n",
    "\n",
    "#### **Step 3: Normalize to Get Probabilities**\n",
    "For each word `w1`, normalize its row:\n",
    "```\n",
    "P[w1, w2] = count[w1, w2] / Œ£_{w} count[w1, w]\n",
    "```\n",
    "\n",
    "Now `P` is a row-stochastic transition matrix!\n",
    "\n",
    "#### **Step 4 (Optional): Smoothing**\n",
    "Problem: What if we never saw \"the\" ‚Üí \"zebra\" in training? `P[\"the\", \"zebra\"] = 0`, even if it's grammatically valid.\n",
    "\n",
    "**Solution:** Add a small constant (Laplace smoothing):\n",
    "```\n",
    "count[w1, w2] += Œµ  (e.g., Œµ = 0.01)\n",
    "```\n",
    "\n",
    "This gives small probability to unseen transitions.\n",
    "\n",
    "---\n",
    "\n",
    "### üìä What Can We Do?\n",
    "\n",
    "1. **Compute transition probabilities:**\n",
    "   ```python\n",
    "   P(\"the\" ‚Üí \"cat\") = ?\n",
    "   ```\n",
    "\n",
    "2. **Generate sentences:**\n",
    "   - Start with a word (e.g., \"the\")\n",
    "   - Sample next word from `P[\"the\", :]`\n",
    "   - Continue for `n` words\n",
    "   - Result: \"the cat sat on the mat ...\" (machine-generated text!)\n",
    "\n",
    "3. **Evaluate perplexity:**\n",
    "   How well does the model predict held-out text?\n",
    "\n",
    "---\n",
    "\n",
    "### üé® Try It Yourself!\n",
    "\n",
    "**Experiment ideas:**\n",
    "- Use a real book (e.g., Pride & Prejudice from Project Gutenberg)\n",
    "- Try different smoothing values\n",
    "- Compare generated text with/without smoothing\n",
    "- Build a 2nd-order model (consider last 2 words instead of 1)\n",
    "\n",
    "**Limitations of 1st-order models:**\n",
    "- No long-range dependencies (can't remember context from 10 words ago)\n",
    "- Grammar violations are common\n",
    "- Modern language models (GPT, etc.) use much more sophisticated architectures!\n",
    "\n",
    "But this is a great starting point to understand sequence modeling. üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f580dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_simple(text: str, lowercase: bool = True) -> List[str]:\n",
    "    \"\"\"Very simple tokenizer: keeps letters and apostrophes, splits on others.\"\"\"\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "    tokens = []\n",
    "    word = []\n",
    "    for ch in text:\n",
    "        if ch.isalpha() or ch == \"'\":\n",
    "            word.append(ch)\n",
    "        else:\n",
    "            if word:\n",
    "                tokens.append(\"\".join(word))\n",
    "                word = []\n",
    "    if word:\n",
    "        tokens.append(\"\".join(word))\n",
    "    return tokens\n",
    "\n",
    "def estimate_transition_matrix_from_tokens(\n",
    "    tokens: Sequence[str],\n",
    "    smoothing: float = 0.0,\n",
    "    min_count: int = 1,\n",
    ") -> Tuple[np.ndarray, Dict[str, int], List[str]]:\n",
    "    \"\"\"Estimate word-level Markov chain P from tokens (Laplace smoothing optional).\"\"\"\n",
    "    # Build vocabulary\n",
    "    counts = {}\n",
    "    for w in tokens:\n",
    "        counts[w] = counts.get(w, 0) + 1\n",
    "    vocab = [w for w, c in counts.items() if c >= min_count]\n",
    "    vocab.sort()\n",
    "    idx = {w: i for i, w in enumerate(vocab)}\n",
    "    k = len(vocab)\n",
    "    if k == 0:\n",
    "        raise ValueError(\"No tokens after applying min_count.\")\n",
    "\n",
    "    C = np.full((k, k), smoothing, dtype=float)\n",
    "    for a, b in zip(tokens[:-1], tokens[1:]):\n",
    "        if a in idx and b in idx:\n",
    "            C[idx[a], idx[b]] += 1.0\n",
    "    P = normalize_rows(C)\n",
    "    return P, idx, vocab\n",
    "\n",
    "def transition_prob(P: np.ndarray, idx: Dict[str, int], a: str, b: str) -> float:\n",
    "    \"\"\"One-step probability P(a->b) if both in vocab.\"\"\"\n",
    "    if a not in idx or b not in idx:\n",
    "        return 0.0\n",
    "    return float(P[idx[a], idx[b]])\n",
    "\n",
    "def generate_tokens_from_chain(\n",
    "    P: np.ndarray,\n",
    "    start_state: int,\n",
    "    n_tokens: int,\n",
    "    seed: Optional[int] = 0,\n",
    ") -> List[int]:\n",
    "    \"\"\"Generate a sequence of state indices of length n_tokens.\"\"\"\n",
    "    traj = simulate_markov_chain(P, x0=start_state, n_steps=max(0, n_tokens - 1), seed=seed)\n",
    "    return traj.tolist()\n",
    "\n",
    "def generate_sentence(\n",
    "    P: np.ndarray,\n",
    "    vocab: List[str],\n",
    "    start_word: str,\n",
    "    n_words: int = 15,\n",
    "    seed: Optional[int] = 0,\n",
    ") -> str:\n",
    "    \"\"\"Generate a sentence-like string of n_words, starting from start_word (must exist in vocab).\"\"\"\n",
    "    idx = {w:i for i,w in enumerate(vocab)}\n",
    "    if start_word not in idx:\n",
    "        raise ValueError(f\"start_word '{start_word}' not in vocabulary.\")\n",
    "    states = generate_tokens_from_chain(P, idx[start_word], n_words, seed=seed)\n",
    "    return \" \".join(vocab[s] for s in states)\n",
    "\n",
    "# Demo with a tiny text sample (replace with file contents)\n",
    "demo_text = \"Lady Catherine was not pleased. Lady Catherine spoke to her niece.\"\n",
    "tokens = tokenize_simple(demo_text, lowercase=True)\n",
    "P_txt, idx_txt, vocab_txt = estimate_transition_matrix_from_tokens(tokens, smoothing=0.1)\n",
    "\n",
    "print(\"P(the->her) =\", transition_prob(P_txt, idx_txt, \"the\", \"her\"))\n",
    "print(generate_sentence(P_txt, vocab_txt, start_word=\"lady\", n_words=10, seed=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff28999",
   "metadata": {},
   "source": [
    "## 9) Exercise: Branching Process (Galton-Watson)\n",
    "\n",
    "### üéØ What is a Branching Process?\n",
    "\n",
    "A **branching process** models **population dynamics** where individuals reproduce independently:\n",
    "- Start with `Z_0` individuals (e.g., `Z_0 = 1`)\n",
    "- Each individual produces a **random number of offspring** (according to some distribution)\n",
    "- All individuals reproduce simultaneously, then die\n",
    "- The next generation has `Z_1` individuals (sum of all offspring)\n",
    "- Repeat: `Z_0 ‚Üí Z_1 ‚Üí Z_2 ‚Üí ...`\n",
    "\n",
    "**Key question:** Does the population die out (go **extinct**) or grow forever?\n",
    "\n",
    "---\n",
    "\n",
    "### üë®‚Äçüë©‚Äçüëß‚Äçüë¶ Example: Simple Reproduction Model\n",
    "\n",
    "Each individual has 0, 1, or 2 offspring with probabilities:\n",
    "```\n",
    "P(0 offspring) = p_0\n",
    "P(1 offspring) = p_1  \n",
    "P(2 offspring) = p_2\n",
    "```\n",
    "\n",
    "**Generation dynamics:**\n",
    "```\n",
    "Generation 0: Z_0 = 1 individual\n",
    "\n",
    "Generation 1: The individual has X offspring\n",
    "              Z_1 = X  (X ‚àà {0, 1, 2})\n",
    "\n",
    "Generation 2: Each of the Z_1 individuals has offspring independently\n",
    "              Z_2 = X_1 + X_2 + ... + X_{Z_1}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üß¨ Why is This a Markov Chain?\n",
    "\n",
    "The next population size `Z_{t+1}` depends **only on the current size** `Z_t`, not on history!\n",
    "- **State space:** {0, 1, 2, 3, ...} (non-negative integers)\n",
    "- **State 0 is absorbing:** Once extinct (Z_t = 0), stays extinct forever\n",
    "- **Markov property holds:** P(Z_{t+1} | Z_t, Z_{t-1}, ..., Z_0) = P(Z_{t+1} | Z_t)\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Key Quantity: Mean Offspring `Œº`\n",
    "\n",
    "Let `Œº = E[X]` be the expected number of offspring per individual:\n",
    "$$\\mu = 0 \\cdot p_0 + 1 \\cdot p_1 + 2 \\cdot p_2$$\n",
    "\n",
    "**Three regimes:**\n",
    "\n",
    "1. **Subcritical (`Œº < 1`):** \n",
    "   - Population **almost surely goes extinct**\n",
    "   - E.g., each individual has < 1 child on average ‚Üí shrinking population\n",
    "\n",
    "2. **Critical (`Œº = 1`):**\n",
    "   - Population **almost surely goes extinct** (but takes longer)\n",
    "   - E.g., exactly replacement level, but randomness causes eventual extinction\n",
    "\n",
    "3. **Supercritical (`Œº > 1`):**\n",
    "   - **Positive probability of survival** (but still might go extinct!)\n",
    "   - Two outcomes: either goes extinct OR grows exponentially\n",
    "   - E.g., each individual has > 1 child on average ‚Üí growth possible\n",
    "\n",
    "---\n",
    "\n",
    "### üé≤ Extinction Probability\n",
    "\n",
    "Let `q` = probability of eventual extinction starting from 1 individual.\n",
    "\n",
    "**Theoretical result:** `q` is the **smallest non-negative solution** to:\n",
    "$$q = \\sum_{k=0}^{\\infty} p_k q^k$$\n",
    "\n",
    "For our 3-state model (`k ‚àà {0,1,2}`):\n",
    "$$q = p_0 + p_1 q + p_2 q^2$$\n",
    "\n",
    "**Special cases:**\n",
    "- If `Œº ‚â§ 1`: Then `q = 1` (extinction is certain)\n",
    "- If `Œº > 1`: Then `q < 1` (survival possible!)\n",
    "\n",
    "---\n",
    "\n",
    "### ‚è±Ô∏è Extinction Time (Lifetime)\n",
    "\n",
    "Even if extinction is certain, **how long does it take?**\n",
    "\n",
    "Define `œÑ` = first time when `Z_t = 0` (extinction time or \"lifetime\").\n",
    "\n",
    "**Questions we can answer via simulation:**\n",
    "1. What is `E[œÑ]` (expected lifetime)?\n",
    "2. What is the distribution of `œÑ`?\n",
    "3. How does `E[œÑ]` depend on `p_0, p_1, p_2`?\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Simulation Approach\n",
    "\n",
    "1. **Start:** `Z_0 = 1`\n",
    "2. **At each generation:**\n",
    "   - If `Z_t = 0`: Stop (extinct!)\n",
    "   - Otherwise: For each individual, draw offspring count from {0,1,2} with probs. `(p_0, p_1, p_2)`\n",
    "   - Sum up: `Z_{t+1} = ` total offspring\n",
    "3. **Record:** Trajectory `[Z_0, Z_1, Z_2, ..., Z_œÑ]` where `Z_œÑ = 0`\n",
    "\n",
    "Run many simulations to estimate:\n",
    "- `E[œÑ]` ‚âà average extinction time over simulations\n",
    "- `P(œÑ > t)` ‚âà fraction of simulations still alive at time `t`\n",
    "\n",
    "---\n",
    "\n",
    "### üåç Real-World Applications\n",
    "\n",
    "- **Biology:** Species extinction, epidemic spread (each infected person infects others)\n",
    "- **Nuclear physics:** Neutron chain reactions\n",
    "- **Genealogy:** Family name survival (surnames passed through male lineage)\n",
    "- **Startups:** Company survival (each company spawns spin-offs or fails)\n",
    "\n",
    "This is a fundamental model in probability theory with deep connections to random trees, percolation, and critical phenomena!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e16683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_branching_process(\n",
    "    p: Sequence[float],\n",
    "    Z0: int = 1,\n",
    "    max_steps: int = 10_000,\n",
    "    seed: Optional[int] = 0,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Simulate branching process until extinction or max_steps.\"\"\"\n",
    "    p = np.asarray(p, dtype=float)\n",
    "    if p.shape[0] != 3:\n",
    "        raise ValueError(\"p must have length 3 for offspring {0,1,2}.\")\n",
    "    if np.any(p < 0) or not np.isclose(p.sum(), 1.0):\n",
    "        raise ValueError(\"p must be a probability vector summing to 1.\")\n",
    "    if Z0 < 0:\n",
    "        raise ValueError(\"Z0 must be >= 0.\")\n",
    "    rng = np.random.default_rng(seed)\n",
    "    Z = [int(Z0)]\n",
    "    for _ in range(max_steps):\n",
    "        if Z[-1] == 0:\n",
    "            break\n",
    "        # offspring for each of Z[-1] individuals\n",
    "        offspring = rng.choice([0,1,2], size=Z[-1], p=p)\n",
    "        Z.append(int(np.sum(offspring)))\n",
    "    return np.array(Z, dtype=int)\n",
    "\n",
    "def extinction_time(Z_path: np.ndarray) -> Optional[int]:\n",
    "    \"\"\"Return first n with Z_n=0; None if not extinct in simulated path.\"\"\"\n",
    "    zeros = np.where(Z_path == 0)[0]\n",
    "    return int(zeros[0]) if zeros.size else None\n",
    "\n",
    "def estimate_expected_lifetime(\n",
    "    p: Sequence[float],\n",
    "    n_sims: int = 5000,\n",
    "    Z0: int = 1,\n",
    "    max_steps: int = 10_000,\n",
    "    seed: Optional[int] = 0,\n",
    ") -> float:\n",
    "    \"\"\"Estimate E[tau] where tau is extinction time.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    taus = []\n",
    "    for s in range(n_sims):\n",
    "        Z = simulate_branching_process(p, Z0=Z0, max_steps=max_steps, seed=int(rng.integers(0, 2**31-1)))\n",
    "        tau = extinction_time(Z)\n",
    "        if tau is None:\n",
    "            tau = max_steps  # censored; you can change this rule if you want\n",
    "        taus.append(tau)\n",
    "    return float(np.mean(taus))\n",
    "\n",
    "# Demo with p=(1/3,1/3,1/3)\n",
    "p = (1/3, 1/3, 1/3)\n",
    "Z = simulate_branching_process(p, max_steps=200, seed=3)\n",
    "tau = extinction_time(Z)\n",
    "tau, Z[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93528ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one sample path\n",
    "plt.figure()\n",
    "plt.plot(Z, marker='o', linewidth=1)\n",
    "plt.title(\"Branching process sample path\")\n",
    "plt.xlabel(\"n\")\n",
    "plt.ylabel(\"Z_n\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Estimated expected lifetime (rough):\", estimate_expected_lifetime(p, n_sims=2000, max_steps=500, seed=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954193e3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Summary: Key Concepts and Their Relationships\n",
    "\n",
    "### üéØ The Big Picture\n",
    "\n",
    "**Markov chains** model systems that transition between states with **memoryless** transitions (future depends only on present, not past).\n",
    "\n",
    "---\n",
    "\n",
    "### üó∫Ô∏è Concept Map\n",
    "\n",
    "```\n",
    "                    MARKOV CHAIN\n",
    "                         |\n",
    "        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "        |                |                |\n",
    "   TRANSITION       DISTRIBUTIONS    SIMULATION\n",
    "    MATRIX P          Œº_t = Œº_0 P^t      (RMR)\n",
    "        |                                  |\n",
    "   Row-stochastic                   Inversion\n",
    "   (rows sum to 1)                   Sampling\n",
    "        |\n",
    "        |\n",
    "    STRUCTURE                      LONG-RUN BEHAVIOR\n",
    "        |                                  |\n",
    "   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "   |         |                    |               |\n",
    "Irreducible Period          Stationary œÄ     Reversibility\n",
    "   |         |              (œÄP = œÄ)          (detailed balance)\n",
    "   |         |                    |\n",
    "   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "              |\n",
    "         ERGODIC CHAIN\n",
    "    (irreducible + aperiodic)\n",
    "              |\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    |                   |\n",
    "Unique œÄ          Œº_t ‚Üí œÄ\n",
    "Convergence      Power method\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîë Essential Properties\n",
    "\n",
    "| Property | Definition | Why It Matters |\n",
    "|----------|-----------|----------------|\n",
    "| **Markov property** | P(X_{t+1} \\| X_t, ..., X_0) = P(X_{t+1} \\| X_t) | Memoryless: only current state matters |\n",
    "| **Row-stochastic** | Each row of P sums to 1 | Valid probability distribution for transitions |\n",
    "| **Irreducible** | Can reach any state from any state | ‚ûú Unique stationary distribution |\n",
    "| **Aperiodic** | Period = 1 (no cyclic structure) | ‚ûú Smooth convergence to œÄ |\n",
    "| **Ergodic** | Irreducible + aperiodic | ‚ûú Œº_t ‚Üí œÄ guaranteed! |\n",
    "| **Stationary œÄ** | œÄP = œÄ | Equilibrium distribution (doesn't change) |\n",
    "| **Reversible** | œÄ(i)P(i,j) = œÄ(j)P(j,i) | Detailed balance ‚ûú easy to verify œÄ |\n",
    "\n",
    "---\n",
    "\n",
    "### üéì Key Theorems to Remember\n",
    "\n",
    "1. **Chapman-Kolmogorov:** `Œº_t = Œº_0 P^t` (distributions evolve by matrix multiplication)\n",
    "\n",
    "2. **Ergodic Theorem:** If chain is irreducible + aperiodic, then:\n",
    "   - Unique stationary distribution œÄ exists\n",
    "   - Œº_t ‚Üí œÄ as t ‚Üí ‚àû (regardless of starting point)\n",
    "   - Time averages = space averages\n",
    "\n",
    "3. **Reversibility ‚áí Stationarity:** If œÄ satisfies detailed balance, then œÄP = œÄ\n",
    "\n",
    "4. **Random Walk on Graph:** Stationary distribution is proportional to degree\n",
    "\n",
    "---\n",
    "\n",
    "### üõ†Ô∏è Practical Workflow\n",
    "\n",
    "When analyzing a Markov chain:\n",
    "\n",
    "1. **Validate:** Check that P is row-stochastic\n",
    "2. **Structure:** Check if irreducible (all states communicate)\n",
    "3. **Period:** Check if aperiodic (returns not cyclic)\n",
    "4. **Stationary distribution:**\n",
    "   - If ergodic: Use power method (fast, simple)\n",
    "   - Otherwise: Solve linear system (exact)\n",
    "5. **Reversibility:** Check detailed balance if you have a candidate œÄ\n",
    "6. **Simulate:** Use RMR for trajectories and empirical estimates\n",
    "\n",
    "---\n",
    "\n",
    "### üìà When to Use Which Method?\n",
    "\n",
    "#### **Computing Stationary Distribution:**\n",
    "- Small chain (k < 100): **Linear solve** (exact)\n",
    "- Large chain: **Power iteration** (if ergodic)\n",
    "- Periodic chain: **Linear solve** (power iteration won't converge!)\n",
    "\n",
    "#### **Analyzing Structure:**\n",
    "- Small chain: Check **all pairs** of states\n",
    "- Large chain: Use **graph algorithms** (DFS, strongly connected components)\n",
    "\n",
    "#### **Simulation:**\n",
    "- Few steps: **Direct matrix multiplication** (Œº_t = Œº_0 P^t)\n",
    "- Many steps or trajectories: **RMR simulation** (faster, more flexible)\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ Next Steps & Extensions\n",
    "\n",
    "#### **Advanced Topics to Explore:**\n",
    "\n",
    "1. **Continuous-time Markov chains:**\n",
    "   - Transitions happen at random times (not discrete steps)\n",
    "   - Uses rate matrices instead of transition matrices\n",
    "\n",
    "2. **Markov Chain Monte Carlo (MCMC):**\n",
    "   - Design chains to sample from target distributions\n",
    "   - Metropolis-Hastings, Gibbs sampling\n",
    "   - Applications: Bayesian inference, computational physics\n",
    "\n",
    "3. **Hidden Markov Models (HMMs):**\n",
    "   - States are hidden, only observations are visible\n",
    "   - Applications: speech recognition, bioinformatics\n",
    "\n",
    "4. **Markov Decision Processes (MDPs):**\n",
    "   - Add actions and rewards to Markov chains\n",
    "   - Basis of reinforcement learning (Q-learning, policy gradient)\n",
    "\n",
    "5. **Infinite state spaces:**\n",
    "   - Countably infinite (birth-death processes, queues)\n",
    "   - Uncountable (continuous state spaces, diffusions)\n",
    "\n",
    "6. **Higher-order models:**\n",
    "   - 2nd-order: P(X_t | X_{t-1}, X_{t-2})\n",
    "   - Variable-order Markov models\n",
    "   - Neural language models\n",
    "\n",
    "---\n",
    "\n",
    "### üìñ Recommended Resources\n",
    "\n",
    "**Books:**\n",
    "- *Markov Chains* by J.R. Norris (rigorous mathematical treatment)\n",
    "- *Introduction to Probability Models* by Sheldon Ross (applications-focused)\n",
    "- *Monte Carlo Statistical Methods* by Robert & Casella (MCMC focus)\n",
    "\n",
    "**Online:**\n",
    "- 3Blue1Brown: \"Markov Chains\" (YouTube - great visual intuition)\n",
    "- Brilliant.org: Interactive Markov chain problems\n",
    "- setosa.io: Interactive visualizations of random walks\n",
    "\n",
    "**Practice:**\n",
    "- Implement MCMC samplers (Metropolis-Hastings)\n",
    "- Analyze real-world networks (social, biological, web)\n",
    "- Build higher-order language models\n",
    "- Study queueing theory and applications\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You now have a complete toolkit for working with finite Markov chains. These concepts form the foundation for:\n",
    "- Probabilistic modeling\n",
    "- Time series analysis  \n",
    "- Machine learning (HMMs, RL)\n",
    "- Network science\n",
    "- Computational statistics (MCMC)\n",
    "\n",
    "**Keep exploring, keep experimenting, and have fun with Markov chains!** üöÄ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
