{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d506d6",
   "metadata": {},
   "source": [
    "# Risk & Distribution Estimation - Cheat Sheet\n",
    "\n",
    "## Key Concepts\n",
    "1. **Empirical Distribution Function (EDF)**: Estimate unknown distribution from data\n",
    "2. **DKW Inequality**: Provides confidence bands for the EDF\n",
    "3. **Density Estimation**: PMF for discrete data, histograms for continuous data\n",
    "4. **Risk Minimization**: Finding the best model by minimizing loss (e.g., linear regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d133376a",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Empirical Distribution Function (EDF)\n",
    "\n",
    "**What it is:** A way to estimate the unknown distribution function $F^*$ from data.\n",
    "\n",
    "**Formula:** $\\widehat{F}_n(x) = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{1}_{[X_i,+\\infty)}(x)$\n",
    "\n",
    "**In words:** For each point $x$, count how many data points are $\\leq x$, then divide by total number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f475581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# CHANGE THESE PARAMETERS\n",
    "distribution_type = 'poisson'  # Options: 'poisson', 'normal', 'exponential', 'uniform'\n",
    "sample_size = 1000\n",
    "param1 = 1  # For poisson: lambda, normal: mean, exponential: lambda, uniform: low\n",
    "param2 = 0  # For normal: std, uniform: high (otherwise unused)\n",
    "\n",
    "# Generate data based on distribution type\n",
    "if distribution_type == 'poisson':\n",
    "    data = np.random.poisson(param1, size=sample_size)\n",
    "elif distribution_type == 'normal':\n",
    "    data = np.random.normal(param1, param2 if param2 != 0 else 1, size=sample_size)\n",
    "elif distribution_type == 'exponential':\n",
    "    data = np.random.exponential(1/param1, size=sample_size)\n",
    "elif distribution_type == 'uniform':\n",
    "    data = np.random.uniform(param1, param2 if param2 != 0 else param1+1, size=sample_size)\n",
    "\n",
    "print(f\"Generated {sample_size} samples from {distribution_type} distribution\")\n",
    "print(f\"First 10 samples: {data[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d6cb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create EDF\n",
    "def makeEDF(data):\n",
    "    \"\"\"Create Empirical Distribution Function from data\"\"\"\n",
    "    sorted_data = np.sort(data)\n",
    "    n = len(data)\n",
    "    # Create step function: for each unique value, compute proportion <= that value\n",
    "    unique_vals = np.unique(sorted_data)\n",
    "    edf_vals = np.array([np.sum(data <= val) / n for val in unique_vals])\n",
    "    return unique_vals, edf_vals\n",
    "\n",
    "# Function to plot EDF\n",
    "def plotEDF(x_vals, edf_vals, title=\"Empirical Distribution Function\"):\n",
    "    \"\"\"Plot the Empirical Distribution Function\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.step(x_vals, edf_vals, where='post', linewidth=2, label='EDF')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('F(x)')\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Create and plot EDF\n",
    "x_vals, edf_vals = makeEDF(data)\n",
    "plotEDF(x_vals, edf_vals, f\"EDF for {distribution_type} distribution (n={sample_size})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20315c2",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. DKW Inequality & Confidence Bands\n",
    "\n",
    "**What it is:** Tells us how confident we can be that our EDF is close to the true distribution.\n",
    "\n",
    "**DKW Inequality:** $P\\left( \\sup_x | \\widehat{F}_n(x) - F^*(x) | > \\varepsilon \\right) \\leq 2 \\exp(-2n\\varepsilon^2)$\n",
    "\n",
    "**Confidence Band:** With probability $\\geq 1-\\alpha$, the true $F^*$ lies within:\n",
    "- $\\underline{C}_n(x) = \\max\\{\\widehat{F}_n(x) - \\varepsilon_n, 0\\}$\n",
    "- $\\overline{C}_n(x) = \\min\\{\\widehat{F}_n(x) + \\varepsilon_n, 1\\}$\n",
    "- where $\\varepsilon_n = \\sqrt{\\frac{1}{2n}\\log(\\frac{2}{\\alpha})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a681b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS PARAMETER\n",
    "confidence_level = 0.95  # Common values: 0.90, 0.95, 0.99\n",
    "\n",
    "# Calculate confidence bands using DKW inequality\n",
    "alpha = 1 - confidence_level\n",
    "n = len(data)\n",
    "epsilon_n = np.sqrt((1/(2*n)) * np.log(2/alpha))\n",
    "\n",
    "print(f\"Confidence level: {confidence_level*100}%\")\n",
    "print(f\"Sample size: {n}\")\n",
    "print(f\"Epsilon (band width): {epsilon_n:.4f}\")\n",
    "\n",
    "# Compute confidence bands\n",
    "x_vals, edf_vals = makeEDF(data)\n",
    "lower_band = np.maximum(edf_vals - epsilon_n, 0)\n",
    "upper_band = np.minimum(edf_vals + epsilon_n, 1)\n",
    "\n",
    "# Plot EDF with confidence bands\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.step(x_vals, edf_vals, where='post', linewidth=2, label='EDF', color='blue')\n",
    "plt.step(x_vals, lower_band, where='post', linewidth=1.5, linestyle='--', \n",
    "         label=f'{confidence_level*100}% Lower Band', color='red')\n",
    "plt.step(x_vals, upper_band, where='post', linewidth=1.5, linestyle='--', \n",
    "         label=f'{confidence_level*100}% Upper Band', color='green')\n",
    "plt.fill_between(x_vals, lower_band, upper_band, alpha=0.2, step='post', color='gray')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('F(x)')\n",
    "plt.title(f'EDF with {confidence_level*100}% Confidence Bands (DKW Inequality)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a373fa",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Estimating Density\n",
    "\n",
    "### 3.1 For Discrete Data: Empirical PMF (Probability Mass Function)\n",
    "\n",
    "**What it is:** The proportion of times each value appears in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b96384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate discrete data (e.g., Poisson)\n",
    "# CHANGE THESE PARAMETERS\n",
    "discrete_distribution = 'poisson'  # Options: 'poisson', 'binomial', 'geometric'\n",
    "discrete_sample_size = 1000\n",
    "discrete_param1 = 3  # For poisson: lambda, binomial: n, geometric: p\n",
    "discrete_param2 = 0.5  # For binomial: p (otherwise unused)\n",
    "\n",
    "# Generate discrete data\n",
    "if discrete_distribution == 'poisson':\n",
    "    discrete_data = np.random.poisson(discrete_param1, size=discrete_sample_size)\n",
    "elif discrete_distribution == 'binomial':\n",
    "    discrete_data = np.random.binomial(int(discrete_param1), discrete_param2, size=discrete_sample_size)\n",
    "elif discrete_distribution == 'geometric':\n",
    "    discrete_data = np.random.geometric(discrete_param1, size=discrete_sample_size)\n",
    "\n",
    "# Function to create Empirical PMF\n",
    "def makeEMF(data):\n",
    "    \"\"\"Create Empirical Mass Function (PMF) from discrete data\"\"\"\n",
    "    unique_vals, counts = np.unique(data, return_counts=True)\n",
    "    pmf = counts / len(data)\n",
    "    return unique_vals, pmf\n",
    "\n",
    "# Create and plot EMF\n",
    "vals, pmf = makeEMF(discrete_data)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(vals, pmf, width=0.8, alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Probability')\n",
    "plt.title(f'Empirical PMF for {discrete_distribution} distribution (n={discrete_sample_size})')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(f\"Value\\tProbability\")\n",
    "for v, p in zip(vals[:10], pmf[:10]):  # Show first 10\n",
    "    print(f\"{v}\\t{p:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287f052c",
   "metadata": {},
   "source": [
    "### 3.2 For Continuous Data: Histogram\n",
    "\n",
    "**What it is:** Divide the data range into bins and count how many observations fall in each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7152d3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate continuous data\n",
    "# CHANGE THESE PARAMETERS\n",
    "continuous_distribution = 'normal'  # Options: 'normal', 'exponential', 'uniform', 'beta'\n",
    "continuous_sample_size = 1000\n",
    "continuous_param1 = 0  # For normal: mean, exponential: lambda, uniform: low, beta: alpha\n",
    "continuous_param2 = 1  # For normal: std, uniform: high, beta: beta\n",
    "num_bins = 30  # Number of histogram bins\n",
    "\n",
    "# Generate continuous data\n",
    "if continuous_distribution == 'normal':\n",
    "    continuous_data = np.random.normal(continuous_param1, continuous_param2, size=continuous_sample_size)\n",
    "elif continuous_distribution == 'exponential':\n",
    "    continuous_data = np.random.exponential(1/continuous_param1 if continuous_param1 != 0 else 1, \n",
    "                                           size=continuous_sample_size)\n",
    "elif continuous_distribution == 'uniform':\n",
    "    continuous_data = np.random.uniform(continuous_param1, continuous_param2, size=continuous_sample_size)\n",
    "elif continuous_distribution == 'beta':\n",
    "    continuous_data = np.random.beta(continuous_param1, continuous_param2, size=continuous_sample_size)\n",
    "\n",
    "# Create histogram\n",
    "freq, bins, _ = plt.hist(continuous_data, bins=num_bins, density=True, \n",
    "                         alpha=0.7, edgecolor='black', label='Histogram')\n",
    "\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.title(f'Histogram for {continuous_distribution} distribution (n={continuous_sample_size}, bins={num_bins})')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Print bin information (first 10 bins)\n",
    "print(f\"{'Bin Range':<20}\\tDensity\")\n",
    "print(\"-\" * 40)\n",
    "for i, (f, l_edge, r_edge) in enumerate(zip(freq[:10], bins[:10], bins[1:11])):\n",
    "    print(f\"[{l_edge:.2f}, {r_edge:.2f}]\\t{f:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45b214e",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Risk Minimization: Linear Regression\n",
    "\n",
    "**Problem:** Find the best linear function $g(x) = kx + m$ that predicts $Y$ from $X$.\n",
    "\n",
    "**Method:** Minimize the average squared error (quadratic loss):\n",
    "\n",
    "$$k^*, m^* = \\text{argmin}_{k,m} \\frac{1}{n}\\sum_{i=1}^n (kX_i + m - Y_i)^2$$\n",
    "\n",
    "**In words:** Find the slope $k$ and intercept $m$ that minimize the average squared difference between predictions and actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7790e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic regression data\n",
    "# CHANGE THESE PARAMETERS\n",
    "true_slope = 2.5\n",
    "true_intercept = 10\n",
    "noise_level = 5  # Standard deviation of noise\n",
    "n_samples = 100\n",
    "x_min, x_max = 0, 10\n",
    "\n",
    "# Generate data: Y = true_slope * X + true_intercept + noise\n",
    "np.random.seed(42)  # For reproducibility\n",
    "X_reg = np.random.uniform(x_min, x_max, n_samples)\n",
    "Y_reg = true_slope * X_reg + true_intercept + np.random.normal(0, noise_level, n_samples)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(X_reg, Y_reg, alpha=0.6, s=50, label='Data points')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title(f'Generated Data (True: Y = {true_slope}X + {true_intercept} + noise)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Generated {n_samples} data points\")\n",
    "print(f\"True relationship: Y = {true_slope}X + {true_intercept} + noise(std={noise_level})\")\n",
    "print(f\"X range: [{x_min}, {x_max}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c72908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 1: Using scipy optimization\n",
    "from scipy import optimize\n",
    "\n",
    "# Define the risk (mean squared error)\n",
    "def compute_risk(params, X, Y):\n",
    "    \"\"\"Compute mean squared error for linear model Y_pred = params[0]*X + params[1]\"\"\"\n",
    "    k, m = params\n",
    "    predictions = k * X + m\n",
    "    mse = np.mean((predictions - Y) ** 2)\n",
    "    return mse\n",
    "\n",
    "# Initial guess\n",
    "initial_params = [0, 0]\n",
    "\n",
    "# Minimize the risk\n",
    "result = optimize.minimize(compute_risk, initial_params, args=(X_reg, Y_reg), method='Nelder-Mead')\n",
    "\n",
    "k_opt, m_opt = result.x\n",
    "print(\"=== Optimization Results (scipy) ===\")\n",
    "print(f\"Optimal slope (k): {k_opt:.4f}\")\n",
    "print(f\"Optimal intercept (m): {m_opt:.4f}\")\n",
    "print(f\"Final risk (MSE): {result.fun:.4f}\")\n",
    "print(f\"True values: slope={true_slope}, intercept={true_intercept}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41208bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 2: Using closed-form solution (Normal Equations)\n",
    "# For linear regression, we can solve directly: (X^T X)^-1 X^T Y\n",
    "\n",
    "# Add column of ones for intercept\n",
    "X_with_intercept = np.column_stack([X_reg, np.ones(len(X_reg))])\n",
    "\n",
    "# Closed-form solution: theta = (X^T X)^-1 X^T Y\n",
    "theta = np.linalg.inv(X_with_intercept.T @ X_with_intercept) @ X_with_intercept.T @ Y_reg\n",
    "k_closed, m_closed = theta\n",
    "\n",
    "print(\"\\n=== Closed-Form Solution ===\")\n",
    "print(f\"Optimal slope (k): {k_closed:.4f}\")\n",
    "print(f\"Optimal intercept (m): {m_closed:.4f}\")\n",
    "\n",
    "# Compute MSE for closed-form solution\n",
    "predictions_closed = k_closed * X_reg + m_closed\n",
    "mse_closed = np.mean((predictions_closed - Y_reg) ** 2)\n",
    "print(f\"Final risk (MSE): {mse_closed:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the fitted line\n",
    "x_plot = np.linspace(x_min, x_max, 100)\n",
    "y_pred_scipy = k_opt * x_plot + m_opt\n",
    "y_pred_closed = k_closed * x_plot + m_closed\n",
    "y_true = true_slope * x_plot + true_intercept\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.scatter(X_reg, Y_reg, alpha=0.6, s=50, label='Data points', color='blue')\n",
    "plt.plot(x_plot, y_pred_scipy, 'r-', linewidth=2, \n",
    "         label=f'Scipy: Y = {k_opt:.2f}X + {m_opt:.2f}')\n",
    "plt.plot(x_plot, y_pred_closed, 'g--', linewidth=2, \n",
    "         label=f'Closed-form: Y = {k_closed:.2f}X + {m_closed:.2f}')\n",
    "plt.plot(x_plot, y_true, 'k:', linewidth=2, alpha=0.5,\n",
    "         label=f'True: Y = {true_slope}X + {true_intercept}')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Linear Regression: Risk Minimization')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5ef64c",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Real Data Example: House Prices\n",
    "\n",
    "Let's apply linear regression to real house price data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a06ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration, let's create synthetic house price data\n",
    "# In practice, you would load from CSV: pd.read_csv('portland.csv')\n",
    "\n",
    "# CHANGE THESE TO USE YOUR OWN DATA\n",
    "# If you have a CSV file, uncomment and modify:\n",
    "# import pandas as pd\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "# X_houses = df['size'].values  # or df.iloc[:, 0]\n",
    "# Y_prices = df['price'].values  # or df.iloc[:, 2]\n",
    "\n",
    "# For now, generate synthetic house data\n",
    "np.random.seed(123)\n",
    "n_houses = 50\n",
    "house_sizes = np.random.uniform(1000, 4000, n_houses)  # Square feet\n",
    "# Price roughly $100 per sq ft + base of $50k + noise\n",
    "house_prices = 100 * house_sizes + 50000 + np.random.normal(0, 20000, n_houses)\n",
    "\n",
    "X_houses = house_sizes\n",
    "Y_prices = house_prices\n",
    "\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(X_houses, Y_prices, alpha=0.6, s=80, edgecolors='black')\n",
    "plt.xlabel('House Size (sq ft)')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.title('House Prices vs Size')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Number of houses: {len(X_houses)}\")\n",
    "print(f\"Size range: {X_houses.min():.0f} - {X_houses.max():.0f} sq ft\")\n",
    "print(f\"Price range: ${Y_prices.min():.0f} - ${Y_prices.max():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1596bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression model\n",
    "def fit_linear_regression(X, Y):\n",
    "    \"\"\"Fit linear regression using closed-form solution\"\"\"\n",
    "    # Add intercept term\n",
    "    X_design = np.column_stack([X, np.ones(len(X))])\n",
    "    # Solve: theta = (X^T X)^-1 X^T Y\n",
    "    theta = np.linalg.inv(X_design.T @ X_design) @ X_design.T @ Y\n",
    "    slope, intercept = theta\n",
    "    \n",
    "    # Calculate statistics\n",
    "    predictions = slope * X + intercept\n",
    "    residuals = Y - predictions\n",
    "    mse = np.mean(residuals ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # R-squared\n",
    "    ss_total = np.sum((Y - np.mean(Y)) ** 2)\n",
    "    ss_residual = np.sum(residuals ** 2)\n",
    "    r_squared = 1 - (ss_residual / ss_total)\n",
    "    \n",
    "    return {\n",
    "        'slope': slope,\n",
    "        'intercept': intercept,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'r_squared': r_squared,\n",
    "        'predictions': predictions\n",
    "    }\n",
    "\n",
    "# Fit the model\n",
    "results = fit_linear_regression(X_houses, Y_prices)\n",
    "\n",
    "print(\"=== Linear Regression Results ===\")\n",
    "print(f\"Equation: Price = {results['slope']:.2f} × Size + {results['intercept']:.2f}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  - Price increases by ${results['slope']:.2f} per square foot\")\n",
    "print(f\"  - Base price (at 0 sq ft): ${results['intercept']:.2f}\")\n",
    "print(f\"\\nModel Quality:\")\n",
    "print(f\"  - RMSE: ${results['rmse']:.2f} (average prediction error)\")\n",
    "print(f\"  - R²: {results['r_squared']:.4f} (proportion of variance explained)\")\n",
    "\n",
    "# Make a prediction\n",
    "# CHANGE THIS to predict for different house sizes\n",
    "new_house_size = 2500\n",
    "predicted_price = results['slope'] * new_house_size + results['intercept']\n",
    "print(f\"\\n=== Prediction ===\")\n",
    "print(f\"A {new_house_size} sq ft house is predicted to cost: ${predicted_price:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d1a8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the regression line\n",
    "x_range = np.linspace(X_houses.min(), X_houses.max(), 100)\n",
    "y_pred_line = results['slope'] * x_range + results['intercept']\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Main plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_houses, Y_prices, alpha=0.6, s=80, edgecolors='black', label='Actual prices')\n",
    "plt.plot(x_range, y_pred_line, 'r-', linewidth=2, \n",
    "         label=f\"Y = {results['slope']:.1f}X + {results['intercept']:.0f}\")\n",
    "plt.xlabel('House Size (sq ft)', fontsize=12)\n",
    "plt.ylabel('Price ($)', fontsize=12)\n",
    "plt.title(f\"Linear Regression (R² = {results['r_squared']:.3f})\", fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Residual plot\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals = Y_prices - results['predictions']\n",
    "plt.scatter(results['predictions'], residuals, alpha=0.6, s=80, edgecolors='black')\n",
    "plt.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Predicted Price ($)', fontsize=12)\n",
    "plt.ylabel('Residuals ($)', fontsize=12)\n",
    "plt.title('Residual Plot', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba2941a",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary of Key Functions\n",
    "\n",
    "### Quick Reference\n",
    "\n",
    "```python\n",
    "# 1. Empirical Distribution Function\n",
    "x_vals, edf_vals = makeEDF(data)\n",
    "plotEDF(x_vals, edf_vals)\n",
    "\n",
    "# 2. DKW Confidence Bands\n",
    "epsilon_n = np.sqrt((1/(2*n)) * np.log(2/alpha))\n",
    "lower_band = np.maximum(edf_vals - epsilon_n, 0)\n",
    "upper_band = np.minimum(edf_vals + epsilon_n, 1)\n",
    "\n",
    "# 3. Empirical PMF (discrete data)\n",
    "vals, pmf = makeEMF(discrete_data)\n",
    "\n",
    "# 4. Histogram (continuous data)\n",
    "plt.hist(continuous_data, bins=30, density=True)\n",
    "\n",
    "# 5. Linear Regression\n",
    "results = fit_linear_regression(X, Y)\n",
    "predicted_y = results['slope'] * new_x + results['intercept']\n",
    "```\n",
    "\n",
    "### When to Use Each Method\n",
    "\n",
    "- **EDF**: When you want to estimate the cumulative distribution from data\n",
    "- **DKW Bands**: When you need confidence intervals for your distribution estimate\n",
    "- **PMF**: For discrete random variables (counts, categories)\n",
    "- **Histogram**: For continuous random variables (measurements)\n",
    "- **Linear Regression**: When you want to predict one variable from another with a linear relationship"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
