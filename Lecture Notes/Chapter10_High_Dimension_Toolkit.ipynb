{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5bf7863",
   "metadata": {},
   "source": [
    "# Lecture Notes Toolkit - High-Dimensional Geometry (Chapter 10)\n",
    "\n",
    "## üåå The Strange World of High Dimensions\n",
    "\n",
    "Welcome to one of the most **counter-intuitive** topics in mathematics and data science: **high-dimensional geometry**!\n",
    "\n",
    "### ü§î Why Should You Care?\n",
    "\n",
    "**Modern data is high-dimensional:**\n",
    "- **Images:** A 100√ó100 grayscale image = 10,000 dimensions\n",
    "- **Text:** Document vectors can have 10,000+ dimensions (one per word)\n",
    "- **Genetics:** DNA sequencing produces thousands of features\n",
    "- **Machine Learning:** Neural networks operate in spaces with millions of parameters\n",
    "\n",
    "**The challenge:** Our intuition from 2D and 3D **completely breaks down** in high dimensions!\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ What This Notebook Covers\n",
    "\n",
    "This toolkit provides complete implementations of Chapter 10 concepts (Lecture Notes pp. 152‚Äì163), with a focus on **understanding why high dimensions are weird**.\n",
    "\n",
    "### üìö Content Overview\n",
    "\n",
    "**Part 1: Foundations (Sections 1-2)**\n",
    "- ‚úÖ **Geometric Definitions** (Def 10.1)\n",
    "  - Balls and spheres in d dimensions\n",
    "  - Distance and volume measures\n",
    "\n",
    "- ‚úÖ **Gaussian Models** (Models 10.3‚Äì10.4)\n",
    "  - Spherical Gaussian: standard normal in d dimensions\n",
    "  - Normalized Gaussian: scaled version for cleaner formulas\n",
    "\n",
    "---\n",
    "\n",
    "**Part 2: The Curse of Dimensionality (Sections 3-4)**\n",
    "- ‚úÖ **Vanishing Volume** (Lemma 10.5)\n",
    "  - Unit ball volume shrinks exponentially with dimension\n",
    "  - Most of the space is \"outside\" the unit ball!\n",
    "\n",
    "- ‚úÖ **Boundary Concentration** (Lemma 10.7)\n",
    "  - In high dimensions, most volume is near the boundary\n",
    "  - Interior becomes negligible\n",
    "\n",
    "- ‚úÖ **Exact Formulas** (Theorem 10.8)\n",
    "  - Precise volume/surface area using Gamma functions\n",
    "  - Numerical computation for large dimensions\n",
    "\n",
    "---\n",
    "\n",
    "**Part 3: Sampling in High Dimensions (Sections 5-6)**\n",
    "- ‚úÖ **Uniform Sampling on Spheres** (Lemma 10.16)\n",
    "  - Why normalizing Gaussians works\n",
    "  - Proof and implementation\n",
    "\n",
    "- ‚úÖ **Uniform Sampling in Balls** (Theorem 10.18)\n",
    "  - Radial rescaling method\n",
    "  - Why naive rejection fails\n",
    "\n",
    "- ‚úÖ **Projection Problems** (Section 10.4.1)\n",
    "  - Why projecting from squares doesn't work\n",
    "  - Visualization of the bias\n",
    "\n",
    "---\n",
    "\n",
    "**Part 4: Concentration Phenomena (Section 7)**\n",
    "- ‚úÖ **Annulus Theorem** (Theorem 10.20)\n",
    "  - Norms concentrate in thin shells\n",
    "  - Sub-Gaussian tail bounds\n",
    "  - Empirical verification\n",
    "\n",
    "---\n",
    "\n",
    "## üéì Key Insights You'll Gain\n",
    "\n",
    "1. **\"Empty space\" paradox:** In d=100, the unit ball contains virtually no volume compared to the cube [-1,1]^100\n",
    "\n",
    "2. **\"Surface\" paradox:** Almost all volume of a ball is near its surface when d is large\n",
    "\n",
    "3. **\"Sampling\" paradox:** Rejection sampling from cubes becomes impossible (acceptance rate ‚âà 0)\n",
    "\n",
    "4. **\"Concentration\" paradox:** Random vectors have almost deterministic lengths (thin shell phenomenon)\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ How to Use This Notebook\n",
    "\n",
    "1. **Read explanations carefully** - Each concept has intuition + math + code\n",
    "2. **Run all cells** - See the phenomena for yourself\n",
    "3. **Experiment with parameters** - Try different dimensions (d), sample sizes (n)\n",
    "4. **Reuse functions** - All functions are modular and documented\n",
    "5. **Build intuition** - Visualizations show what formulas mean\n",
    "\n",
    "**‚ö†Ô∏è Warning:** Your 3D intuition will be wrong. That's okay‚Äîeveryone's is! This notebook will help you build new intuition.\n",
    "\n",
    "Let's explore the fascinating geometry of high dimensions! üé¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a9f538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, Tuple, Optional, Dict\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c43ef54",
   "metadata": {},
   "source": [
    "## 1) Geometric Foundations: Balls and Spheres (Definition 10.1)\n",
    "\n",
    "### üéØ What Are Balls and Spheres?\n",
    "\n",
    "In d-dimensional space ‚Ñù^d, we generalize familiar 2D and 3D concepts:\n",
    "\n",
    "**Ball of radius r centered at x:**\n",
    "$$B_r(x) = \\{y \\in \\mathbb{R}^d : \\|y - x\\| < r\\}$$\n",
    "\n",
    "This is the **interior** (all points strictly closer than distance r from x).\n",
    "\n",
    "**Sphere of radius r centered at x:**\n",
    "$$S_r(x) = \\{y \\in \\mathbb{R}^d : \\|y - x\\| = r\\}$$\n",
    "\n",
    "This is the **boundary** (all points exactly at distance r from x).\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Examples Across Dimensions\n",
    "\n",
    "| Dimension | Ball $B_1(0)$ | Sphere $S_1(0)$ |\n",
    "|-----------|-------------|---------------|\n",
    "| $d=1$ | Open interval $(-1, 1)$ | Two points $\\{-1, 1\\}$ |\n",
    "| $d=2$ | Open disk | Circle |\n",
    "| $d=3$ | Open ball | Sphere (hollow surface) |\n",
    "| $d=4+$ | **No direct visualization!** | **No direct visualization!** |\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Key Notation\n",
    "\n",
    "Throughout this notebook:\n",
    "- $B_1$ = unit ball (radius 1, centered at origin)\n",
    "- $S_1$ = unit sphere (radius 1, centered at origin)\n",
    "- $\\|\\cdot\\|$ = Euclidean norm (L2 distance): $\\|x\\| = \\sqrt{x_1^2 + x_2^2 + \\cdots + x_d^2}$\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Intuition: Interior vs. Boundary\n",
    "\n",
    "In low dimensions:\n",
    "- **$d=2$:** A circle has \"length\" (1D), the disk has \"area\" (2D)\n",
    "- **$d=3$:** A sphere has \"surface area\" (2D), the ball has \"volume\" (3D)\n",
    "\n",
    "In general:\n",
    "- **Sphere $S_1$:** A $(d-1)$-dimensional object\n",
    "- **Ball $B_1$:** A $d$-dimensional object\n",
    "\n",
    "**The weird part:** In high dimensions, the sphere $S_1$ actually captures \"most of the action\"‚Äîwe'll see why!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5bbca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_unit_ball(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Boolean mask: which rows of X are inside the unit ball.\"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    return np.linalg.norm(X, axis=1) < 1.0\n",
    "\n",
    "def in_ball(X: np.ndarray, r: float = 1.0) -> np.ndarray:\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    return np.linalg.norm(X, axis=1) < float(r)\n",
    "\n",
    "def on_unit_sphere(X: np.ndarray, tol: float = 1e-8) -> np.ndarray:\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    return np.abs(np.linalg.norm(X, axis=1) - 1.0) <= tol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa8f4a8",
   "metadata": {},
   "source": [
    "## 2) Gaussian Models in High Dimensions (Models 10.3‚Äì10.4)\n",
    "\n",
    "### üéØ Why Gaussians?\n",
    "\n",
    "Gaussian distributions are **fundamental** to high-dimensional geometry because:\n",
    "1. **Rotation invariance:** Distribution looks the same from all directions\n",
    "2. **Independence:** Coordinates are independent ‚Üí easy to analyze\n",
    "3. **Central Limit Theorem:** Sums of random variables ‚Üí Gaussian\n",
    "4. **Mathematical tractability:** Nice formulas, concentration properties\n",
    "\n",
    "---\n",
    "\n",
    "### üìê Model 10.3: Spherical Gaussian\n",
    "\n",
    "A **spherical Gaussian** in ‚Ñù^d has **independent standard normal coordinates**:\n",
    "$$Z = (Z_1, Z_2, \\ldots, Z_d) \\quad \\text{where each } Z_i \\sim N(0,1) \\text{ independently}$$\n",
    "\n",
    "**Density function:**\n",
    "$$f(x) = (2\\pi)^{-d/2} \\exp\\left(-\\frac{\\|x\\|^2}{2}\\right)$$\n",
    "\n",
    "**Key properties:**\n",
    "- **Mean:** $\\mathbb{E}[Z] = 0$ (center at origin)\n",
    "- **Covariance:** $\\text{Cov}(Z) = I_d$ (identity matrix, uncorrelated coordinates)\n",
    "- **Expected squared norm:** $\\mathbb{E}[\\|Z\\|^2] = d$ (sum of $d$ unit variances)\n",
    "- **Typical norm:** $\\|Z\\| \\approx \\sqrt{d}$ (by concentration)\n",
    "\n",
    "**Physical interpretation:** Like a \"cloud\" of points centered at origin, spreading out in all directions equally.\n",
    "\n",
    "---\n",
    "\n",
    "### üìê Model 10.4: Normalized Gaussian\n",
    "\n",
    "A **normalized Gaussian** rescales the spherical Gaussian:\n",
    "$$Y = \\frac{1}{\\sqrt{2\\pi}} Z$$\n",
    "\n",
    "**Density function:**\n",
    "$$f(y) = (2\\pi)^{d/2} \\exp(-\\pi \\|y\\|^2)$$\n",
    "\n",
    "Notice the cleaner exponent (no factor of 2 in the argument)!\n",
    "\n",
    "**Key properties:**\n",
    "- **Expected squared norm:** $\\mathbb{E}[\\|Y\\|^2] = \\frac{d}{2\\pi}$\n",
    "- **Typical norm:** $\\|Y\\| \\approx \\sqrt{\\frac{d}{2\\pi}}$\n",
    "\n",
    "**Why use this?** The notes use the normalized version in Lemma 10.5 because it gives cleaner expressions for volume arguments.\n",
    "\n",
    "---\n",
    "\n",
    "### üîó Relationship\n",
    "\n",
    "```\n",
    "Spherical Gaussian Z ~ N(0, I_d)\n",
    "        ‚Üì scale by 1/‚àö(2œÄ)\n",
    "Normalized Gaussian Y = Z/‚àö(2œÄ)\n",
    "```\n",
    "\n",
    "Both capture the same high-dimensional phenomena, just with different scaling constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db7f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_spherical_gaussian(d: int, n: int, rng: Optional[np.random.Generator] = None) -> np.ndarray:\n",
    "    \"\"\"Z ~ N(0,I_d). Returns array shape (n,d).\"\"\"\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    return rng.normal(loc=0.0, scale=1.0, size=(n, d))\n",
    "\n",
    "def sample_normalized_gaussian(d: int, n: int, rng: Optional[np.random.Generator] = None) -> np.ndarray:\n",
    "    \"\"\"Y = (2œÄ)^(-1/2) Z where Z~N(0,I).\"\"\"\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    Z = sample_spherical_gaussian(d, n, rng=rng)\n",
    "    return Z / math.sqrt(2*math.pi)\n",
    "\n",
    "def expected_norm_sq_spherical(d: int) -> float:\n",
    "    return float(d)\n",
    "\n",
    "def expected_norm_sq_normalized(d: int) -> float:\n",
    "    return float(d/(2*math.pi))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6434d40e",
   "metadata": {},
   "source": [
    "## 3) The Vanishing Volume Phenomenon (Lemma 10.5)\n",
    "\n",
    "### ü§Ø The Most Counter-Intuitive Result\n",
    "\n",
    "**Lemma 10.5:** For $d > 4\\pi \\approx 12.57$, the unit ball volume $|B_1|$ **shrinks toward zero** as $d$ increases!\n",
    "\n",
    "### üìä How Small?\n",
    "\n",
    "Some actual values:\n",
    "- $d=5$: $|B_1| \\approx 5.26$\n",
    "- $d=10$: $|B_1| \\approx 2.55$\n",
    "- $d=20$: $|B_1| \\approx 0.026$ (smaller than in $d=2$!)\n",
    "- $d=50$: $|B_1| \\approx 10^{-18}$ (essentially zero)\n",
    "- $d=100$: $|B_1| \\approx 10^{-41}$ (unimaginably tiny)\n",
    "\n",
    "**Compare to the d-dimensional cube $[-1,1]^d$:**\n",
    "- Cube volume = $2^d$ (grows exponentially!)\n",
    "- Ball volume ‚Üí 0 (shrinks exponentially!)\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Why Does This Happen?\n",
    "\n",
    "**Intuitive explanation:** The unit ball is defined by $\\|x\\| < 1$, meaning:\n",
    "$$x_1^2 + x_2^2 + \\cdots + x_d^2 < 1$$\n",
    "\n",
    "In high dimensions:\n",
    "- Most random points have many coordinates\n",
    "- Squared terms $x_i^2$ add up quickly\n",
    "- Very few combinations satisfy the constraint!\n",
    "\n",
    "**Analogy:** Imagine trying to fit inside a multidimensional \"budget constraint\"‚Äîas you add more dimensions, it becomes harder and harder to satisfy.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Seeing It Through Gaussians\n",
    "\n",
    "For a **normalized Gaussian** $Y$:\n",
    "- Typical norm: $\\|Y\\| \\approx \\sqrt{d/(2\\pi)}$\n",
    "- Unit ball condition: $\\|Y\\| < 1$\n",
    "- This happens only when $\\sqrt{d/(2\\pi)} < 1$, i.e., $d < 2\\pi \\approx 6.28$\n",
    "\n",
    "For $d > 6.28$:\n",
    "- The Gaussian \"cloud\" is centered **outside** the unit ball!\n",
    "- $\\mathbb{P}(Y \\in B_1)$ becomes exponentially small\n",
    "\n",
    "**Conclusion:** The unit ball captures a vanishingly small fraction of probability mass.\n",
    "\n",
    "---\n",
    "\n",
    "### üìà Simulation Strategy\n",
    "\n",
    "Below, we verify this by:\n",
    "1. Sampling from the normalized Gaussian\n",
    "2. Checking what fraction lands in $B_1$\n",
    "3. Measuring concentration of $\\|Y\\|$ around $\\sqrt{d/(2\\pi)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02532dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_in_unit_ball_under_distribution(\n",
    "    sampler: Callable[[int], np.ndarray],\n",
    "    n: int = 200_000,\n",
    "    seed: int = 0,\n",
    ") -> float:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X = sampler(n) if sampler.__code__.co_argcount == 1 else sampler(n, rng)  # flexible\n",
    "    return float(np.mean(in_unit_ball(X)))\n",
    "\n",
    "def simulate_norm_concentration(\n",
    "    sampler: Callable[[int], np.ndarray],\n",
    "    d: int,\n",
    "    n: int = 100_000,\n",
    "    seed: int = 0,\n",
    ") -> Dict[str, float]:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X = sampler(d, n, rng=rng)  # expect signature (d,n,rng)\n",
    "    norms = np.linalg.norm(X, axis=1)\n",
    "    return {\n",
    "        \"mean_norm\": float(np.mean(norms)),\n",
    "        \"std_norm\": float(np.std(norms, ddof=0)),\n",
    "        \"q05\": float(np.quantile(norms, 0.05)),\n",
    "        \"q95\": float(np.quantile(norms, 0.95)),\n",
    "    }\n",
    "\n",
    "# Quick demo: probability normalized Gaussian lies in B1 for various d\n",
    "def demo_prob_gaussian_in_ball(ds=(2,3,5,10,20), n=200_000, seed=0):\n",
    "    out = []\n",
    "    for d in ds:\n",
    "        rng = np.random.default_rng(seed)\n",
    "        Y = sample_normalized_gaussian(d, n, rng=rng)\n",
    "        out.append((d, float(np.mean(in_unit_ball(Y)))))\n",
    "    return out\n",
    "\n",
    "demo_prob_gaussian_in_ball(ds=(2,3,5,10,15,20), n=100_000, seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fcc2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: P(normalized Gaussian in unit ball) vs dimension\n",
    "vals = demo_prob_gaussian_in_ball(ds=range(1, 21), n=60_000, seed=1)\n",
    "ds = np.array([v[0] for v in vals])\n",
    "ps = np.array([v[1] for v in vals])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ds, ps, marker='o')\n",
    "plt.title(\"P(Y in unit ball) for normalized Gaussian Y (simulation)\")\n",
    "plt.xlabel(\"dimension d\")\n",
    "plt.ylabel(\"probability\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48ccb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: concentration of ||Y|| around sqrt(d/(2œÄ))\n",
    "ds = np.arange(1, 21)\n",
    "mean_norms = []\n",
    "expected = []\n",
    "for d in ds:\n",
    "    stats = simulate_norm_concentration(sample_normalized_gaussian, d=d, n=50_000, seed=0)\n",
    "    mean_norms.append(stats[\"mean_norm\"])\n",
    "    expected.append(math.sqrt(d/(2*math.pi)))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ds, mean_norms, marker='o', label=\"empirical mean ||Y||\")\n",
    "plt.plot(ds, expected, marker='x', label=\"sqrt(d/(2œÄ))\")\n",
    "plt.title(\"Normalized Gaussian norm concentrates near sqrt(d/(2œÄ))\")\n",
    "plt.xlabel(\"dimension d\")\n",
    "plt.ylabel(\"value\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6032d499",
   "metadata": {},
   "source": [
    "## 4) Scaling and the Boundary Effect (Lemma 10.7)\n",
    "\n",
    "### üéØ The Boundary Concentration Principle\n",
    "\n",
    "**Lemma 10.7:** If you shrink any set $E$ by a factor $(1-\\varepsilon)$, its volume scales by $(1-\\varepsilon)^d$:\n",
    "$$|(1-\\varepsilon)E| = (1-\\varepsilon)^d |E|$$\n",
    "\n",
    "---\n",
    "\n",
    "### üìê What Does This Mean?\n",
    "\n",
    "Consider the unit ball $B_1$. Define:\n",
    "- **Outer ball:** $B_1$ (radius 1)\n",
    "- **Inner ball:** $(1-\\varepsilon)B_1$ (radius $1-\\varepsilon$)\n",
    "- **Annulus (shell):** The region between them\n",
    "\n",
    "**Volume of inner ball:**\n",
    "$$|(1-\\varepsilon)B_1| = (1-\\varepsilon)^d |B_1|$$\n",
    "\n",
    "**Volume of annulus:**\n",
    "$$|B_1| - |(1-\\varepsilon)B_1| = |B_1| \\left[1 - (1-\\varepsilon)^d\\right]$$\n",
    "\n",
    "---\n",
    "\n",
    "### üí• The Shocking Consequence\n",
    "\n",
    "Let's use $\\varepsilon = 0.1$ (10% shrinkage) and see what fraction of volume is in the **outer 10% shell**:\n",
    "\n",
    "| Dimension | $(1-0.1)^d$ | Volume in shell | Where's the volume? |\n",
    "|-----------|-----------|-----------------|---------------------|\n",
    "| $d=2$ | 0.81 | 19% | Mostly interior |\n",
    "| $d=5$ | 0.59 | 41% | Balanced |\n",
    "| $d=10$ | 0.35 | 65% | **Mostly shell!** |\n",
    "| $d=20$ | 0.12 | 88% | **Almost all shell!** |\n",
    "| $d=50$ | 0.005 | 99.5% | **Essentially all shell!** |\n",
    "| $d=100$ | 0.00003 | 99.997% | **Everything is surface!** |\n",
    "\n",
    "---\n",
    "\n",
    "### üçä The Orange Peel Analogy\n",
    "\n",
    "Imagine a high-dimensional \"orange\":\n",
    "- In $d=3$: The peel (outer 10%) is a thin layer\n",
    "- In $d=100$: The peel (outer 10%) contains 99.997% of the volume!\n",
    "- The \"interior\" becomes negligible\n",
    "\n",
    "**Consequence:** In high dimensions, **almost all points are near the boundary**. The interior is essentially empty!\n",
    "\n",
    "---\n",
    "\n",
    "### üî¢ Mathematical Insight\n",
    "\n",
    "For small $\\varepsilon$, we can approximate:\n",
    "$$(1-\\varepsilon)^d \\approx e^{-\\varepsilon d}$$\n",
    "\n",
    "This decays **exponentially fast** in $d$. Even a small shrinkage (small $\\varepsilon$) leads to massive volume loss when $d$ is large.\n",
    "\n",
    "**Key takeaway:** High-dimensional objects are \"almost all surface, no interior.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d5dcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_volume_ratio(d: int, eps: float) -> float:\n",
    "    \"\"\"|(1-eps)E|/|E| = (1-eps)^d.\"\"\"\n",
    "    if not (0 < eps <= 1):\n",
    "        raise ValueError(\"eps in (0,1].\")\n",
    "    return float((1.0 - eps) ** d)\n",
    "\n",
    "# Compare (1-0.1)^d vs exp(-0.1 d) like the note snippet\n",
    "ds = np.arange(1, 101)\n",
    "eps = 0.1\n",
    "plt.figure()\n",
    "plt.plot(ds, (1-eps)**ds, label=\"(1-Œµ)^d\")\n",
    "plt.plot(ds, np.exp(-eps*ds), label=\"exp(-Œµ d)\")\n",
    "plt.title(\"Scaling decay: (1-Œµ)^d -> 0 as d grows\")\n",
    "plt.xlabel(\"d\")\n",
    "plt.ylabel(\"ratio\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e7f6c3",
   "metadata": {},
   "source": [
    "## 5) Exact Volume and Surface Area Formulas (Theorem 10.8)\n",
    "\n",
    "### üéØ The Precise Mathematics\n",
    "\n",
    "The notes derive **exact formulas** for the volume of the unit ball and surface area of the unit sphere using the **Gamma function**.\n",
    "\n",
    "---\n",
    "\n",
    "### üìê The Formulas\n",
    "\n",
    "**Volume of the unit ball:**\n",
    "$$|B_1| = \\frac{\\pi^{d/2}}{\\Gamma(d/2 + 1)}$$\n",
    "\n",
    "**Equivalent form** (using $\\Gamma(z+1) = z\\cdot\\Gamma(z)$):\n",
    "$$|B_1| = \\frac{2\\pi^{d/2}}{d\\,\\Gamma(d/2)}$$\n",
    "\n",
    "**Surface area of the unit sphere:**\n",
    "$$|S_1| = d \\cdot |B_1| = \\frac{2\\pi^{d/2}}{\\Gamma(d/2)}$$\n",
    "\n",
    "**Relationship:** The sphere's \"thickness\" is infinitesimal, but its surface area relates to the ball's volume through a factor of $d$.\n",
    "\n",
    "---\n",
    "\n",
    "### üî¨ What is the Gamma Function?\n",
    "\n",
    "The **Gamma function** generalizes factorials to non-integers:\n",
    "$$\\Gamma(n) = (n-1)! \\quad \\text{for positive integers } n$$\n",
    "\n",
    "**Examples:**\n",
    "- $\\Gamma(1) = 0! = 1$\n",
    "- $\\Gamma(2) = 1! = 1$\n",
    "- $\\Gamma(3) = 2! = 2$\n",
    "- $\\Gamma(4) = 3! = 6$\n",
    "- $\\Gamma(1/2) = \\sqrt{\\pi}$ (special value!)\n",
    "\n",
    "**Key identity:** $\\Gamma(z+1) = z\\cdot\\Gamma(z)$\n",
    "\n",
    "**For large $z$:** $\\Gamma(z)$ grows faster than exponentially (roughly like $z^z e^{-z}$ by Stirling's approximation)\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Verifying in Low Dimensions\n",
    "\n",
    "Let's check our formula matches known results:\n",
    "\n",
    "| Dimension | Name | Formula | $|B_1|$ value |\n",
    "|-----------|------|---------|-----------|\n",
    "| $d=1$ | Line segment | $2r = 2$ | 2.000 |\n",
    "| $d=2$ | Disk | $\\pi r^2 = \\pi$ | 3.142 |\n",
    "| $d=3$ | Ball | $\\frac{4}{3}\\pi r^3 = \\frac{4\\pi}{3}$ | 4.189 |\n",
    "| $d=4$ | Hypersphere | $\\frac{\\pi^2 r^4}{2} = \\frac{\\pi^2}{2}$ | 4.935 |\n",
    "\n",
    "**Peak at $d\\approx 5$:** The volume reaches its maximum around $d=5$, then starts decreasing!\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö†Ô∏è Numerical Stability\n",
    "\n",
    "For large $d$, the formula involves large values:\n",
    "- $\\pi^{d/2}$ grows exponentially\n",
    "- $\\Gamma(d/2)$ grows even faster\n",
    "- Their ratio ‚Üí 0\n",
    "\n",
    "**Solution:** Work in **log space**:\n",
    "$$\\log|B_1| = \\frac{d}{2}\\log(\\pi) - \\log\\Gamma\\left(\\frac{d}{2} + 1\\right)$$\n",
    "\n",
    "Use `math.lgamma` (log-gamma function) to avoid overflow/underflow.\n",
    "\n",
    "**Implementation strategy:**\n",
    "1. Compute $\\log(|B_1|)$ for any $d$\n",
    "2. Exponentiate only when needed for display\n",
    "3. For $d > 200$, just work with log values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feed4e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_volume_unit_ball(d: int) -> float:\n",
    "    \"\"\"log(|B1|) in R^d using log-gamma for stability.\"\"\"\n",
    "    d = int(d)\n",
    "    return (d/2)*math.log(math.pi) - math.lgamma(d/2 + 1)\n",
    "\n",
    "def volume_unit_ball(d: int) -> float:\n",
    "    \"\"\"|B1| in R^d.\"\"\"\n",
    "    return float(math.exp(log_volume_unit_ball(d)))\n",
    "\n",
    "def log_area_unit_sphere(d: int) -> float:\n",
    "    \"\"\"log(|S1|) in R^d.\"\"\"\n",
    "    d = int(d)\n",
    "    return math.log(2.0) + (d/2)*math.log(math.pi) - math.lgamma(d/2)\n",
    "\n",
    "def area_unit_sphere(d: int) -> float:\n",
    "    return float(math.exp(log_area_unit_sphere(d)))\n",
    "\n",
    "# Quick sanity checks in low dimensions\n",
    "for d in [1,2,3,4,5,10]:\n",
    "    print(d, \"B1 vol =\", volume_unit_ball(d), \" | S1 area =\", area_unit_sphere(d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb360b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot volume of unit ball vs dimension (exact formula)\n",
    "ds = np.arange(1, 51)\n",
    "vols = np.array([volume_unit_ball(int(d)) for d in ds])\n",
    "plt.figure()\n",
    "plt.plot(ds, vols, marker='o')\n",
    "plt.title(\"Exact volume of the unit ball |B1| vs dimension\")\n",
    "plt.xlabel(\"dimension d\")\n",
    "plt.ylabel(\"|B1|\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023273df",
   "metadata": {},
   "source": [
    "## 6) Uniform Sampling: Spheres and Balls\n",
    "\n",
    "### üéØ The Challenge\n",
    "\n",
    "How do we generate **uniformly random** points:\n",
    "1. **On the unit sphere** $S_1$ (surface)?\n",
    "2. **Inside the unit ball** $B_1$ (interior)?\n",
    "\n",
    "Naive approaches fail! We need mathematically correct methods.\n",
    "\n",
    "---\n",
    "\n",
    "### üåê Method 1: Uniform on the Sphere (Lemma 10.16)\n",
    "\n",
    "**Key Theorem:** If $Z \\sim N(0, I_d)$ (spherical Gaussian), then:\n",
    "$$\\theta = \\frac{Z}{\\|Z\\|} \\sim \\text{Uniform}(S_1)$$\n",
    "\n",
    "**Why this works:**\n",
    "1. **Rotation invariance:** Gaussian distribution looks the same from all directions\n",
    "2. **Normalization:** Dividing by $\\|Z\\|$ projects onto the unit sphere\n",
    "3. **Symmetry:** Every direction is equally likely!\n",
    "\n",
    "**Algorithm:**\n",
    "```python\n",
    "1. Sample Z ~ N(0, I_d)  (d independent standard normals)\n",
    "2. Compute norm: r = ‚à•Z‚à•\n",
    "3. Normalize: Œ∏ = Z / r\n",
    "4. Return Œ∏ (uniformly distributed on S_1)\n",
    "```\n",
    "\n",
    "**Probability of $\\|Z\\| = 0$:** Zero (measure zero event, safe to ignore in floating point)\n",
    "\n",
    "---\n",
    "\n",
    "### üé± Method 2: Uniform in the Ball (Theorem 10.18)\n",
    "\n",
    "**Key Theorem:** If $\\theta \\sim \\text{Uniform}(S_1)$ and $U \\sim \\text{Uniform}([0,1])$ independent, then:\n",
    "$$X = U^{1/d} \\cdot \\theta \\sim \\text{Uniform}(B_1)$$\n",
    "\n",
    "**Why this works:**\n",
    "\n",
    "**Naive (WRONG) approach:** Just use $\\theta \\cdot U$\n",
    "- Problem: This concentrates points near the center!\n",
    "- Reason: In high dimensions, \"most volume is near the surface\"\n",
    "\n",
    "**Correct approach:** Use $\\theta \\cdot U^{1/d}$\n",
    "- The exponent $1/d$ accounts for the volume scaling\n",
    "- More points pushed toward the boundary (where the volume is!)\n",
    "\n",
    "**Intuition via volume:**\n",
    "- Volume of ball of radius $r$: $\\propto r^d$\n",
    "- To get uniform distribution, need CDF proportional to $r^d$\n",
    "- Taking $U^{1/d}$ gives the right radial distribution\n",
    "\n",
    "**Algorithm:**\n",
    "```python\n",
    "1. Sample Œ∏ ~ Uniform(S_1)  (using Method 1)\n",
    "2. Sample U ~ Uniform([0,1])\n",
    "3. Compute radius: r = U^(1/d)\n",
    "4. Return X = r ¬∑ Œ∏ (uniformly distributed in B_1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Visualizing the Radial Distribution\n",
    "\n",
    "For uniform points in $B_1$:\n",
    "- **$d=2$:** Radius $R$ has PDF $f(r) = 2r$ (more points near edge)\n",
    "- **$d=3$:** Radius $R$ has PDF $f(r) = 3r^2$ (even more near edge)\n",
    "- **$d=100$:** Almost ALL points have radius $\\approx 1$ (thin shell!)\n",
    "\n",
    "**Expected radius:** $\\mathbb{E}[R] = \\frac{d}{d+1} \\to 1$ as $d \\to \\infty$\n",
    "\n",
    "This confirms: in high dimensions, uniform random points in the ball are **almost all near the surface**!\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùå What NOT to Do\n",
    "\n",
    "**DON'T:**\n",
    "1. Sample from cube and project ‚Üí biased!\n",
    "2. Sample coordinates uniformly ‚Üí not uniform in ball!\n",
    "3. Use naive radial scaling $r = U$ ‚Üí concentrates at center!\n",
    "\n",
    "**DO:**\n",
    "- Use the Gaussian normalization method for spheres\n",
    "- Use the radial rescaling $r = U^{1/d}$ for balls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876fe352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_uniform_sphere(d: int, n: int, rng: Optional[np.random.Generator] = None) -> np.ndarray:\n",
    "    \"\"\"Uniform on S1 in R^d via Gaussian normalization.\"\"\"\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    Z = rng.normal(size=(n, d))\n",
    "    norms = np.linalg.norm(Z, axis=1, keepdims=True)\n",
    "    # avoid division by zero (almost impossible for Gaussians)\n",
    "    norms = np.where(norms == 0, 1.0, norms)\n",
    "    return Z / norms\n",
    "\n",
    "def sample_uniform_ball(d: int, n: int, rng: Optional[np.random.Generator] = None) -> np.ndarray:\n",
    "    \"\"\"Uniform in B1 in R^d via theta * U^(1/d).\"\"\"\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    theta = sample_uniform_sphere(d, n, rng=rng)\n",
    "    U = rng.random((n, 1))\n",
    "    r = U ** (1.0 / d)\n",
    "    return theta * r\n",
    "\n",
    "def radii(x: np.ndarray) -> np.ndarray:\n",
    "    return np.linalg.norm(np.asarray(x, dtype=float), axis=1)\n",
    "\n",
    "# Demo: radii distribution (most mass near 1 for large d)\n",
    "for d in [2, 5, 20, 100]:\n",
    "    rng = np.random.default_rng(0)\n",
    "    X = sample_uniform_ball(d, 50_000, rng=rng)\n",
    "    R = radii(X)\n",
    "    print(\"d=\", d, \"mean radius=\", float(np.mean(R)), \"q05/q95=\", float(np.quantile(R,0.05)), float(np.quantile(R,0.95)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8aaf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual: radius histogram for a few dimensions\n",
    "dims = [2, 10, 50]\n",
    "plt.figure()\n",
    "for d in dims:\n",
    "    rng = np.random.default_rng(d)\n",
    "    R = radii(sample_uniform_ball(d, 40_000, rng=rng))\n",
    "    plt.hist(R, bins=60, density=True, alpha=0.5, label=f\"d={d}\")\n",
    "plt.title(\"Radius distribution for Uniform(B1): mass moves toward 1 as d grows\")\n",
    "plt.xlabel(\"radius ||X||\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040bc80a",
   "metadata": {},
   "source": [
    "## 7) Why Naive Projection Fails (Section 10.4.1)\n",
    "\n",
    "### üö´ The Common Mistake (2D Example)\n",
    "\n",
    "**Bad idea:** To sample uniformly on the unit circle:\n",
    "1. Sample $(X,Y) \\sim \\text{Uniform}([-1,1]^2)$ (uniform in square)\n",
    "2. Project: $\\theta = (X,Y) / \\|(X,Y)\\|$\n",
    "\n",
    "**Why this fails:** The resulting **angle distribution is NOT uniform**!\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Why Does It Fail?\n",
    "\n",
    "**Geometric reason:**\n",
    "- Points in the square concentrate near the **corners**\n",
    "- Corners are at angles $45¬∞, 135¬∞, 225¬∞, 315¬∞$\n",
    "- After projection, these angles get **over-represented**\n",
    "\n",
    "**Visual intuition:**\n",
    "```\n",
    "Square [-1,1]¬≤:\n",
    "\n",
    "    +-------+\n",
    "    |   ‚Ä¢   |    ‚Üê fewer points project to 0¬∞, 90¬∞, 180¬∞, 270¬∞\n",
    "    | ‚Ä¢   ‚Ä¢ |\n",
    "    |   ‚Ä¢   |    ‚Üê more points project to 45¬∞, 135¬∞, etc.\n",
    "    +-------+\n",
    "\n",
    "```\n",
    "\n",
    "The corners \"stretch out\" when projected onto the circle!\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ The Correct Method\n",
    "\n",
    "**Option 1: Sample from disk, then project**\n",
    "1. Sample uniformly in the disk (using rejection or radial method)\n",
    "2. Project: $\\theta = (X,Y) / \\|(X,Y)\\|$\n",
    "3. Result: **Uniform angles!**\n",
    "\n",
    "**Why this works:** The disk is **rotationally symmetric**, so projection preserves uniformity.\n",
    "\n",
    "**Option 2: Use Gaussian method**\n",
    "1. Sample $Z \\sim N(0, I_2)$\n",
    "2. Normalize: $\\theta = Z / \\|Z\\|$\n",
    "3. Result: **Uniform on circle** (as per Lemma 10.16)\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Empirical Demonstration\n",
    "\n",
    "The code below shows:\n",
    "- **Red histogram:** Angles from projecting square points (NOT uniform, peaks at $\\pm\\pi/4$)\n",
    "- **Blue histogram:** Angles from projecting disk points (uniform, flat)\n",
    "\n",
    "The difference is stark! The naive method creates visible bias.\n",
    "\n",
    "---\n",
    "\n",
    "### üåç Higher Dimensions\n",
    "\n",
    "This problem gets **worse** in higher dimensions:\n",
    "- In $d=3$: Projecting from cube $[-1,1]^3$ to sphere $S_2$ creates bias\n",
    "- In $d=100$: The bias is extreme\n",
    "- **Always use the Gaussian normalization method for uniform sampling on spheres!**\n",
    "\n",
    "**Lesson:** Low-dimensional intuition (\"just project\") breaks down. Use proven methods!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bd7ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_to_circle(XY: np.ndarray) -> np.ndarray:\n",
    "    XY = np.asarray(XY, dtype=float)\n",
    "    norms = np.linalg.norm(XY, axis=1, keepdims=True)\n",
    "    norms = np.where(norms == 0, 1.0, norms)\n",
    "    return XY / norms\n",
    "\n",
    "def sample_uniform_square_2d(n: int, rng: Optional[np.random.Generator] = None) -> np.ndarray:\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    return rng.uniform(-1, 1, size=(n, 2))\n",
    "\n",
    "def sample_uniform_disk_via_rejection(n: int, rng: Optional[np.random.Generator] = None) -> Tuple[np.ndarray, float]:\n",
    "    \"\"\"Uniform in unit disk by sampling from square and accepting norm<1.\"\"\"\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    accepted = []\n",
    "    total = 0\n",
    "    while len(accepted) < n:\n",
    "        batch = rng.uniform(-1, 1, size=(max(1000, n), 2))\n",
    "        total += batch.shape[0]\n",
    "        keep = batch[np.linalg.norm(batch, axis=1) < 1]\n",
    "        accepted.append(keep)\n",
    "        accepted = [np.vstack(accepted)]\n",
    "        if accepted[0].shape[0] > n:\n",
    "            accepted[0] = accepted[0][:n]\n",
    "    return accepted[0], n / total\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "XY = sample_uniform_square_2d(80_000, rng=rng)\n",
    "proj_bad = project_to_circle(XY)\n",
    "angles_bad = np.arctan2(proj_bad[:,1], proj_bad[:,0])\n",
    "\n",
    "disk, acc = sample_uniform_disk_via_rejection(50_000, rng=rng)\n",
    "proj_good = project_to_circle(disk)\n",
    "angles_good = np.arctan2(proj_good[:,1], proj_good[:,0])\n",
    "\n",
    "print(\"disk rejection acceptance rate ~ area(disk)/area(square) =\", acc)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(angles_bad, bins=30, alpha=0.6, label=\"project from square (NOT uniform)\")\n",
    "plt.hist(angles_good, bins=30, alpha=0.6, label=\"disk->project (uniform)\")\n",
    "plt.title(\"Angle histograms on the unit circle\")\n",
    "plt.xlabel(\"angle\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70386529",
   "metadata": {},
   "source": [
    "## Exercise 10.15: Rejection sampling from cube to ball fails in high dimension\n",
    "\n",
    "If you sample from the cube $[-1,1]^d$ and accept if $\\|X\\|<1$, acceptance probability is:\n",
    "$$\\frac{|B_1|}{|[-1,1]^d|} = \\frac{|B_1|}{2^d}$$\n",
    "\n",
    "Since $|B_1|$ shrinks rapidly and $2^d$ grows exponentially, acceptance becomes tiny.\n",
    "\n",
    "Below: compute theoretical acceptance + simulate to feel it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc7073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acceptance_prob_ball_in_cube(d: int) -> float:\n",
    "    return volume_unit_ball(d) / (2.0 ** d)\n",
    "\n",
    "def rejection_sample_ball_from_cube(d: int, n: int, rng: Optional[np.random.Generator] = None, max_batches: int = 100000) -> Tuple[np.ndarray, float]:\n",
    "    \"\"\"Uniform(B1) by cube rejection (impractical for large d). Returns (samples, acceptance_rate).\"\"\"\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    accepted = []\n",
    "    total = 0\n",
    "    while sum(a.shape[0] for a in accepted) < n:\n",
    "        if max_batches <= 0:\n",
    "            raise RuntimeError(\"Too many batches; d is too large for rejection sampling.\")\n",
    "        batch = rng.uniform(-1, 1, size=(max(5000, n), d))\n",
    "        total += batch.shape[0]\n",
    "        keep = batch[np.linalg.norm(batch, axis=1) < 1]\n",
    "        accepted.append(keep)\n",
    "        max_batches -= 1\n",
    "    X = np.vstack(accepted)[:n]\n",
    "    return X, n / total\n",
    "\n",
    "for d in [2, 5, 10, 20, 30]:\n",
    "    print(\"d=\", d, \"theoretical acceptance |B1|/2^d =\", acceptance_prob_ball_in_cube(d))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb3fab3",
   "metadata": {},
   "source": [
    "## 8) The High-Dimensional Annulus Theorem (Theorem 10.20)\n",
    "\n",
    "### üéØ The Concentration Phenomenon\n",
    "\n",
    "**Theorem 10.20** is one of the most important results about high-dimensional geometry. It says:\n",
    "\n",
    "**Random vectors concentrate in thin shells around their expected norm.**\n",
    "\n",
    "---\n",
    "\n",
    "### üìê Precise Statement\n",
    "\n",
    "Let $X \\in \\mathbb{R}^d$ have **independent sub-Gaussian coordinates** with variance $\\sigma^2$.\n",
    "\n",
    "For any $\\beta \\leq \\sqrt{d}$:\n",
    "$$\\mathbb{P}\\left(\\sqrt{d}\\,\\sigma - \\beta \\leq \\|X\\| \\leq \\sqrt{d}\\,\\sigma + \\beta\\right) \\geq 1 - 2e^{-\\beta^2/128}$$\n",
    "\n",
    "**Translation:** With high probability, $\\|X\\|$ is within $\\beta$ of $\\sqrt{d}\\cdot\\sigma$.\n",
    "\n",
    "---\n",
    "\n",
    "### üí° What Does This Mean?\n",
    "\n",
    "**For a standard Gaussian** ($\\sigma = 1$):\n",
    "\n",
    "**Expected norm:** $\\approx \\sqrt{d}$\n",
    "\n",
    "**Concentration:** $\\|X\\| \\approx \\sqrt{d} \\pm \\beta$ with probability $\\geq 1 - 2e^{-\\beta^2/128}$\n",
    "\n",
    "**Example ($d=100, \\beta=3$):**\n",
    "- Expected norm: $\\sqrt{100} = 10$\n",
    "- Shell: $[10-3, 10+3] = [7, 13]$\n",
    "- Probability in shell: $\\geq 1 - 2e^{-9/128} \\approx 99.86\\%$\n",
    "\n",
    "**Almost all vectors have norm between 7 and 13!** The spread is tiny relative to the total space.\n",
    "\n",
    "---\n",
    "\n",
    "### üé± The Annulus (Shell) Picture\n",
    "\n",
    "Imagine concentric spheres:\n",
    "- **Inner sphere:** radius $\\sqrt{d} - \\beta$\n",
    "- **Outer sphere:** radius $\\sqrt{d} + \\beta$  \n",
    "- **Shell (annulus):** region between them\n",
    "\n",
    "**Thickness of shell:** $2\\beta$ (fixed!)\n",
    "\n",
    "**Radius of shell center:** $\\sqrt{d}$ (grows with dimension!)\n",
    "\n",
    "**Relative thickness:** $\\frac{2\\beta}{\\sqrt{d}} \\to 0$ as $d \\to \\infty$\n",
    "\n",
    "**Conclusion:** The shell becomes **arbitrarily thin** (relative to its radius) as $d$ increases!\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Probability Bound Analysis\n",
    "\n",
    "The bound $2e^{-\\beta^2/128}$ decays **exponentially** in $\\beta^2$:\n",
    "\n",
    "| $\\beta$ | Tail bound | In-shell prob |\n",
    "|---|------------|---------------|\n",
    "| 1 | 0.0155 | $\\geq 98.45\\%$ |\n",
    "| 2 | 0.0006 | $\\geq 99.94\\%$ |\n",
    "| 3 | 0.00002 | $\\geq 99.998\\%$ |\n",
    "| 4 | 0.0000002 | $\\geq 99.9998\\%$ |\n",
    "\n",
    "Even for moderate $\\beta$, almost all probability is in the shell!\n",
    "\n",
    "---\n",
    "\n",
    "### üî¨ Sub-Gaussian Coordinates\n",
    "\n",
    "**What are sub-Gaussian random variables?**\n",
    "\n",
    "A random variable $X$ is **sub-Gaussian with parameter $\\sigma$** if:\n",
    "$$\\mathbb{E}[e^{tX}] \\leq e^{\\sigma^2t^2/2} \\quad \\text{for all } t \\in \\mathbb{R}$$\n",
    "\n",
    "**Examples:**\n",
    "- **Gaussian $N(0,\\sigma^2)$:** Exactly sub-Gaussian with parameter $\\sigma$\n",
    "- **Bounded variables:** If $|X| \\leq C$, then $X$ is sub-Gaussian with parameter $\\propto C$\n",
    "- **Many distributions:** Uniform, Laplace, etc. (with appropriate constants)\n",
    "\n",
    "**Why this matters:** The theorem applies to **many distributions beyond Gaussians**!\n",
    "\n",
    "---\n",
    "\n",
    "### üåä Physical Interpretation\n",
    "\n",
    "In high dimensions, random vectors are \"**almost deterministic in length**\":\n",
    "- The norm $\\|X\\|$ concentrates tightly around $\\sqrt{d}\\cdot\\sigma$\n",
    "- Variability is $O(1)$, while mean is $O(\\sqrt{d})$\n",
    "- Relative spread: $O(1/\\sqrt{d}) \\to 0$\n",
    "\n",
    "**Analogy:** Like measuring the distance of millions of randomly thrown darts:\n",
    "- Individual throws are random\n",
    "- But the average distance becomes very predictable\n",
    "- In high dimensions, **even single vectors behave predictably!**\n",
    "\n",
    "---\n",
    "\n",
    "### üíª Empirical Verification\n",
    "\n",
    "The code below:\n",
    "1. Samples vectors from $N(0, I_d)$\n",
    "2. Computes their norms\n",
    "3. Checks what fraction lie in $[\\sqrt{d} - \\beta, \\sqrt{d} + \\beta]$\n",
    "4. Compares to the theoretical lower bound\n",
    "\n",
    "**Result:** Empirical probabilities consistently exceed the theoretical lower bound, confirming the theorem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e12f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annulus_shell_probability_lower_bound(beta: float) -> float:\n",
    "    \"\"\"Lower bound: 1 - 2 exp(-beta^2/128).\"\"\"\n",
    "    return float(1.0 - 2.0 * math.exp(-(beta*beta)/128.0))\n",
    "\n",
    "def annulus_shell_tail_bound(beta: float) -> float:\n",
    "    \"\"\"Upper bound on being outside shell: 2 exp(-beta^2/128).\"\"\"\n",
    "    return float(2.0 * math.exp(-(beta*beta)/128.0))\n",
    "\n",
    "def empirical_shell_probability(d: int, beta: float, n: int = 200_000, seed: int = 0) -> float:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X = sample_spherical_gaussian(d, n, rng=rng)  # a=1\n",
    "    R = radii(X)\n",
    "    lo = math.sqrt(d) - beta\n",
    "    hi = math.sqrt(d) + beta\n",
    "    return float(np.mean((R >= lo) & (R <= hi)))\n",
    "\n",
    "# Demo: compare empirical vs bound for some (d, beta)\n",
    "for d in [20, 50, 100, 200]:\n",
    "    for beta in [0.5, 1.0, 2.0, 3.0]:\n",
    "        if beta <= math.sqrt(d):\n",
    "            emp = empirical_shell_probability(d, beta, n=80_000, seed=1)\n",
    "            lb = annulus_shell_probability_lower_bound(beta)\n",
    "            print(f\"d={d:3d}, beta={beta:3.1f}  empirical={emp:.4f}  bound>={lb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f1fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual: norm distribution of Gaussian vs shell center sqrt(d)\n",
    "d = 100\n",
    "rng = np.random.default_rng(0)\n",
    "X = sample_spherical_gaussian(d, 80_000, rng=rng)\n",
    "R = radii(X)\n",
    "center = math.sqrt(d)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(R, bins=80, density=True)\n",
    "plt.axvline(center, linestyle='--', label=\"sqrt(d)\")\n",
    "plt.title(\"||X|| for X~N(0,I_d) concentrates near sqrt(d)\")\n",
    "plt.xlabel(\"||X||\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312744a4",
   "metadata": {},
   "source": [
    "## Extra: Monte Carlo estimate of $|B_1|$ (useful for intuition)\n",
    "\n",
    "If $X\\sim\\text{Uniform}([-1,1]^d)$, then:\n",
    "$$|B_1| = 2^d \\cdot \\mathbb{P}(\\|X\\|<1)$$\n",
    "\n",
    "This is fine for small $d$, but fails for large $d$ because the probability is tiny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b026a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_volume_unit_ball_mc(d: int, n: int = 2_000_000, seed: int = 0) -> Tuple[float, float]:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X = rng.uniform(-1, 1, size=(n, d))\n",
    "    p = float(np.mean(np.linalg.norm(X, axis=1) < 1.0))\n",
    "    est = (2.0 ** d) * p\n",
    "    return est, p\n",
    "\n",
    "for d in [2,3,5,8,10]:\n",
    "    est, p = estimate_volume_unit_ball_mc(d, n=300_000, seed=0)\n",
    "    print(f\"d={d:2d}  MC |B1|‚âà{est:.6f}  exact={volume_unit_ball(d):.6f}  accept p={p:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5943312e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Summary: The Curse and Blessing of High Dimensions\n",
    "\n",
    "### üéØ Key Phenomena Recap\n",
    "\n",
    "#### 1Ô∏è‚É£ **Vanishing Volume (Lemma 10.5)**\n",
    "- Unit ball volume $|B_1| \\to 0$ as $d \\to \\infty$\n",
    "- For $d > 4\\pi \\approx 12.57$, the volume starts shrinking\n",
    "- By $d=100$, $|B_1| \\approx 10^{-41}$ (essentially zero!)\n",
    "\n",
    "**Implication:** \"Most of the space\" is **outside** the unit ball.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2Ô∏è‚É£ **Boundary Concentration (Lemma 10.7)**\n",
    "- $(1-\\varepsilon)^d \\to 0$ exponentially fast\n",
    "- Almost all volume is in the outer $\\varepsilon$-shell\n",
    "- The interior becomes negligible\n",
    "\n",
    "**Implication:** High-dimensional objects are \"**all surface, no interior**.\"\n",
    "\n",
    "---\n",
    "\n",
    "#### 3Ô∏è‚É£ **Norm Concentration (Theorem 10.20)**\n",
    "- Random vectors have norms tightly concentrated around $\\sqrt{d}\\cdot\\sigma$\n",
    "- Shell thickness is $O(1)$, but radius is $O(\\sqrt{d})$\n",
    "- Relative uncertainty $\\to 0$ as $d \\to \\infty$\n",
    "\n",
    "**Implication:** In high dimensions, **randomness becomes predictable**.\n",
    "\n",
    "---\n",
    "\n",
    "### üó∫Ô∏è Concept Map\n",
    "\n",
    "```\n",
    "     HIGH-DIMENSIONAL GEOMETRY\n",
    "              |\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    |                   |\n",
    "VOLUME EFFECTS    CONCENTRATION\n",
    "    |                   |\n",
    "    ‚îú‚îÄ Vanishing        ‚îú‚îÄ Annulus Theorem\n",
    "    ‚îÇ  (Lemma 10.5)     ‚îÇ  (Thm 10.20)\n",
    "    ‚îÇ                   ‚îÇ\n",
    "    ‚îú‚îÄ Boundary         ‚îú‚îÄ Norm concentration\n",
    "    ‚îÇ  (Lemma 10.7)     ‚îÇ  (tight shells)\n",
    "    ‚îÇ                   ‚îÇ\n",
    "    ‚îî‚îÄ Exact formulas   ‚îî‚îÄ Sub-Gaussian\n",
    "       (Thm 10.8)           variables\n",
    "              |\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    |                   |\n",
    " SAMPLING           APPLICATIONS\n",
    "    |                   |\n",
    "    ‚îú‚îÄ Spheres          ‚îú‚îÄ ML algorithms\n",
    "    ‚îÇ  (Lemma 10.16)    ‚îÇ\n",
    "    ‚îÇ                   ‚îú‚îÄ Dimensionality\n",
    "    ‚îú‚îÄ Balls            ‚îÇ  reduction\n",
    "    ‚îÇ  (Thm 10.18)      ‚îÇ\n",
    "    ‚îÇ                   ‚îî‚îÄ Nearest neighbors\n",
    "    ‚îî‚îÄ Projection       \n",
    "       pitfalls\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üìä The Curse of Dimensionality\n",
    "\n",
    "**Problems caused by high dimensions:**\n",
    "\n",
    "1. **Volume explosion:** $|[-1,1]^d| = 2^d$ grows exponentially\n",
    "2. **Sparse data:** Points become far apart (average distance $\\approx \\sqrt{d}$)\n",
    "3. **Nearest neighbors fail:** \"Near\" and \"far\" lose meaning (all distances $\\approx$ equal)\n",
    "4. **Curse of sampling:** Rejection sampling becomes impossible\n",
    "5. **Computational cost:** Algorithms scale poorly with $d$\n",
    "\n",
    "**Examples:**\n",
    "- **k-NN algorithm:** Breaks down for $d > 20$ (all neighbors equally far)\n",
    "- **Grid search:** Need exponentially many grid points\n",
    "- **Density estimation:** Need exponentially many samples\n",
    "\n",
    "---\n",
    "\n",
    "### üéÅ The Blessing of Dimensionality\n",
    "\n",
    "**But high dimensions also help:**\n",
    "\n",
    "1. **Concentration:** Randomness becomes predictable (law of large numbers in action)\n",
    "2. **Orthogonality:** Random vectors are nearly orthogonal (useful for projections)\n",
    "3. **Linear separability:** Complex patterns become linearly separable\n",
    "4. **Signal representation:** Rich feature spaces for machine learning\n",
    "\n",
    "**Examples:**\n",
    "- **Kernel methods:** Map to high-d spaces for better separation\n",
    "- **Random projections:** Johnson-Lindenstrauss lemma uses high-d concentration\n",
    "- **Compressed sensing:** Sparse signals in high dimensions\n",
    "\n",
    "---\n",
    "\n",
    "### üõ†Ô∏è Practical Guidelines\n",
    "\n",
    "#### When Working with High-Dimensional Data:\n",
    "\n",
    "**‚úÖ DO:**\n",
    "- Use dimensionality reduction (PCA, t-SNE, UMAP)\n",
    "- Leverage concentration phenomena (norms, distances)\n",
    "- Use theoretically sound sampling methods (Gaussian normalization)\n",
    "- Work in subspaces or manifolds when possible\n",
    "- Use algorithms designed for high dimensions\n",
    "\n",
    "**‚ùå DON'T:**\n",
    "- Trust low-dimensional intuition\n",
    "- Use rejection sampling from cubes\n",
    "- Rely on k-NN for very high $d$\n",
    "- Forget to normalize/standardize features\n",
    "- Ignore the curse when designing algorithms\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Function Reference\n",
    "\n",
    "#### **Geometric Predicates:**\n",
    "- `in_ball(X, r)`, `in_unit_ball(X)`, `on_unit_sphere(X)`, `radii(X)`\n",
    "\n",
    "#### **Gaussian Sampling:**\n",
    "- `sample_spherical_gaussian(d, n)` ‚Üí $N(0, I_d)$\n",
    "- `sample_normalized_gaussian(d, n)` ‚Üí $(2\\pi)^{-1/2} Z$\n",
    "\n",
    "#### **Exact Formulas:**\n",
    "- `volume_unit_ball(d)`, `area_unit_sphere(d)`\n",
    "- `log_volume_unit_ball(d)` (stable for large $d$)\n",
    "\n",
    "#### **Uniform Sampling:**\n",
    "- `sample_uniform_sphere(d, n)` ‚Üí $\\text{Uniform}(S_1)$\n",
    "- `sample_uniform_ball(d, n)` ‚Üí $\\text{Uniform}(B_1)$\n",
    "\n",
    "#### **Rejection Sampling:**\n",
    "- `acceptance_prob_ball_in_cube(d)` ‚Üí theoretical rate\n",
    "- `rejection_sample_ball_from_cube(d, n)` (use only for small $d$!)\n",
    "\n",
    "#### **Concentration:**\n",
    "- `annulus_shell_probability_lower_bound(beta)`\n",
    "- `empirical_shell_probability(d, beta, n)`\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ Next Steps & Further Reading\n",
    "\n",
    "#### **Advanced Topics:**\n",
    "\n",
    "1. **Johnson-Lindenstrauss Lemma**\n",
    "   - Random projections preserve distances\n",
    "   - Applications in dimensionality reduction\n",
    "\n",
    "2. **Concentration of Measure**\n",
    "   - Isoperimetric inequalities\n",
    "   - Measure concentration phenomenon\n",
    "\n",
    "3. **Manifold Learning**\n",
    "   - High-dimensional data on low-dimensional manifolds\n",
    "   - t-SNE, UMAP, autoencoders\n",
    "\n",
    "4. **Curse in Machine Learning**\n",
    "   - Feature selection and regularization\n",
    "   - Why deep learning works despite high dimensions\n",
    "\n",
    "5. **Random Matrix Theory**\n",
    "   - Eigenvalue distributions\n",
    "   - Applications in statistics and ML\n",
    "\n",
    "---\n",
    "\n",
    "#### **Recommended Resources:**\n",
    "\n",
    "**Books:**\n",
    "- *High-Dimensional Probability* by Roman Vershynin\n",
    "- *High-Dimensional Statistics* by Martin Wainwright  \n",
    "- *Concentration Inequalities* by Boucheron et al.\n",
    "\n",
    "**Papers:**\n",
    "- Donoho: \"High-Dimensional Data Analysis: The Curses and Blessings of Dimensionality\"\n",
    "- Indyk & Motwani: \"Approximate Nearest Neighbors: Towards Removing the Curse\"\n",
    "\n",
    "**Online:**\n",
    "- 3Blue1Brown: High-dimensional sphere visualizations\n",
    "- Distill.pub: Interactive ML visualizations\n",
    "- Seeing Theory: Probability visualizations\n",
    "\n",
    "---\n",
    "\n",
    "## üéì Final Thoughts\n",
    "\n",
    "High-dimensional geometry is **weird, wonderful, and essential** for modern data science:\n",
    "\n",
    "- **Weird:** Our intuition fails completely\n",
    "- **Wonderful:** Beautiful mathematical phenomena emerge\n",
    "- **Essential:** Understanding it is crucial for ML/AI\n",
    "\n",
    "**Remember:**\n",
    "- In high dimensions, **almost everything is on the surface**\n",
    "- **Random becomes predictable** through concentration\n",
    "- **Your 3D intuition will mislead you**‚Äîtrust the mathematics!\n",
    "\n",
    "**Keep exploring, stay curious, and embrace the strange beauty of high dimensions!** üååüöÄ\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Complete Function Index (Copy/Paste Ready)\n",
    "\n",
    "### Geometry predicates\n",
    "- `in_ball(X, r)` / `in_unit_ball(X)` / `on_unit_sphere(X)` / `radii(X)`\n",
    "\n",
    "### Gaussian models (Models 10.3‚Äì10.4)\n",
    "- `sample_spherical_gaussian(d,n)` ($N(0,I)$)\n",
    "- `sample_normalized_gaussian(d,n)` (scaled by $(2\\pi)^{-1/2}$)\n",
    "- `expected_norm_sq_spherical(d)` / `expected_norm_sq_normalized(d)`\n",
    "\n",
    "### Scaling (Lemma 10.7)\n",
    "- `scaling_volume_ratio(d, eps)`\n",
    "\n",
    "### Exact volumes/areas (Theorem 10.8)\n",
    "- `volume_unit_ball(d)` / `log_volume_unit_ball(d)`\n",
    "- `area_unit_sphere(d)` / `log_area_unit_sphere(d)`\n",
    "\n",
    "### Uniform sampling (Lemma 10.16, Thm 10.18)\n",
    "- `sample_uniform_sphere(d,n)`\n",
    "- `sample_uniform_ball(d,n)`\n",
    "\n",
    "### Rejection sampling + projections (Sec 10.4.1, Ex 10.15)\n",
    "- `sample_uniform_disk_via_rejection(n)`\n",
    "- `project_to_circle(XY)`\n",
    "- `acceptance_prob_ball_in_cube(d)`\n",
    "- `rejection_sample_ball_from_cube(d,n)` (use only for small $d$)\n",
    "\n",
    "### Annulus theorem (Thm 10.20)\n",
    "- `annulus_shell_probability_lower_bound(beta)`\n",
    "- `empirical_shell_probability(d, beta, n, seed)`\n",
    "\n",
    "### Monte Carlo volume estimation\n",
    "- `estimate_volume_unit_ball_mc(d, n, seed)`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
